{
  "hash": "187615d868f9ed1c2fffeb9cf98083bf",
  "result": {
    "engine": "jupyter",
    "markdown": "# Cross-Industry Patterns: Security and Automation {#sec-cross-industry-patterns}\n\n:::{.callout-note}\n## Chapter Overview\nBefore diving into industry-specific applications, this chapter covers embedding patterns that apply universally across all industries. Every organization—regardless of sector—faces cybersecurity threats, must detect behavioral anomalies, and can benefit from embedding-driven decision systems. These cross-cutting patterns from Part IV's advanced applications form the foundation upon which industry-specific solutions are built. Financial services, healthcare, retail, manufacturing, and every other industry should apply these techniques alongside their domain-specific implementations.\n:::\n\nThe application patterns covered in Part IV—RAG (@sec-rag-at-scale), semantic search (@sec-semantic-search), and recommendation systems (@sec-recommendation-systems)—provide powerful capabilities that organizations adopt based on their specific needs. However, some embedding applications are not optional: **every organization must address security threats and behavioral anomalies**, and **every organization can benefit from embedding-driven automation**.\n\nThis chapter consolidates these universal patterns, providing a foundation that subsequent industry chapters build upon. When you read about financial services (@sec-financial-services), healthcare (@sec-healthcare-life-sciences), or manufacturing (@sec-manufacturing-industry40), assume these cross-industry patterns apply in addition to domain-specific techniques.\n\n## Cybersecurity Threat Hunting\n\nCybersecurity teams hunt for threats—APTs, compromised accounts, insider threats—in massive logs. **Embedding-based threat hunting** learns behavioral embeddings of users, devices, and network entities, detecting anomalies that indicate compromise or malicious activity.\n\n### The Threat Hunting Challenge\n\nTraditional Security Information and Event Management (SIEM) systems use rules:\n\n- Rule: If user logs in from new country, alert\n- Rule: If outbound data transfer > 10GB, alert\n\n**Limitations:**\n\n- High false positives (legitimate travel, legitimate data transfers)\n- Evasion: Attackers split transfers, use slow exfiltration\n- Cannot detect novel attacks (zero-day exploits, new TTPs)\n\n**The Zero-Day Argument**: The most compelling case for embeddings in security is **zero-day detection**. A classifier can only recognize attack patterns present in its training data. An embedding system can detect \"this behavior is unlike anything normal I've seen\" without ever having seen that specific attack.\n\n```python\n# Classifier limitation: only knows trained attack types\nattack_types = ['sql_injection', 'xss', 'credential_stuffing']  # Fixed at training time\n\n# Embedding advantage: detects deviation from normal\nif distance_to_nearest_normal_cluster > threshold:\n    alert(\"Anomalous behavior detected\")  # Works for novel attacks\n```\n\n**Embedding approach**: Learn normal behavior embeddings for each user/device. Anomalies = deviation from learned patterns. See @sec-custom-embedding-strategies for approaches to building behavioral embeddings, from fine-tuning pre-trained models to custom architectures.\n\n:::{.callout-important}\n## Establishing \"Normal\": The Cold Start Problem\n\nA common question: *when the system is first deployed, how do you know what's normal?* Several approaches:\n\n**1. Baseline Learning Period (most common)**\n\nRun the system in \"learning mode\" for 2-4 weeks before alerting. During this period:\n\n- Collect behavior embeddings without generating alerts\n- Assume the vast majority of traffic is legitimate (typically >99%)\n- Build per-user/per-device baseline clusters\n- Use statistical methods (IQR, percentile thresholds) to set initial anomaly boundaries\n\n**2. Labeled Historical Data (supervised bootstrap)**\n\nIf you have historical logs with known incidents:\n\n- Label past incidents as \"malicious\" (from SIEM alerts, incident reports)\n- Everything else becomes the \"normal\" training set\n- Risk: unknown compromises in \"normal\" data (addressed below)\n\n**3. Clean Room Approach (high-security environments)**\n\n- Build baseline from controlled test traffic or synthetic data\n- Gradually incorporate production traffic after validation\n- Most conservative but slowest to deploy\n\n**What about malicious traffic already in the baseline?**\n\nThis is a real concern—an attacker who's already present gets \"grandfathered\" into normal. Mitigations:\n\n- **Peer group analysis**: Compare users to similar roles. An analyst doing admin tasks stands out even if that's \"their normal\"\n- **Behavioral drift detection**: Alert on *gradual* changes, not just sudden ones\n- **External threat intelligence**: Cross-reference with known IOCs during baseline period\n- **Periodic baseline refresh**: Rebuild baselines periodically, excluding known-bad periods\n- **Hybrid detection**: Run rule-based detection in parallel during baseline learning\n\n**Practical timeline**:\n\n| Phase | Duration | Mode |\n|-------|----------|------|\n| Initial collection | 1-2 weeks | Silent (no alerts) |\n| Baseline calibration | 1-2 weeks | High-threshold alerts only |\n| Production | Ongoing | Full alerting with feedback loop |\n\nThe key insight: you don't need *perfect* baselines to detect *novel* attacks. Even a baseline contaminated with some malicious behavior will flag attacks that differ from *that* attacker's patterns.\n:::\n\n::: {#b058dbbd .cell execution_count=1}\n``` {.python .cell-code code-fold=\"true\" code-summary=\"Show User Behavior Anomaly Detection\"}\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\n\nclass UserBehaviorModel(nn.Module):\n    \"\"\"Model user behavior as sequence of events.\"\"\"\n    def __init__(self, event_dim: int = 64, hidden_dim: int = 128, num_event_types: int = 20):\n        super().__init__()\n        self.event_type_embedding = nn.Embedding(num_event_types, event_dim)\n        self.lstm = nn.LSTM(input_size=event_dim, hidden_size=hidden_dim,\n                            num_layers=2, batch_first=True)\n        self.attention = nn.Linear(hidden_dim, 1)\n        self.output_projection = nn.Linear(hidden_dim, event_dim)\n\n    def forward(self, event_sequences):\n        \"\"\"Encode user behavior from event sequence.\"\"\"\n        event_embs = self.event_type_embedding(event_sequences)\n        lstm_out, _ = self.lstm(event_embs)\n\n        # Attention mechanism\n        attn_weights = torch.softmax(self.attention(lstm_out), dim=1)\n        behavior_emb = (lstm_out * attn_weights).sum(dim=1)\n\n        behavior_emb = self.output_projection(behavior_emb)\n        return F.normalize(behavior_emb, p=2, dim=1)\n\n# Usage example\nmodel = UserBehaviorModel(event_dim=64, hidden_dim=128, num_event_types=20)\n\n# Normal behavior sequence\nnormal_sequence = torch.tensor([[0, 2, 3, 2, 0]])  # login, file_read, etc.\nnormal_emb = model(normal_sequence)\n\n# Anomalous behavior sequence\nanomalous_sequence = torch.tensor([[1, 4, 5, 4]])  # login_failure, file_delete, etc.\nanomalous_emb = model(anomalous_sequence)\n\n# Compare\ndistance = torch.norm(normal_emb - anomalous_emb)\nprint(f\"Behavior distance: {distance.item():.4f}\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nBehavior distance: 0.2420\n```\n:::\n:::\n\n\n:::{.callout-tip}\n## Threat Hunting Best Practices\n\n**Baselines:**\n\n- **Per-user baselines**: Each user has unique normal behavior\n- **Per-device baselines**: Each device has characteristic patterns\n- **Time-aware**: Behavior varies by time of day, day of week\n- **Context-aware**: Location, VPN usage, remote vs office\n\n**Features:**\n\n- **Login patterns**: Time, location, device, success/failure rate\n- **File access**: Paths accessed, read/write/delete ratios\n- **Network activity**: Connections, data volumes, destinations\n- **Process execution**: Binaries run, arguments, parent processes\n\n**Detection:**\n\n- **Sequential anomalies**: Unusual sequence of events (login → sensitive file → large upload)\n- **Statistical anomalies**: Unusual frequency, volume, or timing\n- **Behavioral drift**: Gradual change in behavior (slow compromise)\n- **Peer group analysis**: Deviation from similar users (same role, department)\n\n**Production:**\n\n- **Low latency**: <1 second for real-time alerting\n- **Prioritization**: Rank alerts by severity (combine multiple signals)\n- **Investigation workflow**: Provide context for analysts (what's unusual, why)\n- **Feedback loop**: Incorporate analyst decisions (true positive, false positive)\n:::\n\n### Industry Applications of Threat Hunting\n\nWhile the core threat hunting techniques are universal, each industry has specific threat profiles:\n\n- **Financial Services** (@sec-financial-services): Focus on credential theft, payment fraud, insider trading\n- **Healthcare** (@sec-healthcare-life-sciences): PHI exfiltration, ransomware, medical device compromise\n- **Retail** (@sec-retail-ecommerce): POS malware, loyalty fraud, supply chain attacks\n- **Manufacturing** (@sec-manufacturing-industry40): Industrial espionage, OT/ICS attacks, IP theft\n- **Defense** (@sec-defense-intelligence): Nation-state APTs, classified data exfiltration\n\n## Behavioral Anomaly Detection\n\nUser accounts can be compromised (phishing, credential stuffing) or misused (insider threats). **Behavioral anomaly detection** learns normal user behavior embeddings, flagging deviations that indicate account takeover or malicious activity.\n\n### The Behavioral Challenge\n\nUsers exhibit consistent patterns:\n\n- Login times (weekdays 9-5)\n- Devices (laptop, phone)\n- Actions (emails, file access)\n\n**Account compromise changes behavior**:\n\n- Login from new location/device\n- Unusual actions (access sensitive files, bulk downloads)\n- Velocity changes (sudden spike in activity)\n\n**Challenge**: Detect deviations while adapting to legitimate behavior changes (new job, new phone).\n\n::: {#bb6c9db9 .cell execution_count=2}\n``` {.python .cell-code code-fold=\"true\" code-summary=\"Show Behavioral Anomaly Detection Example\"}\ndef behavioral_anomaly_example():\n    \"\"\"Account takeover detection for web application.\"\"\"\n    print(\"=== Account Takeover Detection ===\")\n    print(\"\\nNormal baseline:\")\n    print(\"  Login time: Weekdays 9am-6pm\")\n    print(\"  Location: San Francisco office\")\n    print(\"  Device: MacBook Pro\")\n    print(\"  Actions: View dashboard, edit documents\")\n    print(\"  Velocity: 10-20 pages/session\")\n\n    print(\"\\n--- Legitimate Session ---\")\n    print(\"Time: Tuesday 2pm\")\n    print(\"Location: San Francisco office\")\n    print(\"Device: MacBook Pro\")\n    print(\"Actions: View dashboard, edit report, send email\")\n    print(\"Velocity: 15 pages\")\n    print(\"→ Anomaly score: 0.05 (NORMAL)\")\n\n    print(\"\\n--- Compromised Session ---\")\n    print(\"Time: Saturday 3am\")\n    print(\"Location: Unknown (Tor exit node)\")\n    print(\"Device: Windows PC (new)\")\n    print(\"Actions: Access admin panel, bulk export users, delete logs\")\n    print(\"Velocity: 150 pages\")\n    print(\"→ Anomaly score: 0.95 (ALERT: Possible account takeover)\")\n\n    print(\"\\n--- Legitimate Travel ---\")\n    print(\"Time: Monday 10am\")\n    print(\"Location: New York office (business trip)\")\n    print(\"Device: MacBook Pro + iPhone\")\n    print(\"Actions: View dashboard, edit documents\")\n    print(\"Velocity: 12 pages\")\n    print(\"→ Anomaly score: 0.25 (MONITOR: New location, but normal actions)\")\n\n# Run example\nbehavioral_anomaly_example()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n=== Account Takeover Detection ===\n\nNormal baseline:\n  Login time: Weekdays 9am-6pm\n  Location: San Francisco office\n  Device: MacBook Pro\n  Actions: View dashboard, edit documents\n  Velocity: 10-20 pages/session\n\n--- Legitimate Session ---\nTime: Tuesday 2pm\nLocation: San Francisco office\nDevice: MacBook Pro\nActions: View dashboard, edit report, send email\nVelocity: 15 pages\n→ Anomaly score: 0.05 (NORMAL)\n\n--- Compromised Session ---\nTime: Saturday 3am\nLocation: Unknown (Tor exit node)\nDevice: Windows PC (new)\nActions: Access admin panel, bulk export users, delete logs\nVelocity: 150 pages\n→ Anomaly score: 0.95 (ALERT: Possible account takeover)\n\n--- Legitimate Travel ---\nTime: Monday 10am\nLocation: New York office (business trip)\nDevice: MacBook Pro + iPhone\nActions: View dashboard, edit documents\nVelocity: 12 pages\n→ Anomaly score: 0.25 (MONITOR: New location, but normal actions)\n```\n:::\n:::\n\n\n:::{.callout-tip}\n## Behavioral Anomaly Best Practices\n\n**Features:**\n\n- **Temporal**: Time of day, day of week, session duration\n- **Spatial**: Location (IP geolocation), VPN usage\n- **Device**: Browser, OS, screen resolution (fingerprinting)\n- **Actions**: Pages visited, features used, API calls made\n- **Velocity**: Actions per minute, data transferred\n\n**Modeling:**\n\n- **Per-user baselines**: Each user has unique normal behavior\n- **LSTM**: Sequential modeling of user actions\n- **Autoencoder**: Reconstruct behavior, high error = anomaly\n- **Peer groups**: Compare to similar users (same role)\n\n**Production:**\n\n- **Real-time**: Flag suspicious sessions immediately\n- **Progressive authentication**: Challenge anomalous sessions (2FA, security questions)\n- **Adaptive baselines**: Update with confirmed normal behavior\n- **False positive management**: Avoid blocking legitimate users\n\n**Challenges:**\n\n- **Cold start**: New users have no baseline\n- **Concept drift**: Behavior changes over time (new role, new tools)\n- **Adversarial**: Attackers mimic normal behavior (slow compromise)\n:::\n\n## Embedding-Driven Business Rules\n\nBusiness rules encode domain knowledge: credit policies, pricing strategies, underwriting guidelines. **Embedding-driven business rules** replace rigid if-then logic with learned decision boundaries in embedding space, adapting to patterns that humans can't articulate and updating as business conditions change.\n\n### The Business Rules Challenge\n\nTraditional business rules face limitations:\n\n- **Brittleness**: Rules hardcode thresholds (credit score > 700) that don't generalize\n- **Maintenance burden**: Hundreds of rules accumulate, interact unpredictably\n- **Cold start**: No rules exist for new products, markets, situations\n- **Suboptimality**: Rules encode human intuition, miss non-linear patterns\n\n**Embedding approach**: Learn entity embeddings (customers, products, transactions) and decision boundaries from historical outcomes. New decisions query: \"find similar past cases, what happened?\" See @sec-custom-embedding-strategies for guidance on building these embeddings, and @sec-siamese-networks for similarity-based learning approaches.\n\n::: {#95e2a699 .cell execution_count=3}\n``` {.python .cell-code code-fold=\"true\" code-summary=\"Show Case-Based Reasoning System\"}\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport numpy as np\nfrom dataclasses import dataclass\nfrom typing import Optional\n\n\n@dataclass\nclass BusinessCase:\n    \"\"\"Historical business decision case.\"\"\"\n    case_id: str\n    entity_id: str\n    context: dict\n    decision: any\n    outcome: Optional[any] = None\n    embedding: Optional[np.ndarray] = None\n\n\nclass EntityEncoder(nn.Module):\n    \"\"\"Encode entities for decision making.\"\"\"\n    def __init__(self, embedding_dim: int = 128,\n                 num_categorical: int = 10, num_numerical: int = 20):\n        super().__init__()\n        self.embedding_dim = embedding_dim\n        self.categorical_embeddings = nn.ModuleList(\n            [nn.Embedding(1000, 16) for _ in range(num_categorical)]\n        )\n        self.numerical_encoder = nn.Sequential(\n            nn.Linear(num_numerical, 64),\n            nn.ReLU(),\n            nn.Dropout(0.2),\n            nn.Linear(64, 64)\n        )\n        feature_dim = num_categorical * 16 + 64\n        self.feature_encoder = nn.Sequential(\n            nn.Linear(feature_dim, 256),\n            nn.ReLU(),\n            nn.Dropout(0.2),\n            nn.Linear(256, embedding_dim)\n        )\n\n    def forward(self, categorical_features, numerical_features):\n        \"\"\"Encode entities to embeddings.\"\"\"\n        cat_embs = [emb_layer(categorical_features[:, i])\n                    for i, emb_layer in enumerate(self.categorical_embeddings)]\n        cat_emb = torch.cat(cat_embs, dim=1)\n        num_emb = self.numerical_encoder(numerical_features)\n        combined = torch.cat([cat_emb, num_emb], dim=1)\n        entity_emb = self.feature_encoder(combined)\n        return F.normalize(entity_emb, p=2, dim=1)\n\n# Usage example\nencoder = EntityEncoder(embedding_dim=128, num_categorical=10, num_numerical=20)\ncat_features = torch.randint(0, 100, (1, 10))\nnum_features = torch.randn(1, 20)\nembedding = encoder(cat_features, num_features)\nprint(f\"Entity embedding shape: {embedding.shape}\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nEntity embedding shape: torch.Size([1, 128])\n```\n:::\n:::\n\n\n:::{.callout-tip}\n## Embedding-Driven Business Rules Best Practices\n\n**Architecture:**\n\n- **Entity encoders**: Learn embeddings that predict outcomes\n- **Case-based reasoning**: Retrieve similar historical cases\n- **Hybrid systems**: Combine learned patterns + explicit rules\n- **Explainability**: Surface similar cases that influenced decision\n\n**Training:**\n\n- **Metric learning**: Entities with similar outcomes close in embedding space (see @sec-siamese-networks)\n- **Multi-task**: Predict multiple outcomes jointly (default, LTV, churn)\n- **Temporal**: Weight recent cases higher (concept drift)\n- **Fairness**: Constrain to prevent disparate impact\n\n**Production:**\n\n- **Low latency**: <100ms for real-time decisions (credit cards, pricing)\n- **Confidence thresholds**: Route low-confidence to humans\n- **Rule compliance**: Hard constraints for regulations\n- **Monitoring**: Track decision quality, fairness metrics\n- **Feedback loops**: Continuously add outcomes to case database\n\n**Challenges:**\n\n- **Cold start**: No historical cases for new scenarios\n- **Distribution shift**: Decisions change underlying distribution\n- **Adversarial**: Bad actors game the system\n- **Fairness**: Embeddings can encode bias from historical data\n:::\n\n### Industry Applications of Business Rules\n\nEach industry applies embedding-driven rules differently:\n\n- **Financial Services** (@sec-financial-services): Credit decisions, fraud rules, trading limits\n- **Healthcare** (@sec-healthcare-life-sciences): Treatment protocols, clinical decision support\n- **Retail** (@sec-retail-ecommerce): Pricing rules, promotion targeting, inventory allocation\n- **Manufacturing** (@sec-manufacturing-industry40): Quality gates, process parameters, maintenance scheduling\n\n## Customer Support Intelligence\n\nCustomer support operations generate massive volumes of unstructured data—tickets, chat transcripts, emails, call recordings—that embeddings transform into actionable intelligence. **Embedding-based customer support systems** enable semantic routing, automated resolution, agent assist, and proactive issue detection at scale.\n\n### The Support Intelligence Challenge\n\nTraditional customer support systems rely on keyword matching and manual categorization:\n\n- **Routing failures**: \"My card doesn't work\" routes to \"card services\" instead of \"fraud\"\n- **Knowledge silos**: Solutions exist but agents can't find them\n- **Repetitive work**: Agents solve the same problems repeatedly\n- **Reactive posture**: Issues discovered when customers complain\n\n**Embedding approach**: Encode tickets, knowledge articles, and historical resolutions into a unified semantic space. Similar issues cluster together; solutions transfer across variations. See @sec-semantic-search for search implementation and @sec-rag-at-scale for retrieval-augmented response generation.\n\n::: {#a86fbb67 .cell execution_count=4}\n``` {.python .cell-code code-fold=\"true\" code-summary=\"Show Customer Support Embedding System\"}\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom dataclasses import dataclass\nfrom typing import Optional\nimport numpy as np\n\n\n@dataclass\nclass SupportTicket:\n    \"\"\"Customer support ticket with metadata.\"\"\"\n    ticket_id: str\n    text: str\n    category: Optional[str] = None\n    priority: Optional[str] = None\n    resolution: Optional[str] = None\n    embedding: Optional[np.ndarray] = None\n\n\nclass SupportEncoder(nn.Module):\n    \"\"\"Encode support tickets for semantic operations.\"\"\"\n    def __init__(self, vocab_size: int = 30000, embedding_dim: int = 256,\n                 hidden_dim: int = 512):\n        super().__init__()\n        self.token_embedding = nn.Embedding(vocab_size, embedding_dim)\n        self.encoder = nn.TransformerEncoder(\n            nn.TransformerEncoderLayer(\n                d_model=embedding_dim, nhead=8, dim_feedforward=hidden_dim,\n                batch_first=True\n            ),\n            num_layers=4\n        )\n        self.pooler = nn.Linear(embedding_dim, embedding_dim)\n\n    def forward(self, token_ids, attention_mask=None):\n        \"\"\"Encode ticket text to embedding.\"\"\"\n        embeddings = self.token_embedding(token_ids)\n        encoded = self.encoder(embeddings, src_key_padding_mask=attention_mask)\n        # Mean pooling over sequence\n        pooled = encoded.mean(dim=1)\n        return F.normalize(self.pooler(pooled), p=2, dim=1)\n\n\nclass SemanticRouter:\n    \"\"\"Route tickets based on semantic similarity to category exemplars.\"\"\"\n    def __init__(self, encoder: nn.Module, categories: dict[str, list]):\n        self.encoder = encoder\n        self.category_centroids = {}\n        self._build_centroids(categories)\n\n    def _build_centroids(self, categories: dict[str, list]):\n        \"\"\"Compute centroid embedding for each category.\"\"\"\n        for category, exemplar_ids in categories.items():\n            # In production: encode exemplar tickets, compute mean\n            self.category_centroids[category] = np.random.randn(256)\n\n    def route(self, ticket_embedding: np.ndarray, top_k: int = 3):\n        \"\"\"Route ticket to most similar categories.\"\"\"\n        similarities = {}\n        for category, centroid in self.category_centroids.items():\n            sim = np.dot(ticket_embedding, centroid) / (\n                np.linalg.norm(ticket_embedding) * np.linalg.norm(centroid)\n            )\n            similarities[category] = sim\n        return sorted(similarities.items(), key=lambda x: -x[1])[:top_k]\n\n\n# Usage example\nencoder = SupportEncoder()\nprint(\"Support encoder initialized\")\nprint(f\"Embedding dimension: 256\")\n\n# Demonstrate routing concept\ncategories = {\n    \"billing\": [\"exemplar_1\", \"exemplar_2\"],\n    \"technical\": [\"exemplar_3\", \"exemplar_4\"],\n    \"account\": [\"exemplar_5\", \"exemplar_6\"],\n    \"fraud\": [\"exemplar_7\", \"exemplar_8\"]\n}\nrouter = SemanticRouter(encoder, categories)\nsample_embedding = np.random.randn(256)\nroutes = router.route(sample_embedding)\nprint(f\"\\nSample routing results: {routes[:2]}\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nSupport encoder initialized\nEmbedding dimension: 256\n\nSample routing results: [('technical', np.float64(0.03360605429158048)), ('fraud', np.float64(-0.012102201202387697))]\n```\n:::\n:::\n\n\n:::{.callout-tip}\n## Customer Support Intelligence Best Practices\n\n**Semantic Routing:**\n\n- **Multi-label routing**: Tickets often span categories (billing + technical)\n- **Skill-based matching**: Route to agents with relevant expertise\n- **Load balancing**: Consider agent capacity alongside semantic match\n- **Escalation prediction**: Identify tickets likely to escalate early\n\n**Knowledge Retrieval:**\n\n- **Dense retrieval**: Find relevant articles without exact keyword match\n- **Solution transfer**: Apply resolutions from similar past tickets\n- **Agent assist**: Surface relevant info during live interactions\n- **Auto-suggest**: Propose responses for agent review\n\n**Analytics:**\n\n- **Issue clustering**: Discover emerging problems automatically\n- **Root cause analysis**: Link symptoms to underlying causes\n- **Customer journey**: Track issues across channels and time\n- **Satisfaction prediction**: Predict CSAT from ticket embeddings\n\n**Scale Considerations:**\n\n- **Millions of tickets**: Incremental index updates, not full rebuilds\n- **Real-time routing**: <100ms for routing decisions\n- **Multi-language**: Cross-lingual embeddings for global support\n- **Privacy**: PII handling for regulated industries\n:::\n\n### Industry Applications of Support Intelligence\n\n- **Financial Services** (@sec-financial-services): Compliance-aware routing, fraud escalation, regulatory inquiry handling\n- **Healthcare** (@sec-healthcare-life-sciences): HIPAA-compliant support, clinical vs. billing separation, urgent care routing\n- **Retail** (@sec-retail-ecommerce): Order status, returns processing, loyalty program support\n- **Telecommunications**: Network issues, service changes, billing disputes\n\n## Competitive Intelligence\n\nOrganizations must monitor competitors, track market trends, and identify emerging opportunities. **Embedding-based competitive intelligence** processes vast amounts of unstructured data—news, patents, SEC filings, social media, job postings—to surface actionable insights that would be impossible to find manually.\n\n### The Intelligence Challenge\n\nTraditional competitive intelligence faces limitations:\n\n- **Volume**: Too much information to read manually\n- **Noise**: Most content is irrelevant or redundant\n- **Latency**: By the time analysts find it, it's old news\n- **Connections**: Hard to link signals across sources\n\n**Embedding approach**: Encode all sources into a unified semantic space. Monitor for clusters (emerging trends), anomalies (breaking news), and trajectories (strategic shifts). See @sec-semantic-search for retrieval and @sec-recommendation-systems for personalized alerting.\n\n::: {#7560e150 .cell execution_count=5}\n``` {.python .cell-code code-fold=\"true\" code-summary=\"Show Competitive Intelligence System\"}\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport numpy as np\nfrom dataclasses import dataclass\nfrom datetime import datetime\nfrom typing import Optional\n\n\n@dataclass\nclass IntelDocument:\n    \"\"\"Document from intelligence feed.\"\"\"\n    doc_id: str\n    source: str  # news, patent, filing, social, jobs\n    timestamp: datetime\n    text: str\n    entities: list[str]  # companies, people, products mentioned\n    embedding: Optional[np.ndarray] = None\n\n\nclass TrendDetector:\n    \"\"\"Detect emerging trends from document embeddings.\"\"\"\n    def __init__(self, embedding_dim: int = 384, window_days: int = 7):\n        self.embedding_dim = embedding_dim\n        self.window_days = window_days\n        self.cluster_centroids = []\n        self.cluster_sizes = []\n\n    def detect_emerging_clusters(self, recent_embeddings: np.ndarray,\n                                 historical_centroids: np.ndarray,\n                                 threshold: float = 0.3):\n        \"\"\"Find document clusters that don't match historical patterns.\"\"\"\n        emerging = []\n        # Simple clustering simulation\n        n_clusters = min(10, len(recent_embeddings) // 10)\n        for i in range(n_clusters):\n            cluster_centroid = recent_embeddings[i * 10:(i + 1) * 10].mean(axis=0)\n            # Check distance to all historical centroids\n            if len(historical_centroids) > 0:\n                max_sim = max(\n                    np.dot(cluster_centroid, hist) / (\n                        np.linalg.norm(cluster_centroid) * np.linalg.norm(hist)\n                    )\n                    for hist in historical_centroids\n                )\n                if max_sim < threshold:\n                    emerging.append({\n                        'centroid': cluster_centroid,\n                        'novelty_score': 1 - max_sim,\n                        'size': 10\n                    })\n        return emerging\n\n\nclass CompetitorTracker:\n    \"\"\"Track competitor activities through embedding trajectories.\"\"\"\n    def __init__(self, competitors: list[str]):\n        self.competitors = competitors\n        self.trajectories = {c: [] for c in competitors}\n\n    def update_trajectory(self, competitor: str,\n                          embedding: np.ndarray, timestamp: datetime):\n        \"\"\"Add new data point to competitor trajectory.\"\"\"\n        self.trajectories[competitor].append({\n            'embedding': embedding,\n            'timestamp': timestamp\n        })\n\n    def detect_strategic_shift(self, competitor: str,\n                               window: int = 30) -> Optional[dict]:\n        \"\"\"Detect if competitor's focus has shifted.\"\"\"\n        trajectory = self.trajectories.get(competitor, [])\n        if len(trajectory) < window * 2:\n            return None\n\n        # Compare recent centroid to historical centroid\n        recent = np.mean([t['embedding'] for t in trajectory[-window:]], axis=0)\n        historical = np.mean([t['embedding'] for t in trajectory[-window*2:-window]], axis=0)\n\n        shift_magnitude = np.linalg.norm(recent - historical)\n        if shift_magnitude > 0.5:  # Threshold\n            return {\n                'competitor': competitor,\n                'shift_magnitude': shift_magnitude,\n                'direction': recent - historical\n            }\n        return None\n\n\n# Usage example\nprint(\"=== Competitive Intelligence System ===\")\n\n# Trend detection\ndetector = TrendDetector()\nrecent = np.random.randn(100, 384)  # 100 recent documents\nhistorical = np.random.randn(50, 384)  # 50 historical cluster centroids\nemerging = detector.detect_emerging_clusters(recent, historical)\nprint(f\"\\nEmerging trends detected: {len(emerging)}\")\n\n# Competitor tracking\ntracker = CompetitorTracker(['CompetitorA', 'CompetitorB', 'CompetitorC'])\nprint(f\"Tracking {len(tracker.competitors)} competitors\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n=== Competitive Intelligence System ===\n\nEmerging trends detected: 10\nTracking 3 competitors\n```\n:::\n:::\n\n\n:::{.callout-tip}\n## Competitive Intelligence Best Practices\n\n**Data Sources:**\n\n- **News & Press**: Product launches, partnerships, executive changes\n- **Patents**: R&D direction, technology bets, acquisition targets\n- **SEC Filings**: Strategy statements, risk factors, segment performance\n- **Job Postings**: Hiring trends reveal strategic priorities\n- **Social Media**: Sentiment, product feedback, crisis indicators\n\n**Analysis Patterns:**\n\n- **Entity linking**: Connect mentions across sources (company aliases, subsidiaries)\n- **Event detection**: Identify significant events (launches, acquisitions, lawsuits)\n- **Sentiment tracking**: Monitor perception over time\n- **Relationship mapping**: Who partners with whom, who competes where\n\n**Alerting:**\n\n- **Semantic alerts**: \"Notify me about AI chip developments\" (not keyword \"AI chip\")\n- **Competitor alerts**: Any significant activity from tracked competitors\n- **Anomaly alerts**: Unusual volume or sentiment patterns\n- **Personalized feeds**: Different stakeholders need different views\n\n**Scale Considerations:**\n\n- **Millions of documents/day**: Streaming ingestion and embedding\n- **Real-time updates**: Hours matter for breaking news\n- **Global coverage**: Multi-language processing\n- **Historical analysis**: Years of data for trend analysis\n:::\n\n### Industry Applications of Competitive Intelligence\n\n- **Financial Services** (@sec-financial-services): Market moving news, regulatory changes, fintech monitoring\n- **Healthcare** (@sec-healthcare-life-sciences): Clinical trial tracking, drug approval monitoring, competitor pipelines\n- **Retail** (@sec-retail-ecommerce): Pricing intelligence, product launches, market expansion signals\n- **Manufacturing** (@sec-manufacturing-industry40): Supply chain disruptions, technology trends, trade policy impacts\n\n## Document Classification and Compliance\n\nEvery organization processes documents that must be classified, routed, and retained according to policies. **Embedding-based document intelligence** automates classification at scale, ensures compliance with retention policies, and surfaces relevant documents for legal and regulatory requests.\n\n### The Document Challenge\n\nOrganizations struggle with document management:\n\n- **Volume**: Millions of documents across email, files, chat, contracts\n- **Inconsistency**: Manual classification is error-prone and inconsistent\n- **Compliance risk**: Misclassified documents create legal exposure\n- **Discovery cost**: Finding relevant documents for litigation is expensive\n\n**Embedding approach**: Encode all documents into semantic space. Classification becomes nearest-neighbor to labeled exemplars. Compliance rules apply to embedding regions. Discovery queries semantic similarity, not just keywords.\n\n::: {#7d675f89 .cell execution_count=6}\n``` {.python .cell-code code-fold=\"true\" code-summary=\"Show Document Classification System\"}\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport numpy as np\nfrom dataclasses import dataclass\nfrom typing import Optional\nfrom datetime import datetime\n\n\n@dataclass\nclass Document:\n    \"\"\"Enterprise document with classification metadata.\"\"\"\n    doc_id: str\n    content: str\n    doc_type: Optional[str] = None  # contract, email, report, etc.\n    sensitivity: Optional[str] = None  # public, internal, confidential, restricted\n    retention_class: Optional[str] = None\n    embedding: Optional[np.ndarray] = None\n\n\nclass DocumentClassifier:\n    \"\"\"Classify documents using embedding similarity.\"\"\"\n    def __init__(self, embedding_dim: int = 384):\n        self.embedding_dim = embedding_dim\n        self.class_exemplars = {}  # class -> list of exemplar embeddings\n        self.class_centroids = {}  # class -> centroid embedding\n\n    def add_exemplar(self, class_name: str, embedding: np.ndarray):\n        \"\"\"Add labeled exemplar for a class.\"\"\"\n        if class_name not in self.class_exemplars:\n            self.class_exemplars[class_name] = []\n        self.class_exemplars[class_name].append(embedding)\n        # Update centroid\n        self.class_centroids[class_name] = np.mean(\n            self.class_exemplars[class_name], axis=0\n        )\n\n    def classify(self, embedding: np.ndarray,\n                 top_k: int = 3) -> list[tuple[str, float]]:\n        \"\"\"Classify document by similarity to class centroids.\"\"\"\n        similarities = []\n        for class_name, centroid in self.class_centroids.items():\n            sim = np.dot(embedding, centroid) / (\n                np.linalg.norm(embedding) * np.linalg.norm(centroid)\n            )\n            similarities.append((class_name, float(sim)))\n        return sorted(similarities, key=lambda x: -x[1])[:top_k]\n\n\nclass ComplianceEngine:\n    \"\"\"Apply compliance rules based on document classification.\"\"\"\n    def __init__(self):\n        self.retention_rules = {\n            'contract': {'years': 7, 'legal_hold': True},\n            'financial': {'years': 7, 'legal_hold': True},\n            'hr_record': {'years': 5, 'legal_hold': False},\n            'correspondence': {'years': 3, 'legal_hold': False},\n            'marketing': {'years': 1, 'legal_hold': False}\n        }\n        self.sensitivity_rules = {\n            'pii': 'confidential',\n            'phi': 'restricted',\n            'financial': 'confidential',\n            'trade_secret': 'restricted'\n        }\n\n    def apply_retention(self, doc: Document) -> dict:\n        \"\"\"Determine retention requirements.\"\"\"\n        rule = self.retention_rules.get(\n            doc.doc_type, {'years': 3, 'legal_hold': False}\n        )\n        return {\n            'doc_id': doc.doc_id,\n            'retention_years': rule['years'],\n            'legal_hold_eligible': rule['legal_hold'],\n            'destroy_after': datetime.now().year + rule['years']\n        }\n\n\nclass LegalDiscovery:\n    \"\"\"Support e-discovery with semantic search.\"\"\"\n    def __init__(self, classifier: DocumentClassifier):\n        self.classifier = classifier\n        self.document_index = {}  # doc_id -> embedding\n\n    def add_document(self, doc_id: str, embedding: np.ndarray):\n        \"\"\"Index document for discovery.\"\"\"\n        self.document_index[doc_id] = embedding\n\n    def semantic_search(self, query_embedding: np.ndarray,\n                        top_k: int = 100) -> list[tuple[str, float]]:\n        \"\"\"Find documents semantically similar to query.\"\"\"\n        results = []\n        for doc_id, doc_emb in self.document_index.items():\n            sim = np.dot(query_embedding, doc_emb) / (\n                np.linalg.norm(query_embedding) * np.linalg.norm(doc_emb)\n            )\n            results.append((doc_id, float(sim)))\n        return sorted(results, key=lambda x: -x[1])[:top_k]\n\n\n# Usage example\nprint(\"=== Document Classification & Compliance ===\")\n\n# Setup classifier with exemplars\nclassifier = DocumentClassifier()\nfor doc_type in ['contract', 'financial', 'hr_record', 'correspondence']:\n    for _ in range(5):  # 5 exemplars per class\n        classifier.add_exemplar(doc_type, np.random.randn(384))\n\n# Classify new document\nnew_doc_embedding = np.random.randn(384)\nclassifications = classifier.classify(new_doc_embedding)\nprint(f\"\\nDocument classifications: {classifications[:2]}\")\n\n# Apply compliance\ncompliance = ComplianceEngine()\ndoc = Document(doc_id=\"DOC001\", content=\"...\", doc_type=classifications[0][0])\nretention = compliance.apply_retention(doc)\nprint(f\"Retention policy: {retention['retention_years']} years\")\n\n# Legal discovery\ndiscovery = LegalDiscovery(classifier)\nfor i in range(100):\n    discovery.add_document(f\"DOC{i:03d}\", np.random.randn(384))\nquery = np.random.randn(384)\nresults = discovery.semantic_search(query, top_k=5)\nprint(f\"Discovery results: {len(results)} documents\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n=== Document Classification & Compliance ===\n\nDocument classifications: [('financial', 0.03846613266304179), ('correspondence', -0.04459407483284109)]\nRetention policy: 7 years\nDiscovery results: 5 documents\n```\n:::\n:::\n\n\n:::{.callout-tip}\n## Document Classification Best Practices\n\n**Classification:**\n\n- **Multi-label**: Documents often have multiple applicable classes\n- **Hierarchical**: Type → Subtype → Specific category\n- **Confidence thresholds**: Route low-confidence to human review\n- **Active learning**: Prioritize uncertain documents for labeling\n\n**Compliance:**\n\n- **Retention automation**: Apply policies based on classification\n- **Legal holds**: Suspend deletion for litigation-relevant documents\n- **Audit trails**: Track all classification and retention decisions\n- **Policy updates**: Reclassify when policies change\n\n**Discovery:**\n\n- **Semantic search**: Find relevant documents beyond keywords\n- **Concept clustering**: Group related documents for review\n- **Privilege detection**: Flag potentially privileged communications\n- **Deduplication**: Identify near-duplicates to reduce review volume\n\n**Scale Considerations:**\n\n- **Billions of documents**: Incremental processing, not batch\n- **Multi-format**: Email, Office docs, PDFs, images (OCR)\n- **Multi-language**: Global organizations need cross-lingual support\n- **Performance**: Classification must not slow document workflows\n:::\n\n### Industry Applications of Document Classification\n\n- **Financial Services** (@sec-financial-services): Regulatory filings, trading communications, audit documents\n- **Healthcare** (@sec-healthcare-life-sciences): Clinical documentation, HIPAA compliance, medical records retention\n- **Legal**: Case files, contracts, correspondence, privilege review\n- **Government**: FOIA requests, classification levels, records management\n\n## Key Takeaways\n\n- **Cybersecurity threat hunting with embeddings detects zero-day attacks**: Unlike classifiers limited to known attack patterns, embedding-based systems identify \"behavior unlike anything normal,\" enabling detection of novel threats without prior examples\n\n- **Behavioral anomaly detection learns per-entity baselines**: Sequential models (LSTM, Transformer) over user/device event streams learn individual behavior patterns, flagging account compromise and insider threats through deviation from established patterns\n\n- **Embedding-driven business rules replace brittle if-then logic**: Case-based reasoning retrieves similar historical cases and applies their outcomes, adapting automatically as new cases arrive without retraining, while hybrid systems enforce hard regulatory constraints alongside learned patterns\n\n- **These patterns apply universally across all industries**: Every organization faces cyber threats, has users whose behavior should be monitored, and makes decisions that can benefit from embeddings—subsequent industry chapters build on these foundations\n\n- **Online learning is critical for production systems**: Attackers evolve tactics, user behavior changes, business conditions shift—systems must incrementally update embeddings and thresholds to avoid degrading accuracy over time\n\n- **Explainability enables adoption**: High false positive rates create user friction and alert fatigue, requiring feature attribution to help analysts understand anomalies and progressive authentication to balance security and usability\n\n- **Customer support intelligence transforms unstructured interactions into actionable data**: Semantic routing matches tickets to agents based on meaning rather than keywords, while knowledge retrieval surfaces relevant solutions from historical resolutions and documentation\n\n- **Competitive intelligence scales through embedding-based monitoring**: Trend detection identifies emerging clusters in news and patent filings, while competitor tracking measures strategic shifts through embedding trajectory analysis across millions of documents\n\n- **Document classification enables automated compliance at scale**: Embedding similarity to labeled exemplars provides consistent classification across billions of documents, with automated retention policies and semantic search for e-discovery reducing legal risk and review costs\n\n## Looking Ahead\n\nThe next chapter, @sec-video-surveillance, covers another critical cross-industry application: video surveillance and analytics—from retail loss prevention to smart city safety to industrial compliance monitoring—generating more embedding vectors than almost any other domain.\n\nFollowing video surveillance, @sec-entity-resolution addresses a fundamental cross-industry challenge: identifying and linking records that refer to the same real-world entities across disparate data sources—a problem that scales to trillions of comparison pairs.\n\nThe remaining chapters in Part V explore industry-specific applications:\n\n- @sec-financial-services applies these patterns to trading, credit risk, and regulatory compliance\n- @sec-healthcare-life-sciences addresses patient safety, clinical decision support, and medical data security\n- @sec-retail-ecommerce covers dynamic pricing, inventory optimization, and customer journey analysis\n- @sec-manufacturing-industry40 explores quality control, predictive maintenance, and supply chain optimization\n\n## Further Reading\n\n### Cybersecurity and Threat Detection\n- Sommer, Robin, and Vern Paxson (2010). \"Outside the Closed World: On Using Machine Learning for Network Intrusion Detection.\" IEEE S&P.\n- Tuor, Aaron, et al. (2017). \"Deep Learning for Unsupervised Insider Threat Detection in Structured Cybersecurity Data Streams.\" AAAI Workshop.\n- Ding, Kaize, et al. (2019). \"Deep Anomaly Detection on Attributed Networks.\" SDM.\n- Yuan, Shuhan, et al. (2019). \"Insider Threat Detection with Deep Neural Network.\" CODASPY.\n\n### Behavioral Anomaly Detection\n- Xu, Ke, et al. (2018). \"Show, Attend and Tell: Neural Image Caption Generation with Visual Attention Applied to Insider Threat Detection.\" Journal of Wireless Mobile Networks.\n- Das, Sanmitra, et al. (2019). \"Online Multimodal Deep Similarity Learning with Application to Insider Threat Detection.\" ACM TOPS.\n- Legg, Philip A., et al. (2015). \"Automated Insider Threat Detection System Using User and Role-Based Profile Assessment.\" IEEE Systems Journal.\n- Liu, Lin, et al. (2018). \"GEM: Graph Embedding for Insider Threat Detection.\" IEEE BigData.\n\n### Automated Decision Systems\n- Brynjolfsson, Erik, and Andrew McAfee (2017). \"The Business of Artificial Intelligence.\" Harvard Business Review.\n- Kleinberg, Jon, et al. (2018). \"Human Decisions and Machine Predictions.\" Quarterly Journal of Economics.\n- Mullainathan, Sendhil, and Jann Spiess (2017). \"Machine Learning: An Applied Econometric Approach.\" Journal of Economic Perspectives.\n\n### Explainability and Fairness\n- Lundberg, Scott M., and Su-In Lee (2017). \"A Unified Approach to Interpreting Model Predictions.\" NeurIPS.\n- Ribeiro, Marco Tulio, Sameer Singh, and Carlos Guestrin (2016). \"Why Should I Trust You? Explaining the Predictions of Any Classifier.\" KDD.\n- Mehrabi, Ninareh, et al. (2021). \"A Survey on Bias and Fairness in Machine Learning.\" ACM Computing Surveys.\n\n",
    "supporting": [
      "ch22_cross_industry_patterns_files"
    ],
    "filters": [],
    "includes": {}
  }
}