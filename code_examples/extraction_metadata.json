{
  "total_files": 253,
  "total_lines": 66908,
  "chapters": {
    "ch01": {
      "name": "foundations",
      "file_count": 16,
      "files": [
        "traditional_update.py",
        "keyword_search.py",
        "example_03.py",
        "example_04.py",
        "example_05.py",
        "example_06.py",
        "answer_question_with_rag.py",
        "example_08.py",
        "example_09.py",
        "example_10.py",
        "calculate_search_roi.py",
        "calculate_efficiency_roi.py",
        "calculate_fraud_roi.py",
        "calculate_ltv_improvement.py",
        "risk_adjusted_roi.py",
        "embeddingroicalculator.py"
      ],
      "imports": [
        "distributed_index",
        "gensim",
        "math",
        "sentence_transformers",
        "sklearn"
      ]
    },
    "ch02": {
      "name": "strategic_architecture",
      "file_count": 30,
      "files": [
        "embeddingbusinessmetrics.py",
        "embeddingdataaudit.py",
        "embeddingstrategyroadmap.py",
        "embeddingstrategyvalidator.py",
        "example_05.py",
        "example_06.py",
        "multimodalembeddingsystem.py",
        "modalityfusion.py",
        "multimodaltraining.py",
        "multimodalindex.py",
        "example_11.py",
        "index_video.py",
        "embed_product.py",
        "modalitybalancing.py",
        "modalityqualityweighting.py",
        "efficientmultimodalencoding.py",
        "embeddingdatagovernance.py",
        "embeddingmodelregistry.py",
        "embeddingexplainability.py",
        "embeddingbiasmonitor.py",
        "embeddingaccesscontrol.py",
        "embeddingcomplianceframework.py",
        "embeddingcostmodel.py",
        "dimensionreducer.py",
        "embeddingquantization.py",
        "tieredembeddingstorage.py",
        "embeddingcompression.py",
        "sparseembeddings.py",
        "buildvsbuydecisionframework.py",
        "vectordbevaluation.py"
      ],
      "imports": [
        "cryptography",
        "faiss",
        "math",
        "sklearn"
      ]
    },
    "ch03": {
      "name": "vector_database_fundamentals",
      "file_count": 21,
      "files": [
        "find_customer.py",
        "vectordatabasephilosophy.py",
        "geometricintuition.py",
        "hierarchicalnavigation.py",
        "indexstructurecomparison.py",
        "productionvectordatabasearchitecture.py",
        "ecommercevectordbarchitecture.py",
        "scaleconstraints.py",
        "hnswdeepdive.py",
        "trillionscalehnsw.py",
        "ivfpqstrategy.py",
        "ivfpqtradeoffs.py",
        "shardingpatterns.py",
        "vectordatabasecap.py",
        "replicationstrategies.py",
        "failurerecovery.py",
        "coordinationpatterns.py",
        "vectordatabaseslas.py",
        "vectordatabasebenchmark.py",
        "loadtestingstrategy.py",
        "globaldistributionarchitecture.py"
      ],
      "imports": [
        "math",
        "numpy",
        "sklearn",
        "time"
      ]
    },
    "ch04": {
      "name": "custom_embedding_strategies",
      "file_count": 19,
      "files": [
        "customembeddingdecisionframework.py",
        "embeddingfinetuner.py",
        "semanticgranularity.py",
        "asymmetricsimilarity.py",
        "multifacetedembeddings.py",
        "temporalembeddings.py",
        "hierarchicalembeddings.py",
        "domainspecificobjectives.py",
        "multitaskembeddingmodel.py",
        "multivectorembedding.py",
        "constrainedembeddingobjective.py",
        "multiobjectiveoptimization.py",
        "dimensionalityexperiment.py",
        "intrinsicdimensionality.py",
        "progressivedimensionreduction.py",
        "binaryembeddings.py",
        "embeddingtco.py",
        "costperformancefrontier.py",
        "tieredembeddings.py"
      ],
      "imports": [
        "matplotlib",
        "numpy",
        "sentence_transformers",
        "sklearn",
        "torch"
      ]
    },
    "ch05": {
      "name": "contrastive_learning",
      "file_count": 21,
      "files": [
        "infonceloss.py",
        "temperatureanalysis.py",
        "tripletloss.py",
        "ntxentloss.py",
        "alignmentuniformityanalysis.py",
        "simclrtextembedding.py",
        "mocotextembedding.py",
        "multimodalcontrastive.py",
        "domainadaptedcontrastive.py",
        "contrastivedataset.py",
        "inbatchhardnegativemining.py",
        "queuebasedhardnegativemining.py",
        "offlinehardnegativemining.py",
        "debiasedhardnegativemining.py",
        "gradientaccumulationcontrastive.py",
        "distributedcontrastivelearning.py",
        "mixedprecisioncontrastive.py",
        "smartbatchsampler.py",
        "multinodecontrastivelearning.py",
        "memoryefficientcontrastive.py",
        "communicationefficientdistributed.py"
      ],
      "imports": [
        "collections",
        "faiss",
        "matplotlib",
        "nltk",
        "numpy",
        "openai",
        "os",
        "random",
        "sklearn",
        "torch",
        "transformers"
      ]
    },
    "ch06": {
      "name": "siamese_networks",
      "file_count": 13,
      "files": [
        "siamesenetwork.py",
        "contrastiveloss.py",
        "enterpriseoptimizedsiamesenetwork.py",
        "tripletloss.py",
        "advancedtripletloss.py",
        "balancedbatchsampler.py",
        "oneshotclassifier.py",
        "prototypicalnetworkclassifier.py",
        "thresholdcalibrator.py",
        "adaptivethresholdmanager.py",
        "siameseembeddingservice.py",
        "siameseannservice.py",
        "multistageverificationpipeline.py"
      ],
      "imports": [
        "faiss",
        "functools",
        "hashlib",
        "matplotlib",
        "numpy",
        "torch",
        "torchvision",
        "transformers"
      ]
    },
    "ch07": {
      "name": "self_supervised_learning",
      "file_count": 8,
      "files": [
        "selfsupervisedembeddingframework.py",
        "enterpriseselfsupervisedpipeline.py",
        "domainspecificmlm.py",
        "advancedmlm.py",
        "maskedautoencodervit.py",
        "industrialdefectdetection.py",
        "timeseriesselfsupervised.py",
        "multimodalselfsupervised.py"
      ],
      "imports": [
        "datasets",
        "numpy",
        "tokenizers",
        "torch",
        "torchvision",
        "transformers"
      ]
    },
    "ch08": {
      "name": "advanced_embedding_techniques",
      "file_count": 11,
      "files": [
        "hyperbolicembedding.py",
        "hierarchicalproductrecommender.py",
        "embed_medical_ontology.py",
        "dynamicembedding.py",
        "streamingembeddingservice.py",
        "compositionalembedding.py",
        "taskadaptivecomposition.py",
        "probabilisticembedding.py",
        "federatedembeddingserver.py",
        "differentiallyprivateembedding.py",
        "secureaggregation.py"
      ],
      "imports": [
        "copy",
        "datetime",
        "numpy",
        "torch"
      ]
    },
    "ch09": {
      "name": "embedding_pipeline_engineering",
      "file_count": 6,
      "files": [
        "from.py",
        "hybridembeddingsystem.py",
        "deploymentstrategy.py",
        "example_04.py",
        "from_1.py",
        "import.py"
      ],
      "imports": [
        "asyncio",
        "collections",
        "dataclasses",
        "datetime",
        "enum",
        "hashlib",
        "json",
        "numpy",
        "torch",
        "typing"
      ]
    },
    "ch10": {
      "name": "scaling_embedding_training",
      "file_count": 10,
      "files": [
        "distributedembeddingtable.py",
        "gradientaccumulationtrainer.py",
        "mixedprecisiontrainer.py",
        "example_04.py",
        "checkpointedtransformerlayer.py",
        "memoryefficientoptimizer.py",
        "embeddingdataset.py",
        "setup_multi_node.py",
        "from.py",
        "spotinstancetrainer.py"
      ],
      "imports": [
        "bitsandbytes",
        "dataclasses",
        "math",
        "numpy",
        "os",
        "pathlib",
        "signal",
        "time",
        "torch",
        "typing"
      ]
    },
    "ch11": {
      "name": "high_performance_vector_ops",
      "file_count": 5,
      "files": [
        "import.py",
        "ivfindex.py",
        "gpuvectorsearch.py",
        "memorymappedvectorstore.py",
        "class.py"
      ],
      "imports": [
        "collections",
        "concurrent",
        "dataclasses",
        "heapq",
        "numpy",
        "os",
        "pathlib",
        "queue",
        "threading",
        "time",
        "torch",
        "typing"
      ]
    },
    "ch12": {
      "name": "data_engineering",
      "file_count": 5,
      "files": [
        "from.py",
        "class.py",
        "from_1.py",
        "from_2.py",
        "from_3.py"
      ],
      "imports": [
        "asyncio",
        "collections",
        "dataclasses",
        "datetime",
        "enum",
        "hashlib",
        "json",
        "numpy",
        "pandas",
        "pathlib",
        "queue",
        "threading",
        "time",
        "typing"
      ]
    },
    "ch13": {
      "name": "rag_at_scale",
      "file_count": 5,
      "files": [
        "from.py",
        "passageextractor.py",
        "multistageretriever.py",
        "from_1.py",
        "from_2.py"
      ],
      "imports": [
        "collections",
        "dataclasses",
        "datetime",
        "numpy",
        "re",
        "time",
        "typing"
      ]
    },
    "ch14": {
      "name": "semantic_search",
      "file_count": 5,
      "files": [
        "from.py",
        "import.py",
        "from_1.py",
        "from_2.py",
        "import_1.py"
      ],
      "imports": [
        "PIL",
        "ast",
        "dataclasses",
        "datetime",
        "io",
        "numpy",
        "re",
        "torch",
        "typing"
      ]
    },
    "ch15": {
      "name": "recommendation_systems",
      "file_count": 5,
      "files": [
        "from.py",
        "class.py",
        "from_1.py",
        "from_2.py",
        "crossdomainrecommender.py"
      ],
      "imports": [
        "collections",
        "dataclasses",
        "numpy",
        "random",
        "time",
        "torch",
        "typing"
      ]
    },
    "ch16": {
      "name": "anomaly_detection_security",
      "file_count": 5,
      "files": [
        "from.py",
        "from_1.py",
        "from_2.py",
        "class.py",
        "behavioral_anomaly_example.py"
      ],
      "imports": [
        "PIL",
        "collections",
        "dataclasses",
        "datetime",
        "numpy",
        "time",
        "torch",
        "typing"
      ]
    },
    "ch17": {
      "name": "automated_decision_systems",
      "file_count": 5,
      "files": [
        "from.py",
        "class.py",
        "class_1.py",
        "class_2.py",
        "class_3.py"
      ],
      "imports": [
        "dataclasses",
        "datetime",
        "numpy",
        "random",
        "torch",
        "typing"
      ]
    },
    "ch18": {
      "name": "financial_services",
      "file_count": 5,
      "files": [
        "from.py",
        "class.py",
        "class_1.py",
        "class_2.py",
        "class_3.py"
      ],
      "imports": [
        "dataclasses",
        "datetime",
        "numpy",
        "time",
        "torch",
        "typing"
      ]
    },
    "ch19": {
      "name": "healthcare_life_sciences",
      "file_count": 5,
      "files": [
        "from.py",
        "class.py",
        "class_1.py",
        "class_2.py",
        "class_3.py"
      ],
      "imports": [
        "dataclasses",
        "datetime",
        "numpy",
        "random",
        "torch",
        "typing"
      ]
    },
    "ch20": {
      "name": "retail_ecommerce",
      "file_count": 5,
      "files": [
        "class.py",
        "styleattribute.py",
        "demandregime.py",
        "actiontype.py",
        "productrelationtype.py"
      ],
      "imports": [
        "collections",
        "dataclasses",
        "datetime",
        "enum",
        "json",
        "numpy",
        "torch",
        "typing"
      ]
    },
    "ch21": {
      "name": "manufacturing_industry40",
      "file_count": 5,
      "files": [
        "class.py",
        "risklevel.py",
        "machinestatus.py",
        "processstatus.py",
        "class_1.py"
      ],
      "imports": [
        "collections",
        "dataclasses",
        "datetime",
        "enum",
        "numpy",
        "torch",
        "typing"
      ]
    },
    "ch22": {
      "name": "media_entertainment",
      "file_count": 5,
      "files": [
        "class.py",
        "class_1.py",
        "class_2.py",
        "class_3.py",
        "class_4.py"
      ],
      "imports": [
        "dataclasses",
        "datetime",
        "json",
        "numpy",
        "sklearn",
        "torch",
        "typing"
      ]
    },
    "ch23": {
      "name": "performance_optimization",
      "file_count": 5,
      "files": [
        "class.py",
        "class_1.py",
        "class_2.py",
        "class_3.py",
        "class_4.py"
      ],
      "imports": [
        "collections",
        "dataclasses",
        "datetime",
        "hashlib",
        "heapq",
        "json",
        "numpy",
        "sklearn",
        "struct",
        "time",
        "torch",
        "typing"
      ]
    },
    "ch24": {
      "name": "security_privacy",
      "file_count": 5,
      "files": [
        "class.py",
        "class_1.py",
        "class_2.py",
        "permission.py",
        "dataregion.py"
      ],
      "imports": [
        "abc",
        "collections",
        "dataclasses",
        "datetime",
        "enum",
        "hashlib",
        "hmac",
        "json",
        "math",
        "numpy",
        "secrets",
        "time",
        "torch",
        "typing"
      ]
    },
    "ch25": {
      "name": "monitoring_observability",
      "file_count": 5,
      "files": [
        "class.py",
        "metrictype.py",
        "class_1.py",
        "class_2.py",
        "class_3.py"
      ],
      "imports": [
        "collections",
        "dataclasses",
        "datetime",
        "enum",
        "json",
        "matplotlib",
        "numpy",
        "random",
        "scipy",
        "sklearn",
        "threading",
        "time",
        "typing",
        "warnings"
      ]
    },
    "ch26": {
      "name": "future_trends",
      "file_count": 9,
      "files": [
        "quantumbackend.py",
        "class.py",
        "quantumembeddingtrainer.py",
        "neuronmodel.py",
        "stdplearning.py",
        "devicetype.py",
        "blockchainnetwork.py",
        "from.py",
        "humanaicollaboration.py"
      ],
      "imports": [
        "abc",
        "collections",
        "dataclasses",
        "datetime",
        "dwave",
        "enum",
        "hashlib",
        "json",
        "numpy",
        "scipy",
        "sklearn",
        "time",
        "typing"
      ]
    },
    "ch27": {
      "name": "organizational_transformation",
      "file_count": 5,
      "files": [
        "capability.py",
        "stakeholderrole.py",
        "learningtrack.py",
        "vendorcategory.py",
        "metriccategory.py"
      ],
      "imports": [
        "dataclasses",
        "datetime",
        "enum",
        "json",
        "typing"
      ]
    },
    "ch28": {
      "name": "implementation_roadmap",
      "file_count": 4,
      "files": [
        "technologycategory.py",
        "deploymentstage.py",
        "region.py",
        "innovationtype.py"
      ],
      "imports": [
        "dataclasses",
        "datetime",
        "enum",
        "json",
        "typing"
      ]
    },
    "ch30": {
      "name": "path_forward",
      "file_count": 5,
      "files": [
        "dataassettype.py",
        "innovationstage.py",
        "partnershiptype.py",
        "disruptioncategory.py",
        "transformationstage.py"
      ],
      "imports": [
        "collections",
        "dataclasses",
        "datetime",
        "enum",
        "numpy",
        "typing"
      ]
    }
  },
  "all_imports": [
    "PIL",
    "abc",
    "ast",
    "asyncio",
    "bitsandbytes",
    "collections",
    "concurrent",
    "copy",
    "cryptography",
    "dataclasses",
    "datasets",
    "datetime",
    "distributed_index",
    "dwave",
    "enum",
    "faiss",
    "functools",
    "gensim",
    "hashlib",
    "heapq",
    "hmac",
    "io",
    "json",
    "math",
    "matplotlib",
    "nltk",
    "numpy",
    "openai",
    "os",
    "pandas",
    "pathlib",
    "queue",
    "random",
    "re",
    "scipy",
    "secrets",
    "sentence_transformers",
    "signal",
    "sklearn",
    "struct",
    "threading",
    "time",
    "tokenizers",
    "torch",
    "torchvision",
    "transformers",
    "typing",
    "warnings"
  ]
}