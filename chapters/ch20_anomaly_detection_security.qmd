# Anomaly Detection and Security {#sec-anomaly-detection-security}

:::{.callout-note}
## Chapter Overview
Anomaly detection identifies rare, suspicious patterns that deviate from normal behavior—critical for fraud prevention, security monitoring, and quality control. This chapter applies embeddings to security and anomaly detection at scale: fraud detection systems that identify unusual transaction patterns through outliers in embedding space, cybersecurity threat hunting using behavioral embeddings of users and network entities to detect compromises, manufacturing quality control with product embeddings that flag defects through deviation from normal specifications, financial risk assessment via company and transaction embeddings that identify elevated risk profiles, and behavioral anomaly detection that flags account takeovers and insider threats by measuring drift from established embedding patterns. These techniques transform anomaly detection from rule-based systems to learned representations that adapt to evolving threats.
:::

After building recommendation systems (@sec-recommendation-systems), embeddings enable a fundamentally different approach to **anomaly detection**. Traditional anomaly detection relies on hand-crafted rules (if transaction amount > $10K, flag), statistical thresholds (flag values beyond 3σ), or supervised classifiers (requires labeled anomalies). **Embedding-based anomaly detection** learns normal behavior as dense clusters in embedding space, then identifies anomalies as points far from any cluster—enabling unsupervised detection, adaptation to concept drift, and detection of novel attack patterns never seen before.

## Embedding-Based Fraud Detection

Financial fraud costs billions annually, with attackers constantly evolving tactics. **Embedding-based fraud detection** represents transactions, users, and merchants as vectors, identifying fraud as outliers in learned embedding spaces—detecting both known fraud patterns and novel attacks.

### The Fraud Detection Challenge

Traditional fraud detection faces limitations:

- **Rule-based systems**: Brittle, high false positives, easy to circumvent
- **Supervised learning**: Requires labeled fraud (rare, expensive), can't detect novel attacks
- **Feature engineering**: Manual, domain-specific, doesn't capture complex patterns

**Embedding approach**: Learn transaction embeddings capturing behavior patterns. Normal transactions cluster together; fraud transactions lie in sparse regions or form small, distinct clusters. See @sec-custom-embedding-strategies for guidance on building these embeddings, and @sec-contrastive-learning for training techniques that learn to distinguish normal from anomalous patterns.

```python
{{< include /code_examples/ch20_anomaly_detection_security/from.py >}}
```

:::{.callout-tip}
## Fraud Detection Best Practices

**Architecture:**

- **Autoencoder approach**: Train on normal transactions, high reconstruction error = fraud
- **Entity embeddings**: Learn user/merchant representations (fraud users form distinct clusters)
- **Sequential modeling**: LSTM over transaction history (flag deviations from normal sequence)
- **Graph embeddings**: Capture money laundering rings (abnormal network patterns)

**Training:**

- **Clean training data**: Remove known fraud from training (autoencoders learn normal patterns only)
- **Imbalanced data**: Expect 99%+ normal transactions
- **Online learning**: Update embeddings daily with new normal transactions
- **Hard negative mining**: Sample edge cases (high-value normal transactions) (see @sec-contrastive-learning)

**Production:**

- **Latency**: <50ms for real-time blocking
- **Explainability**: SHAP values on features causing high score
- **Threshold tuning**: Balance false positives (user friction) vs false negatives (fraud losses)
- **A/B testing**: Measure impact on fraud reduction and user experience
:::

:::{.callout-warning}
## False Positive Management

Fraud detection faces extreme class imbalance (0.1% fraud rate). High false positive rates create user friction:

- Block legitimate transaction → user frustration, lost sales
- Alert user for verification → abandonment, support costs

**Mitigation strategies:**

- **Two-stage system**: High-recall first stage (flag suspicious), high-precision second stage (human review)
- **Progressive friction**: Soft decline (ask for additional verification) before hard decline
- **User whitelist**: Trust established users with consistent behavior
- **Feedback loop**: Incorporate user feedback (approved flagged transactions)

**Target metrics:**

- Precision: 30-50% (of flagged transactions, 30-50% are actual fraud)
- Recall: 70-90% (catch 70-90% of fraud)
- False positive rate: <0.5% (flag <0.5% of normal transactions)
:::

## Cybersecurity Threat Hunting

Cybersecurity teams hunt for threats—APTs, compromised accounts, insider threats—in massive logs. **Embedding-based threat hunting** learns behavioral embeddings of users, devices, and network entities, detecting anomalies that indicate compromise or malicious activity.

### The Threat Hunting Challenge

Traditional Security Information and Event Management (SIEM) systems use rules:

- Rule: If user logs in from new country, alert
- Rule: If outbound data transfer > 10GB, alert

**Limitations:**

- High false positives (legitimate travel, legitimate data transfers)
- Evasion: Attackers split transfers, use slow exfiltration
- Cannot detect novel attacks (zero-day exploits, new TTPs)

**The Zero-Day Argument**: The most compelling case for embeddings in security is **zero-day detection**. A classifier can only recognize attack patterns present in its training data. An embedding system can detect "this behavior is unlike anything normal I've seen" without ever having seen that specific attack.

```python
# Classifier limitation: only knows trained attack types
attack_types = ['sql_injection', 'xss', 'credential_stuffing']  # Fixed at training time

# Embedding advantage: detects deviation from normal
if distance_to_nearest_normal_cluster > threshold:
    alert("Anomalous behavior detected")  # Works for novel attacks
```

**Embedding approach**: Learn normal behavior embeddings for each user/device. Anomalies = deviation from learned patterns. See @sec-custom-embedding-strategies for approaches to building behavioral embeddings, from fine-tuning pre-trained models to custom architectures.

```python
{{< include /code_examples/ch20_anomaly_detection_security/from_1.py >}}
```

:::{.callout-tip}
## Threat Hunting Best Practices

**Baselines:**

- **Per-user baselines**: Each user has unique normal behavior
- **Per-device baselines**: Each device has characteristic patterns
- **Time-aware**: Behavior varies by time of day, day of week
- **Context-aware**: Location, VPN usage, remote vs office

**Features:**

- **Login patterns**: Time, location, device, success/failure rate
- **File access**: Paths accessed, read/write/delete ratios
- **Network activity**: Connections, data volumes, destinations
- **Process execution**: Binaries run, arguments, parent processes

**Detection:**

- **Sequential anomalies**: Unusual sequence of events (login → sensitive file → large upload)
- **Statistical anomalies**: Unusual frequency, volume, or timing
- **Behavioral drift**: Gradual change in behavior (slow compromise)
- **Peer group analysis**: Deviation from similar users (same role, department)

**Production:**

- **Low latency**: <1 second for real-time alerting
- **Prioritization**: Rank alerts by severity (combine multiple signals)
- **Investigation workflow**: Provide context for analysts (what's unusual, why)
- **Feedback loop**: Incorporate analyst decisions (true positive, false positive)
:::

## Manufacturing Quality Control

Manufacturing produces millions of units, with defects causing recalls and safety issues. **Embedding-based quality control** represents products as vectors from sensor data, images, and measurements, detecting defects as outliers from normal specifications.

### The Quality Control Challenge

Traditional quality control uses thresholds:

- If dimension < 10mm or > 12mm, reject
- If surface roughness > 0.5µm, reject

**Limitations:**

- High dimensional data (100+ measurements)
- Correlated features (defects manifest as combinations of features)
- Rare defects (< 0.1%) missed by simple thresholds

**Embedding approach**: Learn product embeddings from sensor/image data. Normal products cluster tightly; defects are outliers. See @sec-custom-embedding-strategies for guidance on choosing between pre-trained and custom embeddings for your domain.

```python
{{< include /code_examples/ch20_anomaly_detection_security/from_2.py >}}
```

:::{.callout-tip}
## Quality Control Best Practices

**Data collection:**

- **Multi-modal**: Combine sensor measurements, images, process parameters
- **High frequency**: Inspect every product (100% inspection)
- **Temporal**: Track drift over time (machine wear, calibration)
- **Provenance**: Link to production line, shift, machine

**Modeling:**

- **Unsupervised**: Defects are rare, labeled data limited
- **Cluster-based**: Normal products form tight cluster
- **Autoencoder**: Reconstruct normal products, high error = defect
- **One-class SVM**: Learn boundary around normal products

**Production:**

- **Real-time**: Inspect at line speed (milliseconds per product)
- **Inline integration**: Automatic rejection of defects
- **Root cause analysis**: Identify which features are abnormal
- **Process control**: Alert when cluster drifts (machine degradation)

**Evaluation:**

- **Precision**: % of flagged products that are true defects
- **Recall**: % of true defects that are flagged
- **Cost analysis**: False positive cost (wasted product) vs false negative cost (recalls)
:::

## Financial Risk Assessment

Financial institutions assess risk for loans, investments, and insurance. **Embedding-based risk assessment** represents companies, individuals, and transactions as vectors, identifying elevated risk through learned representations and relationships.

### The Risk Assessment Challenge

Traditional risk models use scores (credit score, financial ratios):

- Credit score = f(payment history, debt, income)
- Default risk = f(debt-to-income ratio, assets)

**Limitations:**

- Linear models miss complex interactions
- Sparse data for new entities (thin credit files)
- Cannot capture network effects (company relationships, supply chain risk)

**Embedding approach**: Learn entity embeddings from financial data, network relationships, and behavioral patterns. Risk propagates through networks. See @sec-custom-embedding-strategies for the decision framework on building domain-specific embeddings.

```python
{{< include /code_examples/ch20_anomaly_detection_security/class.py >}}
```

:::{.callout-tip}
## Risk Assessment Best Practices

**Features:**

- **Financial ratios**: Debt-to-income, debt-to-equity, liquidity ratios
- **Behavioral**: Payment history, transaction patterns, volatility
- **Network**: Relationships, supply chain dependencies, contagion risk
- **Macroeconomic**: Industry trends, economic indicators

**Modeling:**

- **Multi-task learning**: Jointly predict default, delinquency, prepayment
- **Temporal**: Time-varying embeddings (risk changes over time)
- **Explainability**: SHAP values for regulatory compliance
- **Calibration**: Predicted probabilities match observed frequencies

**Production:**

- **Real-time**: Score loan applications in seconds
- **Batch**: Portfolio risk assessment overnight
- **Monitoring**: Track model drift (economic conditions change)
- **Backtesting**: Validate on historical defaults

**Fairness:**

- **Protected attributes**: Avoid bias on race, gender, age
- **Disparate impact**: Equal false positive rates across groups
- **Regulatory compliance**: Fair lending laws (ECOA, FCRA)
:::

## Behavioral Anomaly Detection

User accounts can be compromised (phishing, credential stuffing) or misused (insider threats). **Behavioral anomaly detection** learns normal user behavior embeddings, flagging deviations that indicate account takeover or malicious activity.

### The Behavioral Challenge

Users exhibit consistent patterns:

- Login times (weekdays 9-5)
- Devices (laptop, phone)
- Actions (emails, file access)

**Account compromise changes behavior**:

- Login from new location/device
- Unusual actions (access sensitive files, bulk downloads)
- Velocity changes (sudden spike in activity)

**Challenge**: Detect deviations while adapting to legitimate behavior changes (new job, new phone).

```python
{{< include /code_examples/ch20_anomaly_detection_security/behavioral_anomaly_example.py >}}
```

:::{.callout-tip}
## Behavioral Anomaly Best Practices

**Features:**

- **Temporal**: Time of day, day of week, session duration
- **Spatial**: Location (IP geolocation), VPN usage
- **Device**: Browser, OS, screen resolution (fingerprinting)
- **Actions**: Pages visited, features used, API calls made
- **Velocity**: Actions per minute, data transferred

**Modeling:**

- **Per-user baselines**: Each user has unique normal behavior
- **LSTM**: Sequential modeling of user actions
- **Autoencoder**: Reconstruct behavior, high error = anomaly
- **Peer groups**: Compare to similar users (same role)

**Production:**

- **Real-time**: Flag suspicious sessions immediately
- **Progressive authentication**: Challenge anomalous sessions (2FA, security questions)
- **Adaptive baselines**: Update with confirmed normal behavior
- **False positive management**: Avoid blocking legitimate users

**Challenges:**

- **Cold start**: New users have no baseline
- **Concept drift**: Behavior changes over time (new role, new tools)
- **Adversarial**: Attackers mimic normal behavior (slow compromise)
:::

## Key Takeaways

- **Embedding-based anomaly detection learns normal behavior as dense clusters**: Anomalies manifest as outliers far from normal clusters, enabling unsupervised detection of novel attacks and fraud patterns never seen during training

- **Autoencoders provide effective unsupervised anomaly detection**: Training on normal transactions to minimize reconstruction error creates detectors where high error indicates fraud, bypassing the need for labeled anomaly examples

- **Behavioral embeddings enable threat hunting at scale**: Sequential models (LSTM, Transformer) over user/device event streams learn typical behavior patterns, with deviations flagging account compromise, insider threats, and lateral movement

- **Manufacturing quality control benefits from multi-modal embeddings**: Combining sensor measurements and images in unified embeddings detects complex defect patterns that simple threshold-based systems miss, achieving sub-0.1% defect rates

- **Financial risk propagates through network embeddings**: Graph neural networks on transaction and relationship networks capture contagion risk and identify entities at elevated risk through network position and relationships

- **Online learning is critical for production anomaly detection**: Attackers evolve tactics, manufacturing processes drift, user behavior changes—systems must incrementally update embeddings and thresholds to avoid degrading accuracy over time

- **Explainability and false positive management determine adoption**: High false positive rates create user friction and alert fatigue, requiring SHAP-style feature attribution to help analysts understand anomalies and progressive authentication to balance security and usability

## Looking Ahead

Part IV (Advanced Applications) continues with Chapter 17, which explores automated decision systems powered by embeddings: embedding-driven business rules that replace hand-crafted logic with learned patterns, dynamic pricing systems that optimize prices based on learned product and customer embeddings, supply chain optimization using facility and route embeddings to minimize costs, risk scoring and underwriting with entity embeddings for credit and insurance decisions, and predictive maintenance systems that use equipment embeddings to forecast failures and schedule interventions before breakdowns occur.

## Further Reading

### Fraud Detection
- Cheng, Dawei, et al. (2020). "Graph Neural Network for Fraud Detection via Spatial-temporal Attention." IEEE TKDE.
- Van Vlasselaer, Véronique, et al. (2015). "APATE: A Novel Approach for Automated Credit Card Transaction Fraud Detection using Network-based Extensions." Decision Support Systems.
- Abdallah, Ali, et al. (2016). "Fraud Detection System: A Survey." Journal of Network and Computer Applications.
- Wang, Daixin, et al. (2019). "A Semi-supervised Graph Attentive Network for Financial Fraud Detection." ICDM.

### Cybersecurity and Threat Detection
- Sommer, Robin, and Vern Paxson (2010). "Outside the Closed World: On Using Machine Learning for Network Intrusion Detection." IEEE S&P.
- Tuor, Aaron, et al. (2017). "Deep Learning for Unsupervised Insider Threat Detection in Structured Cybersecurity Data Streams." AAAI Workshop.
- Ding, Kaize, et al. (2019). "Deep Anomaly Detection on Attributed Networks." SDM.
- Yuan, Shuhan, et al. (2019). "Insider Threat Detection with Deep Neural Network." CODASPY.

### Manufacturing Quality Control
- Weimer, Daniel, et al. (2016). "Design of Deep Convolutional Neural Network Architectures for Automated Feature Extraction in Industrial Inspection." CIRP Annals.
- Wang, Jenq-Neng, et al. (2018). "Autoencoder-based Anomaly Detection for Surface Defect Inspection." Advanced Engineering Informatics.
- Fink, Olga, et al. (2020). "Potential, Challenges and Future Directions for Deep Learning in Prognostics and Health Management Applications." Engineering Applications of Artificial Intelligence.
- Tercan, Hasan, and Tobias Meisen (2022). "Machine Learning and Deep Learning Based Predictive Quality in Manufacturing: A Systematic Review." Journal of Intelligent Manufacturing.

### Financial Risk Assessment
- Khandani, Amir E., Adlar J. Kim, and Andrew W. Lo (2010). "Consumer Credit-Risk Models via Machine-Learning Algorithms." Journal of Banking & Finance.
- Barboza, Flavio, et al. (2017). "Machine Learning Models and Bankruptcy Prediction." Expert Systems with Applications.
- Moscato, Valentina, et al. (2021). "A Benchmark of Machine Learning Approaches for Credit Score Prediction." Expert Systems with Applications.
- Addo, Peter Martey, Dominique Guegan, and Bertrand Hassani (2018). "Credit Risk Analysis Using Machine and Deep Learning Models." Risks.

### Behavioral Anomaly Detection
- Xu, Ke, et al. (2018). "Show, Attend and Tell: Neural Image Caption Generation with Visual Attention Applied to Insider Threat Detection." Journal of Wireless Mobile Networks.
- Das, Sanmitra, et al. (2019). "Online Multimodal Deep Similarity Learning with Application to Insider Threat Detection." ACM TOPS.
- Legg, Philip A., et al. (2015). "Automated Insider Threat Detection System Using User and Role-Based Profile Assessment." IEEE Systems Journal.
- Liu, Lin, et al. (2018). "GEM: Graph Embedding for Insider Threat Detection." IEEE BigData.
