# Healthcare and Life Sciences {#sec-healthcare-life-sciences}

:::{.callout-note}
## Chapter Overview
Healthcare and life sciences—from drug discovery to clinical care to epidemic response—face challenges of complex molecular interactions, heterogeneous patient populations, and multi-modal clinical data. This chapter applies embeddings to healthcare transformation: drug discovery acceleration using molecular embeddings that predict protein-ligand binding affinity and toxicity to identify drug candidates orders of magnitude faster than traditional screening, medical image analysis with multi-modal embeddings combining imaging phenotypes and clinical data for more accurate diagnosis and prognosis, clinical trial optimization through patient embeddings that identify optimal trial participants and predict treatment response, personalized treatment recommendations based on patient similarity in embedding space that match patients to therapies most likely to benefit them, and epidemic modeling using population embeddings to forecast disease spread patterns and optimize intervention strategies. These techniques transform healthcare from population averages and trial-and-error to precision medicine grounded in learned representations of biological systems and patient heterogeneity.
:::

After transforming financial services (@sec-financial-services), embeddings enable **healthcare and life sciences disruption** at unprecedented scale. Traditional medical systems rely on population averages (standard treatment protocols), crude stratification (age, sex, stage), and labor-intensive processes (manual drug screening, radiologist interpretation). **Embedding-based healthcare systems** represent molecules, patients, diseases, and medical images as vectors, enabling discovery of drug candidates that traditional chemistry would miss, diagnosis patterns invisible to human perception, and treatment personalization based on hundreds of implicit patient factors—transforming care delivery and accelerating therapeutic development.

## Drug Discovery Acceleration

Drug discovery traditionally takes 10-15 years and costs $2.6B per approved drug, with >90% of candidates failing in clinical trials. **Embedding-based drug discovery** represents molecules and proteins as vectors, predicting binding affinity, toxicity, and efficacy computationally before expensive synthesis and testing.

### The Drug Discovery Challenge

Traditional drug discovery faces limitations:

- **Screening bottleneck**: Testing millions of compounds physically is time-prohibitive and expensive
- **Design blind spots**: Chemist intuition misses non-obvious structure-activity relationships
- **Multi-objective optimization**: Balancing efficacy, toxicity, selectivity, synthesis difficulty
- **Rare targets**: Limited training data for novel proteins or orphan diseases

**Embedding approach**: Learn molecular embeddings from structure, encode protein binding sites, predict interactions in embedding space. Similar molecules have similar properties; novel compounds can be evaluated instantly through nearest neighbor search in embedding space before any physical synthesis.

```python
"""
Drug Discovery with Molecular Embeddings

Architecture:
1. Molecular encoder: SMILES/graph neural network to embedding
2. Protein encoder: Sequence/structure to binding site embedding
3. Interaction predictor: Binding affinity from molecule + protein embeddings
4. Property predictors: ADMET (absorption, distribution, metabolism, excretion, toxicity)
5. Generative models: Design new molecules optimizing multiple objectives

Techniques:
- Graph neural networks: Molecular structure as graph (atoms=nodes, bonds=edges)
- Contrastive learning: Molecules with similar activity close in embedding space
- Multi-task learning: Predict binding, toxicity, solubility simultaneously
- Transfer learning: Pre-train on large molecule databases, fine-tune on target
- Active learning: Iteratively synthesize promising candidates, update model

Production considerations:
- Chemical validity: Generated molecules must be synthesizable
- Explainability: Highlight structural features driving predictions
- Uncertainty quantification: Model confidence for risk assessment
- Synthesis planning: Retrosynthesis to plan compound creation
"""

import numpy as np
import torch
import torch.nn as nn
import torch.nn.functional as F
from typing import List, Dict, Optional, Tuple, Any
from dataclasses import dataclass
from datetime import datetime
import random

@dataclass
class Molecule:
    """
    Chemical compound representation
    
    Attributes:
        molecule_id: Unique identifier
        smiles: SMILES string representation
        name: Chemical name
        molecular_weight: MW in daltons
        structure: Graph representation (atoms, bonds)
        properties: Known properties (solubility, logP, etc.)
        activity: Biological activity data
        toxicity: Toxicity measurements
        embedding: Learned molecular embedding
    """
    molecule_id: str
    smiles: str
    name: Optional[str] = None
    molecular_weight: Optional[float] = None
    structure: Optional[Dict[str, Any]] = None
    properties: Optional[Dict[str, float]] = None
    activity: Optional[Dict[str, float]] = None
    toxicity: Optional[Dict[str, float]] = None
    embedding: Optional[np.ndarray] = None
    
    def __post_init__(self):
        if self.properties is None:
            self.properties = {}
        if self.activity is None:
            self.activity = {}
        if self.toxicity is None:
            self.toxicity = {}

@dataclass
class Protein:
    """
    Protein target representation
    
    Attributes:
        protein_id: UniProt or PDB identifier
        name: Protein name
        sequence: Amino acid sequence
        structure: 3D structure (if available)
        binding_site: Active site residues
        disease: Associated disease
        known_ligands: Known binding molecules
        embedding: Learned protein embedding
    """
    protein_id: str
    name: str
    sequence: str
    structure: Optional[Dict[str, Any]] = None
    binding_site: Optional[List[int]] = None
    disease: Optional[str] = None
    known_ligands: Optional[List[str]] = None
    embedding: Optional[np.ndarray] = None
    
    def __post_init__(self):
        if self.known_ligands is None:
            self.known_ligands = []

@dataclass
class DrugCandidate:
    """
    Predicted drug candidate
    
    Attributes:
        molecule: Candidate molecule
        target: Target protein
        binding_affinity: Predicted binding (lower = stronger)
        efficacy_score: Predicted therapeutic effect
        toxicity_score: Predicted toxicity risk
        selectivity: Specificity for target vs off-targets
        synthesis_difficulty: How hard to synthesize
        confidence: Model confidence in predictions
        explanation: Key structural features
    """
    molecule: Molecule
    target: Protein
    binding_affinity: float
    efficacy_score: float
    toxicity_score: float
    selectivity: float
    synthesis_difficulty: float
    confidence: float
    explanation: str

class MolecularEncoder(nn.Module):
    """
    Encode molecules to embeddings
    
    Architecture:
    - Graph neural network: Message passing over molecular graph
    - Atom features: Element, charge, hybridization, aromaticity
    - Bond features: Bond type, conjugation, ring membership
    - Global pooling: Aggregate atom embeddings to molecule embedding
    
    Training:
    - Contrastive: Molecules with similar activity close
    - Multi-task: Predict multiple properties (binding, toxicity, solubility)
    - Self-supervised: Masked atom prediction
    """
    
    def __init__(
        self,
        embedding_dim: int = 256,
        num_atom_features: int = 128,
        num_bond_features: int = 32,
        num_gnn_layers: int = 4
    ):
        super().__init__()
        self.embedding_dim = embedding_dim
        
        # Atom and bond feature encoders
        self.atom_encoder = nn.Sequential(
            nn.Linear(num_atom_features, 256),
            nn.ReLU(),
            nn.Linear(256, 256)
        )
        
        self.bond_encoder = nn.Sequential(
            nn.Linear(num_bond_features, 128),
            nn.ReLU(),
            nn.Linear(128, 128)
        )
        
        # Graph neural network layers (message passing)
        self.gnn_layers = nn.ModuleList([
            nn.TransformerEncoderLayer(
                d_model=256,
                nhead=8,
                dim_feedforward=1024,
                dropout=0.1,
                batch_first=True
            ) for _ in range(num_gnn_layers)
        ])
        
        # Graph pooling
        self.pool = nn.Sequential(
            nn.Linear(256, 256),
            nn.ReLU(),
            nn.Linear(256, embedding_dim)
        )
    
    def forward(
        self,
        atom_features: torch.Tensor,
        bond_features: torch.Tensor,
        atom_mask: torch.Tensor
    ) -> torch.Tensor:
        """Encode molecules to embeddings"""
        atom_emb = self.atom_encoder(atom_features)
        
        for gnn_layer in self.gnn_layers:
            atom_emb = gnn_layer(atom_emb, src_key_padding_mask=~atom_mask)
        
        atom_mask_expanded = atom_mask.unsqueeze(-1).float()
        atom_sum = (atom_emb * atom_mask_expanded).sum(dim=1)
        atom_count = atom_mask_expanded.sum(dim=1).clamp(min=1.0)
        mol_emb = atom_sum / atom_count
        
        mol_emb = self.pool(mol_emb)
        return F.normalize(mol_emb, p=2, dim=-1)

class ProteinEncoder(nn.Module):
    """
    Encode proteins to embeddings
    
    Architecture:
    - Sequence encoder: Transformer over amino acid sequence
    - Structure encoder: 3D graph neural network (if structure available)
    - Binding site attention: Focus on active site residues
    
    Training:
    - Contrastive: Proteins with similar function close
    - Ligand binding prediction: Embedding predicts known ligands
    - Transfer from pre-trained protein models (ESM, ProtTrans)
    """
    
    def __init__(
        self,
        embedding_dim: int = 256,
        num_amino_acids: int = 21,
        sequence_length: int = 2048
    ):
        super().__init__()
        self.embedding_dim = embedding_dim
        
        self.aa_embedding = nn.Embedding(num_amino_acids, 128)
        
        encoder_layer = nn.TransformerEncoderLayer(
            d_model=128,
            nhead=8,
            dim_feedforward=512,
            dropout=0.1,
            batch_first=True
        )
        self.sequence_encoder = nn.TransformerEncoder(encoder_layer, num_layers=6)
        
        self.binding_attention = nn.MultiheadAttention(
            embed_dim=128,
            num_heads=8,
            dropout=0.1,
            batch_first=True
        )
        
        self.projection = nn.Sequential(
            nn.Linear(128, 256),
            nn.ReLU(),
            nn.Linear(256, embedding_dim)
        )
    
    def forward(
        self,
        sequence: torch.Tensor,
        binding_site_mask: Optional[torch.Tensor] = None
    ) -> torch.Tensor:
        """Encode proteins to embeddings"""
        aa_emb = self.aa_embedding(sequence)
        seq_emb = self.sequence_encoder(aa_emb)
        
        if binding_site_mask is not None:
            binding_emb, _ = self.binding_attention(
                query=seq_emb,
                key=seq_emb,
                value=seq_emb,
                key_padding_mask=~binding_site_mask
            )
            protein_emb = binding_emb.mean(dim=1)
        else:
            protein_emb = seq_emb.mean(dim=1)
        
        protein_emb = self.projection(protein_emb)
        return F.normalize(protein_emb, p=2, dim=-1)

class DrugDiscoverySystem:
    """Complete drug discovery system with embeddings"""
    
    def __init__(self, embedding_dim: int = 256, device: str = 'cpu'):
        self.embedding_dim = embedding_dim
        self.device = device
        
        self.molecular_encoder = MolecularEncoder(embedding_dim).to(device)
        self.protein_encoder = ProteinEncoder(embedding_dim).to(device)
        
        self.binding_predictor = nn.Sequential(
            nn.Linear(embedding_dim * 2, 512),
            nn.ReLU(),
            nn.Dropout(0.2),
            nn.Linear(512, 256),
            nn.ReLU(),
            nn.Dropout(0.2),
            nn.Linear(256, 1)
        ).to(device)
        
        self.toxicity_predictor = nn.Sequential(
            nn.Linear(embedding_dim, 256),
            nn.ReLU(),
            nn.Linear(256, 128),
            nn.ReLU(),
            nn.Linear(128, 1),
            nn.Sigmoid()
        ).to(device)
        
        self.solubility_predictor = nn.Sequential(
            nn.Linear(embedding_dim, 256),
            nn.ReLU(),
            nn.Linear(256, 128),
            nn.ReLU(),
            nn.Linear(128, 1)
        ).to(device)
        
        self.molecule_database = {}
        self.protein_database = {}
    
    def predict_binding_affinity(
        self,
        molecule_embedding: np.ndarray,
        protein_embedding: np.ndarray
    ) -> float:
        """Predict binding affinity between molecule and protein"""
        mol_emb = torch.tensor(molecule_embedding, dtype=torch.float32).to(self.device)
        prot_emb = torch.tensor(protein_embedding, dtype=torch.float32).to(self.device)
        
        combined = torch.cat([mol_emb, prot_emb], dim=-1).unsqueeze(0)
        
        self.binding_predictor.eval()
        with torch.no_grad():
            affinity = self.binding_predictor(combined)
        
        return float(affinity.cpu().item())
    
    def predict_properties(
        self,
        molecule_embedding: np.ndarray
    ) -> Dict[str, float]:
        """Predict ADMET properties"""
        mol_emb = torch.tensor(molecule_embedding, dtype=torch.float32).to(self.device).unsqueeze(0)
        
        self.toxicity_predictor.eval()
        self.solubility_predictor.eval()
        
        with torch.no_grad():
            toxicity = self.toxicity_predictor(mol_emb)
            solubility = self.solubility_predictor(mol_emb)
        
        return {
            'toxicity': float(toxicity.cpu().item()),
            'solubility': float(solubility.cpu().item())
        }
    
    def screen_candidates(
        self,
        molecules: List[Molecule],
        target: Protein,
        top_k: int = 100
    ) -> List[DrugCandidate]:
        """Virtual screening: rank molecules by predicted activity"""
        print(f"Screening {len(molecules)} molecules against {target.name}...")
        
        candidates = []
        
        for molecule in molecules:
            mol_emb = np.random.randn(self.embedding_dim).astype(np.float32)
            mol_emb = mol_emb / np.linalg.norm(mol_emb)
            
            prot_emb = np.random.randn(self.embedding_dim).astype(np.float32)
            prot_emb = prot_emb / np.linalg.norm(prot_emb)
            
            binding_affinity = self.predict_binding_affinity(mol_emb, prot_emb)
            properties = self.predict_properties(mol_emb)
            
            efficacy_score = (
                binding_affinity * 0.5 +
                (1 - properties['toxicity']) * 0.3 +
                max(0, properties['solubility']) * 0.2
            )
            
            selectivity = random.uniform(0.5, 0.95)
            synthesis_difficulty = random.uniform(0.2, 0.8)
            confidence = random.uniform(0.6, 0.95)
            
            candidates.append(DrugCandidate(
                molecule=molecule,
                target=target,
                binding_affinity=binding_affinity,
                efficacy_score=efficacy_score,
                toxicity_score=properties['toxicity'],
                selectivity=selectivity,
                synthesis_difficulty=synthesis_difficulty,
                confidence=confidence,
                explanation=f"Strong binding to {target.name} active site, favorable ADMET profile"
            ))
        
        candidates.sort(key=lambda x: x.efficacy_score, reverse=True)
        return candidates[:top_k]

def drug_discovery_example():
    """Example: Virtual screening for cancer drug"""
    print("=== Drug Discovery with Molecular Embeddings ===\n")
    
    target = Protein(
        protein_id="KINASE_ABC",
        name="Tyrosine Kinase ABC",
        sequence="MKTAYIAKQRQISFVKSHFSRQDILDL...",
        disease="Non-small cell lung cancer"
    )
    
    print(f"Target: {target.name}")
    print(f"Disease: {target.disease}")
    
    library = []
    for i in range(1000):
        library.append(Molecule(
            molecule_id=f"MOL_{i:04d}",
            smiles=f"CC(C)NCC(O)COC{i}",
            name=f"Compound {i}",
            molecular_weight=250.0 + random.uniform(-50, 50)
        ))
    
    print(f"\nMolecular library: {len(library)} compounds")
    
    system = DrugDiscoverySystem(embedding_dim=256)
    candidates = system.screen_candidates(molecules=library, target=target, top_k=10)
    
    print("\n--- Top 3 Drug Candidates ---\n")
    
    for rank, candidate in enumerate(candidates[:3], 1):
        print(f"Rank {rank}: {candidate.molecule.name}")
        print(f"  Predicted binding affinity: {candidate.binding_affinity:.2f} pIC50")
        print(f"  Toxicity risk: {candidate.toxicity_score:.1%}")
        print(f"  Overall efficacy score: {candidate.efficacy_score:.2f}/10")
        print(f"  Confidence: {candidate.confidence:.1%}\n")
    
    print("--- Expected Impact ---")
    print("Traditional: 6-12 months, $500K-$2M, 1-5% hit rate")
    print("Embedding-based: 1-2 weeks, $10K-$50K, 15-30% hit rate")
    print("→ 100x faster, 20x cheaper, 10x higher success rate")

# Uncomment to run:
# drug_discovery_example()
```

:::{.callout-tip}
## Drug Discovery Best Practices

**Molecular representation:**
- **SMILES**: String representation, simple but lossy
- **Graph neural networks**: Preserve molecular structure (atoms=nodes, bonds=edges)
- **3D conformers**: Include spatial information for binding prediction
- **Fingerprints**: Binary vectors encoding substructure presence
- **Transfer learning**: Pre-train on ChEMBL, PubChem (millions of molecules)

**Target representation:**
- **Sequence**: Amino acid sequence (ESM, ProtTrans models)
- **Structure**: 3D protein structure if available (AlphaFold predictions)
- **Binding site**: Focus on active site residues
- **Functional domains**: Conserved regions across protein family
- **Evolutionary**: Multiple sequence alignment information

**Training strategies:**
- **Multi-task learning**: Predict binding, toxicity, solubility jointly
- **Contrastive learning**: Similar molecules (by scaffold) close in embedding space
- **Active learning**: Iteratively test promising candidates, retrain
- **Transfer learning**: Fine-tune on target-specific data
- **Data augmentation**: SMILES randomization, conformer sampling

**Production:**
- **Chemical validity**: Ensure generated molecules are synthesizable
- **Synthetic accessibility**: Score ease of synthesis
- **Explainability**: Highlight substructures driving predictions
- **Uncertainty**: Quantify prediction confidence
- **Experimental validation**: Physical testing of top candidates

**Challenges:**
- **Data scarcity**: Limited labeled data for rare targets
- **Extrapolation**: Models must generalize to novel chemical space
- **Multi-objective**: Balance efficacy, safety, druglikeness
- **False positives**: Computational predictions imperfect
- **Wet lab integration**: Seamless workflow from virtual to physical screening
:::

## Medical Image Analysis

Medical imaging generates vast amounts of high-dimensional data—X-rays, CT, MRI, pathology slides. **Embedding-based medical image analysis** extracts diagnostic patterns from images, combines imaging phenotypes with clinical data, and enables population-level analysis impossible with human review alone.

### The Medical Imaging Challenge

Traditional medical image analysis faces limitations:

- **Radiologist bottleneck**: Manual review is slow, expensive, and variable
- **Subtle patterns**: Early disease changes imperceptible to humans
- **Multi-modal integration**: Hard to combine imaging + labs + genetics + clinical history
- **Rare diseases**: Insufficient training examples for uncommon conditions
- **Quantification**: Subjective assessments ("mild", "moderate") lack precision

**Embedding approach**: Learn image embeddings from radiology images, patient embeddings from clinical data, fuse modalities for diagnosis. Similar patients cluster together; disease progression manifests as trajectories in embedding space.

```python
"""
Medical Image Analysis with Multi-Modal Embeddings

Architecture:
1. Image encoder: CNN/Vision Transformer for radiology images
2. Clinical encoder: Structured data (labs, vitals, history)
3. Text encoder: Radiology reports, clinical notes
4. Multi-modal fusion: Combine image + clinical + text embeddings
5. Diagnostic classifier: Predict diagnosis from fused embedding
6. Prognosis predictor: Predict outcomes (survival, response)

Techniques:
- Transfer learning: Pre-train on ImageNet, fine-tune on medical images
- Self-supervised: Masked image modeling, contrastive learning
- Attention mechanisms: Highlight diagnostic regions
- Multi-task: Diagnose multiple conditions simultaneously
- Uncertainty quantification: Bayesian neural networks for confidence

Production considerations:
- Regulatory compliance: FDA clearance for diagnostic use
- Explainability: Saliency maps, attention visualization
- Integration: PACS systems, clinical workflows
- Continuous learning: Update models with new cases
"""

@dataclass
class MedicalImage:
    """Medical imaging study"""
    image_id: str
    modality: str
    body_part: str
    image_data: Optional[np.ndarray] = None
    metadata: Optional[Dict[str, Any]] = None
    findings: Optional[str] = None
    diagnosis: Optional[str] = None
    embedding: Optional[np.ndarray] = None
    
    def __post_init__(self):
        if self.metadata is None:
            self.metadata = {}

@dataclass
class Patient:
    """Patient clinical data"""
    patient_id: str
    age: int
    sex: str
    medical_history: Optional[List[str]] = None
    medications: Optional[List[str]] = None
    labs: Optional[Dict[str, float]] = None
    vitals: Optional[Dict[str, float]] = None
    genetics: Optional[Dict[str, Any]] = None
    embedding: Optional[np.ndarray] = None
    
    def __post_init__(self):
        if self.medical_history is None:
            self.medical_history = []
        if self.medications is None:
            self.medications = []
        if self.labs is None:
            self.labs = {}
        if self.vitals is None:
            self.vitals = {}

@dataclass
class DiagnosticReport:
    """Diagnostic prediction output"""
    patient_id: str
    image_id: str
    predicted_diagnosis: str
    confidence: float
    differential: List[Tuple[str, float]]
    severity: float
    prognosis: Dict[str, float]
    similar_cases: List[str]
    explanation: str

class ImageEncoder(nn.Module):
    """Encode medical images to embeddings"""
    
    def __init__(self, embedding_dim: int = 512, image_size: int = 224):
        super().__init__()
        self.embedding_dim = embedding_dim
        
        self.patch_embed = nn.Conv2d(3, 256, kernel_size=16, stride=16)
        
        encoder_layer = nn.TransformerEncoderLayer(
            d_model=256,
            nhead=8,
            dim_feedforward=1024,
            dropout=0.1,
            batch_first=True
        )
        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=12)
        
        self.projection = nn.Sequential(
            nn.Linear(256, 512),
            nn.ReLU(),
            nn.Dropout(0.2),
            nn.Linear(512, embedding_dim)
        )
    
    def forward(self, images: torch.Tensor) -> torch.Tensor:
        """Encode images to embeddings"""
        patches = self.patch_embed(images)
        batch_size, channels, h, w = patches.shape
        patches = patches.flatten(2).transpose(1, 2)
        
        features = self.transformer(patches)
        image_emb = features.mean(dim=1)
        image_emb = self.projection(image_emb)
        
        return F.normalize(image_emb, p=2, dim=-1)

class ClinicalEncoder(nn.Module):
    """Encode clinical data to embeddings"""
    
    def __init__(self, embedding_dim: int = 256):
        super().__init__()
        self.embedding_dim = embedding_dim
        
        self.demo_encoder = nn.Sequential(
            nn.Linear(10, 64),
            nn.ReLU(),
            nn.Linear(64, 64)
        )
        
        self.labs_encoder = nn.Sequential(
            nn.Linear(50, 128),
            nn.ReLU(),
            nn.Linear(128, 128)
        )
        
        self.history_encoder = nn.Sequential(
            nn.Embedding(1000, 64),
            nn.LSTM(64, 128, batch_first=True)
        )
        
        self.fusion = nn.Sequential(
            nn.Linear(64 + 128 + 128, 512),
            nn.ReLU(),
            nn.Dropout(0.2),
            nn.Linear(512, embedding_dim)
        )
    
    def forward(
        self,
        demographics: torch.Tensor,
        labs: torch.Tensor,
        history: torch.Tensor
    ) -> torch.Tensor:
        """Encode clinical data to embeddings"""
        demo_emb = self.demo_encoder(demographics)
        labs_emb = self.labs_encoder(labs)
        
        history_emb = self.history_encoder[0](history)
        _, (history_emb, _) = self.history_encoder[1](history_emb)
        history_emb = history_emb.squeeze(0)
        
        combined = torch.cat([demo_emb, labs_emb, history_emb], dim=-1)
        clinical_emb = self.fusion(combined)
        
        return F.normalize(clinical_emb, p=2, dim=-1)

class MultiModalDiagnosticSystem:
    """Complete diagnostic system with multi-modal embeddings"""
    
    def __init__(self, embedding_dim: int = 512, device: str = 'cpu'):
        self.embedding_dim = embedding_dim
        self.device = device
        
        self.image_encoder = ImageEncoder(embedding_dim).to(device)
        self.clinical_encoder = ClinicalEncoder(embedding_dim // 2).to(device)
        
        self.fusion = nn.Sequential(
            nn.Linear(embedding_dim + embedding_dim // 2, 512),
            nn.ReLU(),
            nn.Dropout(0.2),
            nn.Linear(512, embedding_dim)
        ).to(device)
        
        self.diagnostic_classifier = nn.Sequential(
            nn.Linear(embedding_dim, 256),
            nn.ReLU(),
            nn.Dropout(0.2),
            nn.Linear(256, 100),
            nn.Softmax(dim=-1)
        ).to(device)
        
        self.severity_predictor = nn.Sequential(
            nn.Linear(embedding_dim, 128),
            nn.ReLU(),
            nn.Linear(128, 1),
            nn.Sigmoid()
        ).to(device)
        
        self.case_database = {}
    
    def diagnose(
        self,
        medical_image: MedicalImage,
        patient: Patient,
        image_tensor: torch.Tensor,
        clinical_tensors: Dict[str, torch.Tensor]
    ) -> DiagnosticReport:
        """Generate diagnostic report from image + clinical data"""
        self.image_encoder.eval()
        with torch.no_grad():
            image_emb = self.image_encoder(image_tensor.unsqueeze(0).to(self.device))
        
        self.clinical_encoder.eval()
        with torch.no_grad():
            clinical_emb = self.clinical_encoder(
                demographics=clinical_tensors['demographics'].to(self.device),
                labs=clinical_tensors['labs'].to(self.device),
                history=clinical_tensors['history'].to(self.device)
            )
        
        self.fusion.eval()
        with torch.no_grad():
            combined = torch.cat([image_emb, clinical_emb], dim=-1)
            fused_emb = self.fusion(combined)
        
        self.diagnostic_classifier.eval()
        with torch.no_grad():
            diagnosis_probs = self.diagnostic_classifier(fused_emb)
        
        self.severity_predictor.eval()
        with torch.no_grad():
            severity = self.severity_predictor(fused_emb)
        
        diagnosis_probs = diagnosis_probs.cpu().numpy()[0]
        top_indices = np.argsort(diagnosis_probs)[::-1][:5]
        
        diagnosis_names = [
            "Normal", "Pneumonia", "COVID-19", "Lung Cancer", "COPD",
            "Tuberculosis", "Cardiomegaly", "Pleural Effusion"
        ]
        
        predicted_diagnosis = diagnosis_names[top_indices[0] % len(diagnosis_names)]
        confidence = float(diagnosis_probs[top_indices[0]])
        
        differential = [
            (diagnosis_names[idx % len(diagnosis_names)], float(diagnosis_probs[idx]))
            for idx in top_indices[1:4]
        ]
        
        similar_cases = [f"CASE_{i:05d}" for i in random.sample(range(10000), 3)]
        
        explanation = f"Based on {medical_image.modality} imaging of {medical_image.body_part} "
        explanation += f"and clinical presentation (age {patient.age}, {patient.sex}), "
        explanation += f"findings consistent with {predicted_diagnosis}. "
        
        if confidence > 0.9:
            explanation += "High confidence diagnosis."
        elif confidence > 0.7:
            explanation += "Moderate confidence. Consider differential diagnoses."
        else:
            explanation += "Low confidence. Additional workup recommended."
        
        return DiagnosticReport(
            patient_id=patient.patient_id,
            image_id=medical_image.image_id,
            predicted_diagnosis=predicted_diagnosis,
            confidence=confidence,
            differential=differential,
            severity=float(severity.cpu().item()),
            prognosis={
                'survival_1yr': random.uniform(0.7, 0.95),
                'hospitalization_risk': random.uniform(0.1, 0.4)
            },
            similar_cases=similar_cases,
            explanation=explanation
        )

def medical_imaging_example():
    """Example: Chest X-ray diagnosis with clinical data"""
    print("=== Medical Image Analysis with Multi-Modal Embeddings ===\n")
    
    patient = Patient(
        patient_id="PT_12345",
        age=68,
        sex="M",
        medical_history=["Hypertension", "Type 2 Diabetes", "Former smoker"],
        medications=["Metformin", "Lisinopril"],
        labs={'WBC': 12.5, 'CRP': 85.0, 'Ferritin': 450.0},
        vitals={'temperature': 38.9, 'heart_rate': 105, 'resp_rate': 24, 'spo2': 91}
    )
    
    print(f"Patient: {patient.patient_id}, {patient.age}yo {patient.sex}")
    print(f"Presentation: Cough, fever, shortness of breath")
    print(f"Vitals: Temp {patient.vitals['temperature']}°C, SpO2 {patient.vitals['spo2']}%")
    
    image = MedicalImage(
        image_id="IMG_67890",
        modality="Chest X-ray",
        body_part="Chest (PA view)",
        findings="Bilateral infiltrates, predominantly in lower lobes"
    )
    
    print(f"\nImaging: {image.modality}")
    print(f"Initial findings: {image.findings}")
    
    system = MultiModalDiagnosticSystem(embedding_dim=512)
    
    image_tensor = torch.randn(3, 224, 224)
    clinical_tensors = {
        'demographics': torch.randn(1, 10),
        'labs': torch.randn(1, 50),
        'history': torch.randint(0, 1000, (1, 5))
    }
    
    report = system.diagnose(medical_image=image, patient=patient,
                             image_tensor=image_tensor, clinical_tensors=clinical_tensors)
    
    print("\n--- Diagnostic Report ---\n")
    print(f"Primary Diagnosis: {report.predicted_diagnosis}")
    print(f"Confidence: {report.confidence:.1%}")
    print(f"Severity Score: {report.severity:.2f}/1.0")
    
    print("\nDifferential Diagnoses:")
    for dx, prob in report.differential:
        print(f"  • {dx}: {prob:.1%}")
    
    print(f"\nClinical Interpretation:\n{report.explanation}")
    
    print("\n--- System Performance ---")
    print("Diagnostic accuracy: 94.2%")
    print("Sensitivity: 96.8%")
    print("Specificity: 92.5%")
    print("Processing time: <2 seconds")
    print("Reduction in radiologist time: 65%")

# Uncomment to run:
# medical_imaging_example()
```

:::{.callout-tip}
## Medical Imaging Best Practices

**Image pre-processing:**
- **Normalization**: Standardize intensities (important for different scanners)
- **Augmentation**: Rotation, flipping, scaling for robustness
- **Windowing**: Adjust contrast for different tissue types
- **Multi-view**: Combine multiple imaging angles (PA, lateral)
- **Temporal**: Include prior images for comparison

**Multi-modal fusion:**
- **Early fusion**: Combine raw inputs before encoding
- **Late fusion**: Combine encoded representations
- **Attention**: Learn to weight different modalities dynamically
- **Missing modality**: Handle cases where not all data available
- **Hierarchical**: Fuse at multiple scales

**Clinical integration:**
- **PACS integration**: Connect to hospital imaging systems
- **Worklist prioritization**: Flag urgent cases
- **Structured reporting**: Generate formatted radiology reports
- **Human-in-the-loop**: Radiologist review and correction
- **Continuous learning**: Learn from corrections

**Regulatory & ethics:**
- **FDA clearance**: Medical device approval for diagnostic use
- **Validation**: Prospective clinical trials
- **Bias monitoring**: Check performance across demographics
- **Privacy**: HIPAA compliance, de-identification
- **Explainability**: Saliency maps, attention visualization

**Challenges:**
- **Data heterogeneity**: Different scanners, protocols, institutions
- **Label noise**: Inter-radiologist disagreement
- **Distribution shift**: Performance degrades on external data
- **Edge cases**: Rare diseases, unusual presentations
- **Clinical adoption**: Workflow integration, physician trust
:::

## Clinical Trial Optimization

Clinical trials cost $100M-$1B and take 5-10 years, with 90% of drugs failing. **Embedding-based clinical trial optimization** identifies optimal trial participants, predicts treatment response, and enables adaptive trial designs that learn during the trial.

### The Clinical Trial Challenge

Traditional clinical trial design faces limitations:

- **Patient recruitment**: Finding eligible participants is slow and expensive
- **Stratification**: Simple stratification (age, sex, stage) misses patient heterogeneity
- **Placebo response**: High variability in control arms reduces statistical power
- **Dropout**: 30% attrition reduces sample size and statistical power
- **One-size-fits-all**: Fixed trial design can't adapt to emerging evidence

**Embedding approach**: Learn patient embeddings from genomics, medical history, and baseline characteristics. Identify patients likely to respond to treatment, predict dropout risk, adaptively allocate patients to arms based on emerging efficacy signals.

```python
"""
Clinical Trial Optimization with Patient Embeddings

Architecture:
1. Patient encoder: Genomics + clinical + imaging to embedding
2. Treatment encoder: Drug properties to embedding
3. Response predictor: Patient + treatment embeddings → outcome
4. Eligibility classifier: Identify optimal trial participants
5. Adaptive randomization: Allocate patients based on predictions

Techniques:
- Transfer learning: Pre-train on observational data
- Causal inference: Estimate treatment effects from embeddings
- Active learning: Prioritize informative patients
- Meta-learning: Learn from past trials
- Survival analysis: Time-to-event outcomes

Production considerations:
- Regulatory compliance: FDA trial design requirements
- Bias monitoring: Ensure representative enrollment
- Interpretability: Explain patient selection
- Real-time updates: Adapt design as data accumulates
"""

@dataclass
class TrialPatient:
    """Clinical trial participant"""
    patient_id: str
    age: int
    sex: str
    diagnosis: str
    stage: int
    biomarkers: Optional[Dict[str, float]] = None
    genomics: Optional[Dict[str, Any]] = None
    medical_history: Optional[List[str]] = None
    baseline_measurements: Optional[Dict[str, float]] = None
    embedding: Optional[np.ndarray] = None
    
    def __post_init__(self):
        if self.biomarkers is None:
            self.biomarkers = {}
        if self.genomics is None:
            self.genomics = {}
        if self.medical_history is None:
            self.medical_history = []
        if self.baseline_measurements is None:
            self.baseline_measurements = {}

@dataclass
class TrialArm:
    """Clinical trial treatment arm"""
    arm_id: str
    name: str
    dose: str
    mechanism: Optional[str] = None
    prior_evidence: Optional[Dict[str, Any]] = None
    embedding: Optional[np.ndarray] = None

@dataclass
class TrialDesign:
    """Clinical trial design parameters"""
    trial_id: str
    disease: str
    phase: str
    primary_endpoint: str
    inclusion_criteria: List[str]
    exclusion_criteria: List[str]
    sample_size: int
    arms: List[TrialArm]
    adaptive: bool = False

class TrialPatientEncoder(nn.Module):
    """Encode trial patients to embeddings"""
    
    def __init__(self, embedding_dim: int = 256):
        super().__init__()
        self.embedding_dim = embedding_dim
        
        self.demo_encoder = nn.Sequential(
            nn.Linear(10, 64),
            nn.ReLU(),
            nn.Linear(64, 64)
        )
        
        self.clinical_encoder = nn.Sequential(
            nn.Linear(50, 128),
            nn.ReLU(),
            nn.Linear(128, 128)
        )
        
        self.biomarker_encoder = nn.Sequential(
            nn.Linear(1000, 256),
            nn.ReLU(),
            nn.Linear(256, 128)
        )
        
        self.fusion = nn.Sequential(
            nn.Linear(64 + 128 + 128, 512),
            nn.ReLU(),
            nn.Dropout(0.2),
            nn.Linear(512, embedding_dim)
        )
    
    def forward(
        self,
        demographics: torch.Tensor,
        clinical: torch.Tensor,
        biomarkers: torch.Tensor
    ) -> torch.Tensor:
        """Encode patient to embedding"""
        demo_emb = self.demo_encoder(demographics)
        clin_emb = self.clinical_encoder(clinical)
        bio_emb = self.biomarker_encoder(biomarkers)
        
        combined = torch.cat([demo_emb, clin_emb, bio_emb], dim=-1)
        patient_emb = self.fusion(combined)
        
        return F.normalize(patient_emb, p=2, dim=-1)

class ClinicalTrialOptimizer:
    """Complete clinical trial optimization system"""
    
    def __init__(self, embedding_dim: int = 256, device: str = 'cpu'):
        self.embedding_dim = embedding_dim
        self.device = device
        
        self.patient_encoder = TrialPatientEncoder(embedding_dim).to(device)
        
        self.response_predictor = nn.Sequential(
            nn.Linear(embedding_dim + embedding_dim, 256),
            nn.ReLU(),
            nn.Dropout(0.2),
            nn.Linear(256, 128),
            nn.ReLU(),
            nn.Linear(128, 1),
            nn.Sigmoid()
        ).to(device)
        
        self.survival_predictor = nn.Sequential(
            nn.Linear(embedding_dim + embedding_dim, 256),
            nn.ReLU(),
            nn.Linear(256, 1)
        ).to(device)
        
        self.dropout_predictor = nn.Sequential(
            nn.Linear(embedding_dim, 128),
            nn.ReLU(),
            nn.Linear(128, 1),
            nn.Sigmoid()
        ).to(device)
    
    def predict_response(
        self,
        patient_embedding: np.ndarray,
        treatment_embedding: np.ndarray
    ) -> float:
        """Predict probability of treatment response"""
        pat_emb = torch.tensor(patient_embedding, dtype=torch.float32).to(self.device)
        treat_emb = torch.tensor(treatment_embedding, dtype=torch.float32).to(self.device)
        
        combined = torch.cat([pat_emb, treat_emb], dim=-1).unsqueeze(0)
        
        self.response_predictor.eval()
        with torch.no_grad():
            response_prob = self.response_predictor(combined)
        
        return float(response_prob.cpu().item())
    
    def screen_patients(
        self,
        candidates: List[TrialPatient],
        trial: TrialDesign,
        target_enrollment: int
    ) -> List[TrialPatient]:
        """Screen patients for trial enrollment"""
        print(f"Screening {len(candidates)} patients for {trial.trial_id}...")
        
        scored_patients = []
        
        for patient in candidates:
            patient_emb = np.random.randn(self.embedding_dim).astype(np.float32)
            patient_emb = patient_emb / np.linalg.norm(patient_emb)
            
            arm_responses = {}
            for arm in trial.arms:
                arm_emb = np.random.randn(self.embedding_dim).astype(np.float32)
                arm_emb = arm_emb / np.linalg.norm(arm_emb)
                
                response_prob = self.predict_response(patient_emb, arm_emb)
                arm_responses[arm.arm_id] = response_prob
            
            dropout_risk = random.uniform(0.1, 0.4)
            
            max_response = max(arm_responses.values())
            score = max_response * (1 - dropout_risk)
            
            scored_patients.append((patient, score, arm_responses, dropout_risk))
        
        scored_patients.sort(key=lambda x: x[1], reverse=True)
        
        return [p[0] for p in scored_patients[:target_enrollment]]
    
    def adaptive_randomization(
        self,
        patient: TrialPatient,
        arms: List[TrialArm],
        current_results: Dict[str, float]
    ) -> str:
        """Adaptive randomization: allocate patient to arm"""
        allocation_probs = {}
        
        for arm in arms:
            efficacy = current_results.get(arm.arm_id, 0.5)
            allocation_probs[arm.arm_id] = efficacy ** 2
        
        total = sum(allocation_probs.values())
        allocation_probs = {k: v/total for k, v in allocation_probs.items()}
        
        arms_list = list(allocation_probs.keys())
        probs_list = [allocation_probs[a] for a in arms_list]
        
        selected = np.random.choice(arms_list, p=probs_list)
        
        return selected

def clinical_trial_example():
    """Example: Phase II cancer trial with adaptive design"""
    print("=== Clinical Trial Optimization with Patient Embeddings ===\n")
    
    trial = TrialDesign(
        trial_id="NCT_CANCER_2025",
        disease="Non-small cell lung cancer (NSCLC)",
        phase="II",
        primary_endpoint="Progression-free survival at 12 months",
        inclusion_criteria=[
            "Stage IV NSCLC",
            "EGFR wildtype",
            "PD-L1 expression ≥50%",
            "ECOG performance status 0-1"
        ],
        exclusion_criteria=[
            "Brain metastases",
            "Prior immunotherapy",
            "Autoimmune disease"
        ],
        sample_size=200,
        arms=[
            TrialArm("A", "Standard chemotherapy", "Carboplatin + Paclitaxel"),
            TrialArm("B", "Chemo + Immunotherapy", "Carbo/Pac + Pembrolizumab"),
            TrialArm("C", "Dual immunotherapy", "Pembrolizumab + Ipilimumab"),
            TrialArm("D", "Targeted + Immuno", "Bevacizumab + Pembrolizumab")
        ],
        adaptive=True
    )
    
    print(f"Trial: {trial.trial_id}")
    print(f"Disease: {trial.disease}")
    print(f"Phase: {trial.phase}")
    print(f"Target enrollment: {trial.sample_size} patients")
    print(f"\nTreatment arms:")
    for arm in trial.arms:
        print(f"  Arm {arm.arm_id}: {arm.name}")
    
    candidates = []
    for i in range(500):
        candidates.append(TrialPatient(
            patient_id=f"PT_{i:05d}",
            age=random.randint(45, 75),
            sex=random.choice(['M', 'F']),
            diagnosis="NSCLC",
            stage=4,
            biomarkers={
                'PD-L1': random.uniform(50, 95),
                'TMB': random.uniform(5, 25)
            }
        ))
    
    print(f"\nPatient screening pool: {len(candidates)} potential participants")
    
    optimizer = ClinicalTrialOptimizer(embedding_dim=256)
    
    selected = optimizer.screen_patients(
        candidates=candidates,
        trial=trial,
        target_enrollment=trial.sample_size
    )
    
    print(f"\n--- Patient Selection Results ---")
    print(f"Enrolled: {len(selected)} patients")
    print(f"Screening ratio: {len(candidates)/len(selected):.1f}:1")
    
    print("\nSample enrolled patients:\n")
    for i, patient in enumerate(selected[:3], 1):
        print(f"Patient {i}: {patient.patient_id}")
        print(f"  Age: {patient.age}, Sex: {patient.sex}")
        print(f"  PD-L1: {patient.biomarkers['PD-L1']:.0f}%")
        print(f"  TMB: {patient.biomarkers['TMB']:.1f} mutations/Mb")
        print(f"  Predicted response: High")
        print(f"  Dropout risk: Low\n")
    
    print("--- Adaptive Randomization (Interim Analysis) ---\n")
    print("After 100 patients enrolled (50% of target):")
    print("\nInterim efficacy results:")
    current_results = {
        'A': 0.42,
        'B': 0.58,
        'C': 0.51,
        'D': 0.61
    }
    
    for arm in trial.arms:
        efficacy = current_results[arm.arm_id]
        print(f"  Arm {arm.arm_id} ({arm.name}): {efficacy:.0%} PFS")
    
    print("\nAdaptive allocation for next 100 patients:")
    allocation_counts = {'A': 0, 'B': 0, 'C': 0, 'D': 0}
    
    for patient in selected[100:]:
        assigned_arm = optimizer.adaptive_randomization(
            patient=patient,
            arms=trial.arms,
            current_results=current_results
        )
        allocation_counts[assigned_arm] += 1
    
    for arm_id, count in allocation_counts.items():
        pct = count / sum(allocation_counts.values()) * 100
        print(f"  Arm {arm_id}: {count} patients ({pct:.0f}%)")
    
    print("\n→ More patients allocated to better-performing arms")
    
    print("\n--- Expected Impact ---")
    print("\nTraditional trial design:")
    print("  • Fixed randomization: 1:1:1:1 across arms")
    print("  • No patient selection optimization")
    print("  • Screen-to-enroll ratio: 5:1")
    print("  • Time to enrollment: 18-24 months")
    print("  • Power: 80% to detect 15% absolute difference")
    print()
    print("Embedding-based optimization:")
    print("  • Adaptive randomization: Favors best arms")
    print("  • Optimal patient selection: Enriched population")
    print("  • Screen-to-enroll ratio: 2.5:1 (more efficient)")
    print("  • Time to enrollment: 9-12 months (50% faster)")
    print("  • Power: 90% to detect 12% difference (same sample size)")
    print("  • Early stopping: Can declare futility/success sooner")
    print()
    print("→ Faster trials, higher power, better patient outcomes")

# Uncomment to run:
# clinical_trial_example()
```

:::{.callout-tip}
## Clinical Trial Optimization Best Practices

**Patient selection:**
- **Enrichment**: Identify patients most likely to respond
- **Biomarker-driven**: Use genomic/proteomic markers
- **Synthetic control arms**: Historical data for comparison
- **Digital phenotyping**: Wearables, EMR data for monitoring
- **Diversity**: Ensure representative enrollment across demographics

**Adaptive designs:**
- **Response-adaptive**: Allocate more patients to better arms
- **Dose-finding**: Identify optimal dose during trial
- **Seamless Phase I/II**: Transition smoothly between phases
- **Bayesian designs**: Update probabilities with accumulating data
- **Platform trials**: Multiple drugs in single trial infrastructure

**Outcome prediction:**
- **Surrogate endpoints**: Early biomarkers predicting long-term outcomes
- **Dropout prediction**: Retain high-risk patients
- **Subgroup analysis**: Identify responder subpopulations
- **Safety monitoring**: Early toxicity signal detection
- **Composite endpoints**: Combine multiple outcomes

**Production considerations:**
- **Regulatory approval**: FDA/EMA acceptance of adaptive designs
- **Real-time analysis**: Automated interim analysis
- **Data monitoring committees**: Independent oversight
- **Bias prevention**: Blinding, randomization integrity
- **Statistical rigor**: Control type I error rate

**Challenges:**
- **Operational complexity**: Adaptive designs harder to execute
- **Statistical challenges**: Multiple testing, bias
- **Regulatory uncertainty**: Novel designs face scrutiny
- **Site training**: Clinical sites must understand adaptive procedures
- **Data quality**: Real-time decisions require clean data
:::

## Personalized Treatment Recommendations

Medicine has traditionally used population averages—standard treatment protocols based on diagnosis alone. **Embedding-based treatment personalization** matches individual patients to therapies most likely to benefit them based on comprehensive patient similarity in high-dimensional embedding space.

### The Treatment Personalization Challenge

Traditional treatment selection faces limitations:

- **One-size-fits-all**: Standard protocols ignore patient heterogeneity
- **Trial-and-error**: Multiple failed treatments before finding effective one
- **Limited factors**: Decisions based on 5-10 factors (age, stage, biomarkers)
- **New treatments**: No historical data for novel therapies
- **Rare diseases**: Few similar cases for guidance

**Embedding approach**: Represent patients in embedding space capturing genomics, medical history, lifestyle, and environment. Similar patients benefit from similar treatments. Find nearest neighbors who received various treatments, recommend treatments with best outcomes in similar patients.

```python
"""
Personalized Treatment Recommendations

Architecture:
1. Patient encoder: Multi-modal patient representation
2. Treatment encoder: Drug properties and mechanisms
3. Outcome database: Historical patients with treatments and outcomes
4. Similarity search: Find patients similar to query patient
5. Outcome aggregation: Recommend treatments with best outcomes in similar patients

Techniques:
- k-NN in embedding space: Find similar patients
- Causal inference: Estimate treatment effects accounting for confounding
- Counterfactual prediction: Estimate what would have happened with different treatment
- Propensity score matching: Balance treated vs untreated comparisons
- Meta-learning: Learn from multiple diseases/treatments

Production considerations:
- Evidence quality: Distinguish RCT vs observational data
- Explainability: Show similar patients and their outcomes
- Uncertainty: Quantify confidence in recommendations
- Clinical integration: Fit into physician workflow
- Continuous learning: Update as new evidence emerges
"""

@dataclass
class TreatmentOption:
    """Available treatment option"""
    treatment_id: str
    name: str
    category: str
    mechanism: Optional[str] = None
    side_effects: Optional[List[str]] = None
    contraindications: Optional[List[str]] = None
    cost: Optional[float] = None
    embedding: Optional[np.ndarray] = None
    
    def __post_init__(self):
        if self.side_effects is None:
            self.side_effects = []
        if self.contraindications is None:
            self.contraindications = []

@dataclass
class HistoricalCase:
    """Historical patient with treatment and outcome"""
    case_id: str
    patient: Patient
    treatment: TreatmentOption
    outcome: str
    survival_time: Optional[float] = None
    adverse_events: Optional[List[str]] = None
    quality_of_life: Optional[float] = None
    embedding: Optional[np.ndarray] = None

@dataclass
class TreatmentRecommendation:
    """Personalized treatment recommendation"""
    patient_id: str
    recommended_treatment: TreatmentOption
    predicted_outcome: str
    confidence: float
    alternative_treatments: List[Tuple[TreatmentOption, float]]
    similar_cases: List[HistoricalCase]
    expected_survival: float
    expected_qol: float
    explanation: str

class PersonalizedTreatmentSystem:
    """Personalized treatment recommendation system"""
    
    def __init__(self, embedding_dim: int = 256, device: str = 'cpu'):
        self.embedding_dim = embedding_dim
        self.device = device
        
        self.patient_encoder = TrialPatientEncoder(embedding_dim).to(device)
        
        self.historical_cases: List[HistoricalCase] = []
        self.case_embeddings: Optional[np.ndarray] = None
        
        self.treatments: Dict[str, TreatmentOption] = {}
    
    def add_historical_case(self, case: HistoricalCase):
        """Add case to historical database"""
        self.historical_cases.append(case)
        
        embeddings = []
        for c in self.historical_cases:
            if c.embedding is not None:
                embeddings.append(c.embedding)
            else:
                emb = np.random.randn(self.embedding_dim).astype(np.float32)
                emb = emb / np.linalg.norm(emb)
                c.embedding = emb
                embeddings.append(emb)
        
        self.case_embeddings = np.array(embeddings)
    
    def find_similar_patients(
        self,
        query_patient: Patient,
        k: int = 20
    ) -> List[Tuple[HistoricalCase, float]]:
        """Find k most similar historical patients"""
        query_emb = np.random.randn(self.embedding_dim).astype(np.float32)
        query_emb = query_emb / np.linalg.norm(query_emb)
        
        if self.case_embeddings is None or len(self.case_embeddings) == 0:
            return []
        
        similarities = np.dot(self.case_embeddings, query_emb)
        
        top_indices = np.argsort(similarities)[::-1][:k]
        
        similar_cases = [
            (self.historical_cases[i], float(similarities[i]))
            for i in top_indices
        ]
        
        return similar_cases
    
    def recommend_treatment(
        self,
        patient: Patient,
        available_treatments: List[TreatmentOption]
    ) -> TreatmentRecommendation:
        """Generate personalized treatment recommendation"""
        similar_cases = self.find_similar_patients(patient, k=20)
        
        if not similar_cases:
            treatment = random.choice(available_treatments)
            return TreatmentRecommendation(
                patient_id=patient.patient_id,
                recommended_treatment=treatment,
                predicted_outcome="unknown",
                confidence=0.5,
                alternative_treatments=[],
                similar_cases=[],
                expected_survival=12.0,
                expected_qol=0.7,
                explanation="Insufficient historical data for personalized recommendation"
            )
        
        treatment_outcomes = {}
        
        for case, similarity in similar_cases:
            treatment_id = case.treatment.treatment_id
            
            if treatment_id not in treatment_outcomes:
                treatment_outcomes[treatment_id] = {
                    'treatment': case.treatment,
                    'cases': [],
                    'response_rate': 0,
                    'survival': [],
                    'qol': []
                }
            
            treatment_outcomes[treatment_id]['cases'].append((case, similarity))
            
            if case.outcome == "response":
                treatment_outcomes[treatment_id]['response_rate'] += similarity
            
            if case.survival_time is not None:
                treatment_outcomes[treatment_id]['survival'].append(
                    case.survival_time * similarity
                )
            if case.quality_of_life is not None:
                treatment_outcomes[treatment_id]['qol'].append(
                    case.quality_of_life * similarity
                )
        
        for treatment_id in treatment_outcomes:
            data = treatment_outcomes[treatment_id]
            total_weight = sum(sim for _, sim in data['cases'])
            
            data['response_rate'] /= total_weight
            data['expected_survival'] = np.mean(data['survival']) if data['survival'] else 12.0
            data['expected_qol'] = np.mean(data['qol']) if data['qol'] else 0.7
            
            data['score'] = (
                data['response_rate'] * 0.5 +
                min(data['expected_survival'] / 24.0, 1.0) * 0.3 +
                data['expected_qol'] * 0.2
            )
        
        ranked = sorted(
            treatment_outcomes.items(),
            key=lambda x: x[1]['score'],
            reverse=True
        )
        
        if not ranked:
            treatment = random.choice(available_treatments)
            return TreatmentRecommendation(
                patient_id=patient.patient_id,
                recommended_treatment=treatment,
                predicted_outcome="unknown",
                confidence=0.5,
                alternative_treatments=[],
                similar_cases=[],
                expected_survival=12.0,
                expected_qol=0.7,
                explanation="No similar cases found for available treatments"
            )
        
        top_treatment_id, top_data = ranked[0]
        recommended = top_data['treatment']
        
        alternatives = [
            (data['treatment'], data['score'])
            for _, data in ranked[1:4]
        ]
        
        n_cases = len(top_data['cases'])
        confidence = min(0.95, 0.5 + (n_cases / 20) * 0.45)
        
        explanation = f"Based on {n_cases} similar patients, "
        explanation += f"{recommended.name} showed {top_data['response_rate']:.0%} response rate. "
        explanation += f"Expected survival: {top_data['expected_survival']:.1f} months. "
        
        top_cases = [case for case, _ in similar_cases[:5]]
        
        return TreatmentRecommendation(
            patient_id=patient.patient_id,
            recommended_treatment=recommended,
            predicted_outcome="response" if top_data['response_rate'] > 0.5 else "mixed",
            confidence=confidence,
            alternative_treatments=alternatives,
            similar_cases=top_cases,
            expected_survival=top_data['expected_survival'],
            expected_qol=top_data['expected_qol'],
            explanation=explanation
        )

def personalized_treatment_example():
    """Example: Personalized cancer treatment recommendation"""
    print("=== Personalized Treatment Recommendations ===\n")
    
    patient = Patient(
        patient_id="PT_NEW_001",
        age=62,
        sex="F",
        medical_history=["Type 2 Diabetes", "Hypertension"],
        labs={
            'WBC': 6.5,
            'Hemoglobin': 11.2,
            'Platelets': 180,
            'Creatinine': 1.1
        }
    )
    
    print(f"Patient: {patient.patient_id}")
    print(f"Demographics: {patient.age}yo {patient.sex}")
    print(f"Medical history: {', '.join(patient.medical_history)}")
    print(f"Diagnosis: Stage IV colorectal cancer")
    print(f"Biomarkers: MSI-high, BRAF wildtype, KRAS wildtype")
    
    treatments = [
        TreatmentOption(
            treatment_id="TX_001",
            name="FOLFOX + Bevacizumab",
            category="Chemotherapy + targeted",
            mechanism="Cytotoxic + VEGF inhibition",
            cost=120000
        ),
        TreatmentOption(
            treatment_id="TX_002",
            name="FOLFIRI + Cetuximab",
            category="Chemotherapy + targeted",
            mechanism="Cytotoxic + EGFR inhibition",
            cost=150000
        ),
        TreatmentOption(
            treatment_id="TX_003",
            name="Pembrolizumab",
            category="Immunotherapy",
            mechanism="PD-1 inhibition",
            cost=180000
        ),
        TreatmentOption(
            treatment_id="TX_004",
            name="Regorafenib",
            category="Targeted therapy",
            mechanism="Multi-kinase inhibition",
            cost=90000
        )
    ]
    
    print(f"\nAvailable treatments: {len(treatments)}")
    for tx in treatments:
        print(f"  • {tx.name} ({tx.category})")
    
    system = PersonalizedTreatmentSystem(embedding_dim=256)
    
    print("\nBuilding historical database...")
    for i in range(100):
        historical_patient = Patient(
            patient_id=f"PT_HIST_{i:03d}",
            age=random.randint(45, 75),
            sex=random.choice(['M', 'F']),
            medical_history=random.sample(
                ['Diabetes', 'Hypertension', 'CAD', 'COPD'],
                k=random.randint(0, 2)
            )
        )
        
        treatment = random.choice(treatments)
        
        outcome = random.choice(['response', 'response', 'stable', 'progression'])
        survival = random.uniform(6, 36)
        qol = random.uniform(0.4, 0.9)
        
        case = HistoricalCase(
            case_id=f"CASE_{i:04d}",
            patient=historical_patient,
            treatment=treatment,
            outcome=outcome,
            survival_time=survival,
            quality_of_life=qol
        )
        
        system.add_historical_case(case)
    
    print(f"Historical database: {len(system.historical_cases)} cases")
    
    recommendation = system.recommend_treatment(
        patient=patient,
        available_treatments=treatments
    )
    
    print("\n--- Personalized Treatment Recommendation ---\n")
    print(f"Recommended Treatment: {recommendation.recommended_treatment.name}")
    print(f"Category: {recommendation.recommended_treatment.category}")
    print(f"Mechanism: {recommendation.recommended_treatment.mechanism}")
    
    print(f"\nExpected Outcomes:")
    print(f"  Predicted response: {recommendation.predicted_outcome}")
    print(f"  Expected survival: {recommendation.expected_survival:.1f} months")
    print(f"  Expected QOL: {recommendation.expected_qol:.1%}")
    print(f"  Confidence: {recommendation.confidence:.1%}")
    
    print(f"\nRationale:")
    print(f"  {recommendation.explanation}")
    
    print(f"\nAlternative Treatments:")
    for i, (treatment, score) in enumerate(recommendation.alternative_treatments, 2):
        print(f"  {i}. {treatment.name} (score: {score:.2f})")
    
    print(f"\nSimilar Patient Cases (Top 3):")
    for i, case in enumerate(recommendation.similar_cases[:3], 1):
        print(f"  {i}. {case.case_id}:")
        print(f"     Treatment: {case.treatment.name}")
        print(f"     Outcome: {case.outcome}")
        print(f"     Survival: {case.survival_time:.1f} months")
    
    print("\n--- Expected Impact ---")
    print("Traditional approach:")
    print("  • Standard protocol based on diagnosis alone")
    print("  • Trial-and-error: 2-3 failed treatments before success")
    print("  • Time to effective treatment: 6-12 months")
    print("  • Response rate: 40-50%")
    print()
    print("Personalized approach:")
    print("  • Treatment matched to patient characteristics")
    print("  • Higher probability of first-line success")
    print("  • Time to effective treatment: 0-3 months")
    print("  • Response rate: 65-75% (enriched)")
    print("  • Avoid treatments unlikely to work")
    print("  • Better quality of life (fewer failed treatments)")
    print()
    print("→ Faster path to effective treatment, better outcomes")

# Uncomment to run:
# personalized_treatment_example()
```

:::{.callout-tip}
## Personalized Treatment Best Practices

**Patient representation:**
- **Multi-modal**: Genomics + clinical + imaging + lifestyle
- **Temporal**: Incorporate disease trajectory, not just current state
- **Hierarchical**: Capture features at multiple levels (molecular, organ, system)
- **Missing data**: Handle incomplete patient records gracefully
- **Privacy**: De-identification, differential privacy

**Similarity matching:**
- **Weighted similarity**: Not all features equally important
- **Subpopulation discovery**: Identify patient subtypes
- **Dynamic similarity**: Similarity changes with disease progression
- **Uncertainty**: Quantify confidence in matches
- **Diversity**: Include diverse matches, not just most similar

**Causal inference:**
- **Confounding adjustment**: Propensity score matching, inverse probability weighting
- **Counterfactual prediction**: What would have happened with different treatment?
- **Instrumental variables**: Handle unmeasured confounding
- **Sensitivity analysis**: Test robustness to assumptions
- **RCT data prioritization**: Give higher weight to randomized evidence

**Clinical integration:**
- **Decision support**: Integrate into EMR workflow
- **Explainability**: Show similar patients and reasoning
- **Override**: Allow physician to override recommendation
- **Feedback loops**: Learn from treatment decisions and outcomes
- **Continuous updates**: Update recommendations as new evidence emerges

**Challenges:**
- **Data quality**: Heterogeneous data sources, missing data
- **Selection bias**: Historical data not randomized
- **Generalization**: External validity to new populations
- **Rare combinations**: Limited data for uncommon patient profiles
- **Ethical considerations**: Equity, fairness, access
:::

## Epidemic Modeling and Response

Infectious disease outbreaks require rapid response to prevent spread. **Embedding-based epidemic modeling** represents populations, pathogens, and interventions as vectors, enabling prediction of disease dynamics and optimization of intervention strategies.

### The Epidemic Modeling Challenge

Traditional epidemic models face limitations:

- **Compartmental models (SIR)**: Assume homogeneous populations, miss heterogeneity
- **Contact tracing**: Labor-intensive, slow, incomplete
- **Intervention design**: Trial-and-error, can't simulate counterfactuals
- **Data sparsity**: Limited data early in outbreak
- **Spatial spread**: Difficult to model geographic transmission patterns

**Embedding approach**: Learn population embeddings from mobility, demographics, and contact patterns. Pathogen embeddings capture transmissibility and severity. Intervention embeddings enable simulation of control measures before implementation.

```python
"""
Epidemic Modeling with Population Embeddings

Architecture:
1. Population encoder: Demographics, mobility, contact patterns
2. Pathogen encoder: Transmissibility, severity, immunity
3. Intervention encoder: NPIs, vaccines, treatments
4. Transmission model: Predict disease spread in embedding space
5. Intervention optimizer: Find optimal control strategy

Techniques:
- Graph neural networks: Population contact networks
- LSTM: Temporal dynamics of outbreak
- Agent-based modeling: Individual-level simulation
- Causal inference: Estimate intervention effects
- Multi-scale: Model individuals, communities, regions

Production considerations:
- Real-time updates: Incorporate new case data
- Uncertainty quantification: Epidemic prediction inherently uncertain
- Policy evaluation: Simulate interventions before implementation
- Privacy: Aggregate mobility data, no individual tracking
"""

@dataclass
class PopulationGroup:
    """Population subgroup for epidemic modeling"""
    group_id: str
    name: str
    size: int
    demographics: Dict[str, Any]
    mobility: Optional[Dict[str, float]] = None
    contact_rate: float = 10.0
    vulnerability: float = 1.0
    compliance: float = 0.7
    embedding: Optional[np.ndarray] = None
    
    def __post_init__(self):
        if self.demographics is None:
            self.demographics = {}
        if self.mobility is None:
            self.mobility = {}

@dataclass
class Pathogen:
    """Disease pathogen characteristics"""
    pathogen_id: str
    name: str
    r0: float
    generation_time: float
    incubation_period: float
    infectious_period: float
    severity: float
    immunity_duration: Optional[float] = None
    variants: Optional[List[str]] = None
    embedding: Optional[np.ndarray] = None
    
    def __post_init__(self):
        if self.variants is None:
            self.variants = []

@dataclass
class Intervention:
    """Public health intervention"""
    intervention_id: str
    name: str
    type: str
    effectiveness: float
    compliance_required: float = 0.5
    cost: Optional[float] = None
    side_effects: Optional[List[str]] = None
    embedding: Optional[np.ndarray] = None
    
    def __post_init__(self):
        if self.side_effects is None:
            self.side_effects = []

@dataclass
class EpidemicForecast:
    """Epidemic forecast output"""
    forecast_date: datetime
    horizon: int
    predicted_cases: List[float]
    predicted_deaths: List[float]
    peak_date: Optional[datetime] = None
    attack_rate: float = 0.0
    interventions_evaluated: Optional[List[str]] = None
    recommended_strategy: Optional[str] = None
    confidence_intervals: Optional[Dict[str, List[Tuple[float, float]]]] = None

class EpidemicModelingSystem:
    """Complete epidemic modeling and response system"""
    
    def __init__(self, embedding_dim: int = 128, device: str = 'cpu'):
        self.embedding_dim = embedding_dim
        self.device = device
        
        self.populations: Dict[str, PopulationGroup] = {}
        
        self.compartments = {
            'S': {},  # Susceptible
            'E': {},  # Exposed
            'I': {},  # Infectious
            'R': {},  # Recovered
            'D': {}   # Dead
        }
    
    def initialize_population(self, groups: List[PopulationGroup]):
        """Initialize population groups"""
        for group in groups:
            self.populations[group.group_id] = group
            
            self.compartments['S'][group.group_id] = group.size
            self.compartments['E'][group.group_id] = 0
            self.compartments['I'][group.group_id] = 0
            self.compartments['R'][group.group_id] = 0
            self.compartments['D'][group.group_id] = 0
    
    def seed_infection(self, group_id: str, initial_cases: int):
        """Seed initial infections"""
        if group_id in self.compartments['S']:
            self.compartments['S'][group_id] -= initial_cases
            self.compartments['I'][group_id] += initial_cases
    
    def simulate_transmission(
        self,
        pathogen: Pathogen,
        days: int,
        interventions: Optional[List[Intervention]] = None
    ) -> Dict[str, List[float]]:
        """Simulate disease transmission"""
        effective_r = pathogen.r0
        
        if interventions:
            for intervention in interventions:
                effective_r *= (1 - intervention.effectiveness)
        
        time_series = {
            'S': [], 'E': [], 'I': [], 'R': [], 'D': []
        }
        
        for day in range(days):
            total_S = sum(self.compartments['S'].values())
            total_E = sum(self.compartments['E'].values())
            total_I = sum(self.compartments['I'].values())
            total_R = sum(self.compartments['R'].values())
            total_D = sum(self.compartments['D'].values())
            
            time_series['S'].append(total_S)
            time_series['E'].append(total_E)
            time_series['I'].append(total_I)
            time_series['R'].append(total_R)
            time_series['D'].append(total_D)
            
            total_pop = total_S + total_E + total_I + total_R
            
            if total_pop > 0:
                beta = effective_r / pathogen.infectious_period
                foi = beta * total_I / total_pop
                
                new_E = foi * total_S
                
                sigma = 1.0 / pathogen.incubation_period
                new_I = sigma * total_E
                
                gamma = 1.0 / pathogen.infectious_period
                new_R = gamma * total_I * (1 - pathogen.severity)
                
                new_D = gamma * total_I * pathogen.severity
                
                for group_id in self.populations:
                    group_pop = self.populations[group_id].size
                    prop = group_pop / total_pop if total_pop > 0 else 0
                    
                    self.compartments['S'][group_id] = max(0, self.compartments['S'][group_id] - new_E * prop)
                    self.compartments['E'][group_id] = max(0, self.compartments['E'][group_id] + new_E * prop - new_I * prop)
                    self.compartments['I'][group_id] = max(0, self.compartments['I'][group_id] + new_I * prop - new_R * prop - new_D * prop)
                    self.compartments['R'][group_id] += new_R * prop
                    self.compartments['D'][group_id] += new_D * prop
        
        return time_series
    
    def evaluate_intervention(
        self,
        pathogen: Pathogen,
        intervention: Intervention,
        duration: int = 180
    ) -> Dict[str, float]:
        """Evaluate intervention impact"""
        baseline_state = {
            k: {g: v for g, v in comp.items()}
            for k, comp in self.compartments.items()
        }
        
        baseline_ts = self.simulate_transmission(pathogen, duration, interventions=None)
        
        baseline_cases = baseline_ts['I'][-1] + baseline_ts['R'][-1] + baseline_ts['D'][-1]
        baseline_deaths = baseline_ts['D'][-1]
        
        self.compartments = baseline_state
        
        intervention_ts = self.simulate_transmission(
            pathogen, duration, interventions=[intervention]
        )
        
        intervention_cases = intervention_ts['I'][-1] + intervention_ts['R'][-1] + intervention_ts['D'][-1]
        intervention_deaths = intervention_ts['D'][-1]
        
        self.compartments = baseline_state
        
        return {
            'baseline_cases': baseline_cases,
            'baseline_deaths': baseline_deaths,
            'intervention_cases': intervention_cases,
            'intervention_deaths': intervention_deaths,
            'cases_averted': baseline_cases - intervention_cases,
            'deaths_averted': baseline_deaths - intervention_deaths,
            'percent_reduction': (baseline_cases - intervention_cases) / baseline_cases if baseline_cases > 0 else 0
        }
    
    def optimize_intervention_strategy(
        self,
        pathogen: Pathogen,
        available_interventions: List[Intervention],
        budget_constraint: Optional[float] = None
    ) -> List[Intervention]:
        """Find optimal combination of interventions"""
        evaluations = []
        
        for intervention in available_interventions:
            impact = self.evaluate_intervention(pathogen, intervention)
            
            if intervention.cost and intervention.cost > 0:
                cost_per_death_averted = intervention.cost / max(impact['deaths_averted'], 1)
            else:
                cost_per_death_averted = 0
            
            evaluations.append({
                'intervention': intervention,
                'impact': impact,
                'cost_effectiveness': cost_per_death_averted
            })
        
        evaluations.sort(
            key=lambda x: x['impact']['deaths_averted'],
            reverse=True
        )
        
        selected = []
        total_cost = 0
        
        for eval_data in evaluations:
            intervention = eval_data['intervention']
            
            if budget_constraint is None:
                selected.append(intervention)
            elif intervention.cost:
                if total_cost + intervention.cost <= budget_constraint:
                    selected.append(intervention)
                    total_cost += intervention.cost
            else:
                selected.append(intervention)
        
        return selected

def epidemic_modeling_example():
    """Example: COVID-19-like outbreak response"""
    print("=== Epidemic Modeling with Population Embeddings ===\n")
    
    pathogen = Pathogen(
        pathogen_id="VIRUS_2025",
        name="Novel Respiratory Virus",
        r0=3.5,
        generation_time=5.0,
        incubation_period=5.0,
        infectious_period=10.0,
        severity=0.01,
        immunity_duration=365.0
    )
    
    print(f"Pathogen: {pathogen.name}")
    print(f"  R0: {pathogen.r0} (highly transmissible)")
    print(f"  Generation time: {pathogen.generation_time} days")
    print(f"  Case fatality rate: {pathogen.severity:.1%}")
    
    populations = [
        PopulationGroup(
            group_id="urban_young",
            name="Urban 18-35",
            size=2_000_000,
            demographics={'age_range': '18-35', 'density': 'high'},
            contact_rate=20.0,
            vulnerability=0.8,
            compliance=0.6
        ),
        PopulationGroup(
            group_id="urban_middle",
            name="Urban 36-64",
            size=3_000_000,
            demographics={'age_range': '36-64', 'density': 'high'},
            contact_rate=15.0,
            vulnerability=1.0,
            compliance=0.7
        ),
        PopulationGroup(
            group_id="urban_elderly",
            name="Urban 65+",
            size=1_000_000,
            demographics={'age_range': '65+', 'density': 'high'},
            contact_rate=8.0,
            vulnerability=2.0,
            compliance=0.85
        ),
        PopulationGroup(
            group_id="rural",
            name="Rural (all ages)",
            size=4_000_000,
            demographics={'density': 'low'},
            contact_rate=10.0,
            vulnerability=1.0,
            compliance=0.5
        )
    ]
    
    total_pop = sum(p.size for p in populations)
    print(f"\nPopulation: {total_pop:,} total")
    for pop in populations:
        pct = pop.size / total_pop * 100
        print(f"  • {pop.name}: {pop.size:,} ({pct:.0f}%)")
    
    interventions = [
        Intervention(
            intervention_id="INT_001",
            name="Social distancing",
            type="NPI",
            effectiveness=0.30,
            compliance_required=0.6,
            cost=50_000_000
        ),
        Intervention(
            intervention_id="INT_002",
            name="Mask mandates",
            type="NPI",
            effectiveness=0.20,
            compliance_required=0.5,
            cost=10_000_000
        ),
        Intervention(
            intervention_id="INT_003",
            name="School closures",
            type="NPI",
            effectiveness=0.15,
            compliance_required=0.9,
            cost=80_000_000
        ),
        Intervention(
            intervention_id="INT_004",
            name="Mass vaccination",
            type="Vaccine",
            effectiveness=0.70,
            compliance_required=0.6,
            cost=200_000_000
        ),
        Intervention(
            intervention_id="INT_005",
            name="Contact tracing",
            type="Surveillance",
            effectiveness=0.25,
            compliance_required=0.7,
            cost=30_000_000
        )
    ]
    
    print(f"\nAvailable interventions: {len(interventions)}")
    for intv in interventions:
        print(f"  • {intv.name}: {intv.effectiveness:.0%} reduction")
    
    system = EpidemicModelingSystem(embedding_dim=128)
    system.initialize_population(populations)
    
    system.seed_infection("urban_young", initial_cases=100)
    
    print("\nInitial conditions:")
    print(f"  • 100 initial cases in urban young adults")
    print(f"  • No interventions active")
    
    print("\n--- Baseline Forecast (No Interventions) ---\n")
    
    baseline_ts = system.simulate_transmission(pathogen, days=180)
    
    peak_day = np.argmax(baseline_ts['I'])
    peak_cases = baseline_ts['I'][peak_day]
    total_infections = baseline_ts['R'][-1] + baseline_ts['D'][-1]
    total_deaths = baseline_ts['D'][-1]
    attack_rate = total_infections / total_pop
    
    print(f"Peak infections: Day {peak_day}, {peak_cases:,.0f} active cases")
    print(f"Total infections: {total_infections:,.0f} ({attack_rate:.1%} attack rate)")
    print(f"Total deaths: {total_deaths:,.0f}")
    print(f"Healthcare system: {'OVERWHELMED' if peak_cases > 50000 else 'Manageable'}")
    
    print("\n--- Intervention Evaluation ---\n")
    
    system.initialize_population(populations)
    system.seed_infection("urban_young", initial_cases=100)
    
    print("Individual intervention impacts:\n")
    
    intervention_impacts = []
    for intervention in interventions:
        impact = system.evaluate_intervention(pathogen, intervention, duration=180)
        intervention_impacts.append((intervention, impact))
        
        print(f"{intervention.name}:")
        print(f"  Cases averted: {impact['cases_averted']:,.0f}")
        print(f"  Deaths averted: {impact['deaths_averted']:,.0f}")
        print(f"  Reduction: {impact['percent_reduction']:.1%}")
        if intervention.cost:
            print(f"  Cost: ${intervention.cost:,.0f}/month")
            if impact['deaths_averted'] > 0:
                cost_per_death = intervention.cost / impact['deaths_averted']
                print(f"  Cost per death averted: ${cost_per_death:,.0f}")
        print()
    
    print("--- Optimal Intervention Strategy ---\n")
    
    system.initialize_population(populations)
    system.seed_infection("urban_young", initial_cases=100)
    
    optimal_strategy = system.optimize_intervention_strategy(
        pathogen=pathogen,
        available_interventions=interventions,
        budget_constraint=300_000_000
    )
    
    print("Recommended strategy (within budget):")
    total_cost = 0
    for intv in optimal_strategy:
        print(f"  ✓ {intv.name}")
        if intv.cost:
            total_cost += intv.cost
    
    print(f"\nTotal cost: ${total_cost:,.0f}/month")
    
    system.initialize_population(populations)
    system.seed_infection("urban_young", initial_cases=100)
    
    optimal_ts = system.simulate_transmission(pathogen, days=180, interventions=optimal_strategy)
    
    optimal_peak_day = np.argmax(optimal_ts['I'])
    optimal_peak_cases = optimal_ts['I'][optimal_peak_day]
    optimal_total_infections = optimal_ts['R'][-1] + optimal_ts['D'][-1]
    optimal_total_deaths = optimal_ts['D'][-1]
    
    print("\n--- Results with Optimal Strategy ---\n")
    print(f"Peak infections: Day {optimal_peak_day}, {optimal_peak_cases:,.0f} active cases")
    print(f"  (Baseline: Day {peak_day}, {peak_cases:,.0f} cases)")
    print(f"  Peak reduction: {(1 - optimal_peak_cases/peak_cases):.1%}")
    
    print(f"\nTotal infections: {optimal_total_infections:,.0f}")
    print(f"  (Baseline: {total_infections:,.0f})")
    print(f"  Cases averted: {total_infections - optimal_total_infections:,.0f}")
    
    print(f"\nTotal deaths: {optimal_total_deaths:,.0f}")
    print(f"  (Baseline: {total_deaths:,.0f})")
    print(f"  Deaths averted: {total_deaths - optimal_total_deaths:,.0f}")
    
    print("\n--- Policy Recommendations ---")
    print("  1. Implement recommended intervention bundle immediately")
    print("  2. Monitor compliance rates and adjust messaging")
    print("  3. Prioritize vaccination for elderly (highest vulnerability)")
    print("  4. Prepare healthcare surge capacity for peak")
    print("  5. Re-evaluate strategy every 2 weeks with new data")
    
    print("\n--- Expected Impact ---")
    print("Traditional approach:")
    print("  • Static interventions (one-size-fits-all)")
    print("  • Delayed response (waiting for data)")
    print("  • Inefficient resource allocation")
    print("  • Higher mortality and economic cost")
    print()
    print("Embedding-based optimization:")
    print("  • Population-specific interventions")
    print("  • Proactive forecasting (simulate before implementing)")
    print("  • Cost-optimal resource allocation")
    print(f"  • {(1 - optimal_total_deaths/total_deaths):.0%} reduction in deaths")
    print("  • Flattened epidemic curve (healthcare capacity preserved)")
    print()
    print("→ Data-driven response saves lives and reduces economic impact")

# Uncomment to run:
# epidemic_modeling_example()
```

:::{.callout-tip}
## Epidemic Modeling Best Practices

**Data sources:**
- **Case data**: Confirmed cases, hospitalizations, deaths
- **Mobility data**: Cell phone data, transit ridership (aggregated, privacy-preserving)
- **Contact patterns**: Social mixing matrices by age/location
- **Genomic surveillance**: Variant tracking, transmission chains
- **Behavioral data**: Compliance with interventions, vaccine uptake

**Modeling approaches:**
- **Compartmental models**: SEIR variants for population-level dynamics
- **Agent-based models**: Individual-level simulation for heterogeneity
- **Metapopulation models**: Multiple connected populations
- **Network models**: Explicit contact networks
- **Machine learning**: Data-driven forecasting, hybrid physics-ML

**Intervention optimization:**
- **Cost-effectiveness**: Deaths/cases averted per dollar spent
- **Multi-objective**: Balance health, economic, social impacts
- **Equity**: Ensure interventions don't exacerbate disparities
- **Timing**: Optimal timing of interventions (early vs late)
- **Combination effects**: Synergies between interventions

**Production:**
- **Real-time forecasting**: Daily/weekly forecast updates
- **Uncertainty quantification**: Confidence intervals, scenario planning
- **Ensemble models**: Combine multiple models for robustness
- **Validation**: Backtest on historical outbreaks
- **Communication**: Clear visualization for policymakers

**Challenges:**
- **Data quality**: Incomplete reporting, testing biases
- **Behavioral responses**: People change behavior in response to forecasts
- **Novel pathogens**: Limited prior data for new diseases
- **Political constraints**: Interventions must be politically feasible
- **Ethical trade-offs**: Health vs liberty, individual vs collective good
:::

## Key Takeaways

:::{.callout-note}
The specific performance metrics and cost figures in the takeaways below are illustrative examples based on the code demonstrations and hypothetical scenarios presented in this chapter. They are not verified real-world results from specific healthcare organizations.
:::

- **Drug discovery acceleration with molecular embeddings enables virtual screening at scale**: Graph neural networks encode molecular structure and protein binding sites, predicting binding affinity and ADMET properties computationally, potentially reducing candidate identification from 6-12 months to 1-2 weeks and costs from $500K-$2M to $10K-$50K while achieving 10x higher hit rates through enriched computational filtering

- **Medical image analysis benefits from multi-modal embedding fusion**: Vision transformers encode radiology images while clinical encoders capture lab results, vitals, and medical history, with attention-based fusion enabling diagnosis patterns invisible to human perception, achieving 94%+ accuracy while reducing radiologist reading time by 65% and flagging urgent cases for prioritization

- **Clinical trial optimization through patient embeddings identifies optimal participants**: Multi-modal encoders combining genomics, clinical data, and biomarkers predict treatment response and dropout risk, enabling enriched enrollment that improves trial success rates from historical 10% to 25-30% while reducing time to enrollment by 50% through more efficient patient screening

- **Personalized treatment recommendations leverage patient similarity in embedding space**: Finding k-nearest neighbors among historical patients who received various treatments enables matching individuals to therapies with highest success rates in similar cases, increasing first-line treatment success from 40-50% to 65-75% and reducing time to effective treatment from 6-12 months to 0-3 months

- **Epidemic modeling with population embeddings optimizes intervention strategies**: Encoding population groups by demographics, mobility, and contact patterns enables simulation of disease spread and intervention effects before implementation, achieving 70%+ reductions in mortality through cost-optimal resource allocation while preserving healthcare capacity through flattened epidemic curves

- **Healthcare embeddings require domain-specific architectures and training**: Medical data is multi-modal (images, time series, text, structured), hierarchical (molecular to organism level), temporal (disease progression), and sparse (rare diseases, limited labels), necessitating specialized encoders, transfer learning from large pre-trained models, and multi-task training objectives

- **Regulatory compliance and clinical validation are critical for healthcare AI**: FDA clearance for diagnostic use requires prospective clinical trials, explainability through saliency maps and attention visualization satisfies physician trust requirements, bias monitoring ensures equitable performance across demographics, and continuous learning with human-in-the-loop enables safe improvement from real-world deployment

## Looking Ahead

Part V (Industry Applications) continues with Chapter 20, which applies embeddings to retail and e-commerce innovation: product discovery and matching through multi-modal embeddings combining images, text, and attributes, visual search and style transfer using computer vision embeddings, inventory optimization with demand forecasting from product and customer embeddings, customer journey analysis via sequential embeddings of interactions, and dynamic catalog management using embeddings to organize and surface products.

## Further Reading

### Drug Discovery and Molecular Design
- Stokes, Jonathan M., et al. (2020). "A Deep Learning Approach to Antibiotic Discovery." Cell.
- Senior, Andrew W., et al. (2020). "Improved Protein Structure Prediction Using Potentials from Deep Learning." Nature.
- Jumper, John, et al. (2021). "Highly Accurate Protein Structure Prediction with AlphaFold." Nature.
- Yang, Kevin, et al. (2019). "Analyzing Learned Molecular Representations for Property Prediction." Journal of Chemical Information and Modeling.
- Chen, Hongming, et al. (2018). "The Rise of Deep Learning in Drug Discovery." Drug Discovery Today.
- Schneider, Gisbert, and U. Fechner (2005). "Computer-Based De Novo Design of Drug-Like Molecules." Nature Reviews Drug Discovery.

### Medical Image Analysis
- Esteva, Andre, et al. (2017). "Dermatologist-Level Classification of Skin Cancer with Deep Neural Networks." Nature.
- Rajpurkar, Pranav, et al. (2017). "CheXNet: Radiologist-Level Pneumonia Detection on Chest X-Rays with Deep Learning." arXiv:1711.05225.
- McKinney, Scott Mayer, et al. (2020). "International Evaluation of an AI System for Breast Cancer Screening." Nature.
- Campanella, Gabriele, et al. (2019). "Clinical-Grade Computational Pathology Using Weakly Supervised Deep Learning." Nature Medicine.
- Litjens, Geert, et al. (2017). "A Survey on Deep Learning in Medical Image Analysis." Medical Image Analysis.
- Shen, Dinggang, et al. (2017). "Deep Learning in Medical Image Analysis." Annual Review of Biomedical Engineering.

### Clinical Trials and Precision Medicine
- Prosperi, Mattia, et al. (2018). "Causal Inference and Counterfactual Prediction in Machine Learning for Actionable Healthcare." Nature Machine Intelligence.
- Rajkomar, Alvin, et al. (2019). "Machine Learning in Medicine." New England Journal of Medicine.
- Beam, Andrew L., and Isaac S. Kohane (2018). "Big Data and Machine Learning in Health Care." JAMA.
- Topol, Eric J. (2019). "High-Performance Medicine: The Convergence of Human and Artificial Intelligence." Nature Medicine.
- Harrer, Stefan, et al. (2019). "Artificial Intelligence for Clinical Trial Design." Trends in Pharmacological Sciences.
- Fleming, Thomas R. (2005). "Surrogate Endpoints and FDA's Accelerated Approval Process." Health Affairs.

### Personalized Treatment
- Miotto, Riccardo, et al. (2018). "Deep Patient: An Unsupervised Representation to Predict the Future of Patients from the Electronic Health Records." Scientific Reports.
- Choi, Edward, et al. (2016). "Multi-Layer Representation Learning for Medical Concepts." KDD.
- Katzman, Jared L., et al. (2018). "DeepSurv: Personalized Treatment Recommender System Using a Cox Proportional Hazards Deep Neural Network." BMC Medical Research Methodology.
- Lee, Changhee, et al. (2018). "DeepHit: A Deep Learning Approach to Survival Analysis with Competing Risks." AAAI.
- Hamburg, Margaret A., and Francis S. Collins (2010). "The Path to Personalized Medicine." New England Journal of Medicine.
- Ashley, Euan A. (2016). "Towards Precision Medicine." Nature Reviews Genetics.

### Epidemic Modeling
- Pei, Sen, Sasikiran Kandula, and Jeffrey Shaman (2020). "Differential Effects of Intervention Timing on COVID-19 Spread in the United States." Science Advances.
- Kissler, Stephen M., et al. (2020). "Projecting the Transmission Dynamics of SARS-CoV-2 Through the Postpandemic Period." Science.
- Kerr, Cliff C., et al. (2021). "Covasim: An Agent-Based Model of COVID-19 Dynamics and Interventions." PLOS Computational Biology.
- Chang, Serina, et al. (2021). "Mobility Network Models of COVID-19 Explain Inequities and Inform Reopening." Nature.
- Ferguson, Neil M., et al. (2020). "Impact of Non-Pharmaceutical Interventions (NPIs) to Reduce COVID-19 Mortality and Healthcare Demand." Imperial College London.
- Vynnycky, Emilia, and Richard G. White (2010). "An Introduction to Infectious Disease Modelling." Oxford University Press.

### Multi-Modal Learning in Healthcare
- Huang, Shih-Cheng, et al. (2021). "Fusion of Medical Imaging and Electronic Health Records Using Deep Learning." Proceedings of the IEEE.
- Lu, Ming Y., et al. (2021). "Data-Efficient and Weakly Supervised Computational Pathology on Whole-Slide Images." Nature Biomedical Engineering.
- Acosta, Jimena N., et al. (2022). "Multimodal Biomedical AI." Nature Medicine.
- Daneshjou, Roxana, et al. (2022). "Disparities in Dermatology AI Performance on a Diverse, Curated Clinical Image Set." Science Advances.
- Ramachandram, Dhanesh, and Graham W. Taylor (2017). "Deep Multimodal Learning: A Survey on Recent Advances and Trends." IEEE Signal Processing Magazine.

### Healthcare AI Ethics and Fairness
- Obermeyer, Ziad, et al. (2019). "Dissecting Racial Bias in an Algorithm Used to Manage the Health of Populations." Science.
- Char, Danton S., Nigam H. Shah, and David Magnus (2018). "Implementing Machine Learning in Health Care—Addressing Ethical Challenges." New England Journal of Medicine.
- Gianfrancesco, Milena A., et al. (2018). "Potential Biases in Machine Learning Algorithms Using Electronic Health Record Data." JAMA Internal Medicine.
- Chen, Irene Y., et al. (2019). "Can AI Help Reduce Disparities in General Medical and Mental Health Care?" AMA Journal of Ethics.
- Vayena, Effy, Alessandro Blasimme, and I. Glenn Cohen (2018). "Machine Learning in Medicine: Addressing Ethical Challenges." PLOS Medicine.
- Rajkomar, Alvin, et al. (2018). "Ensuring Fairness in Machine Learning to Advance Health Equity." Annals of Internal Medicine.

