# Vector Database Fundamentals for Scale {#sec-vector-database-fundamentals}

:::{.callout-note}
## Chapter Overview
This chapter covers vector database architecture principles, indexing strategies for 256+ trillion rows, distributed systems considerations, performance benchmarking and SLA design, and data locality patterns for global-scale embedding deployments.
:::

## Vector Database Architecture Principles

Traditional databases were designed for exact matches: "Find customer with ID=12345" or "Return all orders where status='shipped'". Vector databases serve a fundamentally different purpose: finding semantic similarity in high-dimensional space. This section explores the architectural principles that make trillion-row vector search possible.

### Why Traditional Databases Fail for Embeddings

The scale mismatch becomes clear with a simple calculation:

```python
# Traditional database query
def find_customer(database, customer_id):
    """O(log N) with B-tree index"""
    return database.index['customer_id'].lookup(customer_id)
    # 256 trillion rows: ~48 comparisons

# Naive embedding search
def find_similar_naive(query_embedding, all_embeddings):
    """O(N * D) where N=rows, D=dimensions"""
    similarities = []
    for embedding in all_embeddings:  # 256 trillion iterations
        similarity = cosine_similarity(query_embedding, embedding)  # 768 multiplications
        similarities.append(similarity)
    return top_k(similarities, k=10)

# Cost calculation:
# 256 trillion rows × 768 dimensions = 196 quadrillion operations
# At 1 billion ops/second: 6 years per query
```

Traditional databases optimize for exact lookups and range scans. Vector databases optimize for approximate nearest neighbor (ANN) search in high-dimensional space. These are fundamentally different problems requiring different architectures.

### The Core Architectural Principles

**Principle 1: Approximate is Sufficient**

Unlike financial transactions where precision is mandatory, embedding similarity is inherently approximate. Whether an item is the 47th or 48th most similar out of 256 trillion doesn't matter—both are highly relevant.

This insight unlocks massive performance gains:

| Aspect | Traditional DB | Vector DB |
|--------|---------------|-----------|
| **Correctness** | 100% exact | 95-99% approximate |
| **Performance** | O(log N) with index | O(log N) even without perfect accuracy |
| **Use Case** | Exact match, transactions | Semantic similarity, recommendations |

The key insight: trading a small amount of accuracy for massive speed gains. Finding the top-10 most similar items from 256T vectors via exact search is infeasible—approximate search with HNSW achieves 95%+ correct results in <100ms.

**Principle 2: Geometry Matters More Than Algebra**

Vector databases leverage geometric properties of high-dimensional spaces:

```python
{{< include /code_examples/ch04_vector_database_fundamentals/geometricintuition.py >}}
```

**Principle 3: Hierarchical Navigation is Key**

The breakthrough insight: you don't need to compare with all vectors, just navigate through the space efficiently.

```python
{{< include /code_examples/ch04_vector_database_fundamentals/hierarchicalnavigation.py >}}
```

**Principle 4: Index Structure is Everything**

The choice of index structure determines performance, accuracy, and scalability:

| Index | Build Time | Query Time | Memory | Accuracy | Max Scale | Use Case |
|-------|-----------|------------|--------|----------|-----------|----------|
| **Flat** | O(N) | O(N×D) | O(N×D) | 100% | ~1M | Ground truth |
| **IVF** | O(N×k) | O((N/k)×D×n_probe) | O(N×D+k×D) | 80-95% | ~1B | Balanced |
| **HNSW** | O(N×log(N)×M) | O(log(N)×M) | O(N×(D+M)) | 95-99% | 100B+ | Production (best tradeoff) |
| **LSH** | O(N×L) | O(L×bucket) | O(N×L) | 70-90% | Trillion+ | Ultra-massive scale |
| **PQ** | O(N×iter) | O(N) compressed | O(N×code) | 85-95% | 10B+ | Memory-constrained |

HNSW is the gold standard for high-performance production systems due to its best accuracy/speed tradeoff at scale.

### Production Vector Database Architecture

A production-grade vector database at trillion-row scale needs these core layers:

- **Ingestion**: API gateway, validation, batching, rate limiting (100K-1M embeddings/sec)
- **Storage**: Raw embeddings (cold/S3), indices (hot/SSD), metadata (separate DB), WAL
- **Index**: HNSW graphs, IVF, product quantization, background rebuilder
- **Query**: Parser, planner, distributed executor, result aggregator, LRU cache
- **Metadata**: Filter optimizer, join coordinator (pre-filter vs post-filter)
- **Serving**: Load balancer, router, circuit breaker, adaptive throttling
- **Monitoring**: Latency percentiles, QPS, recall@k, resource utilization, alerts

**Key design patterns for trillion-scale:**

- *Sharding*: 100M-1B vectors per shard, 1000-10000 shards total, hash-based assignment
- *Replication*: 3x for availability, eventual consistency, async replication
- *Caching*: LRU query cache, hot index pages in memory (>80% hit rate target)
- *Versioning*: Multi-version indices for zero-downtime updates and A/B testing

```python
class ShardCalculator:
    """Calculate optimal sharding configuration"""

    def calculate_shards(self, total_vectors, vectors_per_shard_target, replication_factor=3):
        """
        Determine optimal shard count

        Example: 256T vectors, target 256M vectors/shard
        """
        ideal_shards = total_vectors / vectors_per_shard_target

        # Round to nearest power-of-2 for consistent hashing
        import math
        actual_shards = 2 ** math.ceil(math.log2(ideal_shards))

        vectors_per_shard = total_vectors / actual_shards

        # Storage calculation
        embedding_dim = 768
        bytes_per_vector = embedding_dim * 4  # float32

        # HNSW index overhead (~1.5x raw data)
        index_overhead = 1.5

        storage_per_shard_gb = (
            vectors_per_shard * bytes_per_vector * index_overhead / (1024**3)
        )

        total_storage_gb = storage_per_shard_gb * actual_shards * replication_factor

        return {
            'total_vectors': total_vectors,
            'num_shards': actual_shards,
            'vectors_per_shard': vectors_per_shard,
            'storage_per_shard_gb': storage_per_shard_gb,
            'total_storage_gb': total_storage_gb,
            'total_storage_tb': total_storage_gb / 1024,
            'replication_factor': replication_factor,
            'recommended_machine_spec': {
                'memory_gb': storage_per_shard_gb * 1.2,  # 20% overhead
                'cpu_cores': 16,
                'disk_type': 'NVMe SSD',
                'network': '10Gbps+'
            }
        }

# Calculate for 256T vectors
calc = ShardCalculator()
config = calc.calculate_shards(
    total_vectors=256_000_000_000_000,
    vectors_per_shard_target=256_000_000
)

print(f"Shard configuration for 256T vectors:")
print(f"  Shards: {config['num_shards']:,}")
print(f"  Vectors/shard: {config['vectors_per_shard']:,}")
print(f"  Storage/shard: {config['storage_per_shard_gb']:.1f} GB")
print(f"  Total storage: {config['total_storage_tb']:.1f} TB")
```

:::{.callout-important}
## Architecture First, Scaling Later
The most expensive mistake: starting with single-node architecture and retrofitting for scale. Design for distribution from day one, even if you start with one machine. The patterns are the same, only the scale changes.
:::

## Indexing Strategies for 256+ Trillion Rows

Scaling to 256 trillion embeddings requires sophisticated indexing strategies that balance accuracy, speed, memory, and build time. This section explores battle-tested approaches.

### The Indexing Challenge at Scale

Consider the constraints:

```python
class ScaleConstraints:
    """Understanding what makes 256T rows challenging"""

    def memory_constraints(self):
        """Why you can't fit everything in RAM"""

        num_vectors = 256_000_000_000_000
        embedding_dim = 768
        bytes_per_float = 4

        # Raw embeddings
        raw_bytes = num_vectors * embedding_dim * bytes_per_float
        raw_petabytes = raw_bytes / (1024 ** 5)

        # HNSW index (adds ~50% overhead for graph structure)
        index_petabytes = raw_petabytes * 1.5

        # Total memory needed if all in RAM
        total_memory_pb = index_petabytes

        # Cost analysis
        # AWS r6i.32xlarge: 1TB RAM, $8.064/hour
        machines_needed = total_memory_pb * 1024  # Convert to TB
        monthly_cost = machines_needed * 8.064 * 24 * 30

        return {
            'raw_data_size_pb': raw_petabytes,
            'with_index_size_pb': index_petabytes,
            'machines_needed_1tb_ram': int(machines_needed),
            'monthly_cost_if_all_ram': f'${monthly_cost:,.0f}',
            'conclusion': 'Infeasible - must use hybrid memory/disk strategies'
        }

    def build_time_constraints(self):
        """How long to build index from scratch"""

        num_vectors = 256_000_000_000_000

        # HNSW build time: ~100 microseconds per vector (empirical)
        microseconds_per_vector = 100
        total_seconds = (num_vectors * microseconds_per_vector) / 1_000_000
        total_days = total_seconds / (60 * 60 * 24)
        total_years = total_days / 365

        # Parallel building across 10,000 machines
        parallel_machines = 10_000
        parallel_days = total_days / parallel_machines

        return {
            'single_machine_build_time_years': total_years,
            'parallel_build_time_days': parallel_days,
            'conclusion': 'Must parallelize + use incremental updates'
        }

    def query_time_constraints(self):
        """Target query latency"""

        target_p99_latency_ms = 100
        target_qps = 1_000_000  # 1M queries per second globally

        # Available time budget
        time_budget_ms = target_p99_latency_ms

        # Breakdown
        breakdown = {
            'network_latency': '20ms (to nearest region)',
            'query_parsing': '1ms',
            'index_search': '50ms (the critical path)',
            'metadata_filtering': '10ms',
            'result_aggregation': '5ms',
            'serialization': '5ms',
            'buffer': '9ms (for variance)',
            'total': '100ms'
        }

        return {
            'target_p99_ms': target_p99_latency_ms,
            'breakdown': breakdown,
            'index_search_budget': '50ms',
            'implication': 'Index must return results in <50ms at p99'
        }

constraints = ScaleConstraints()
mem_constraints = constraints.memory_constraints()
print(f"Memory needed: {mem_constraints['with_index_size_pb']:.1f} PB")
print(f"Cost if all in RAM: {mem_constraints['monthly_cost_if_all_ram']}")
# Output: Memory needed: 1179.6 PB, Cost: $71,145,984,000/month
```

Clearly, naïve approaches won't work. We need sophisticated indexing strategies.

### Strategy 1: Hierarchical Navigable Small World (HNSW)

HNSW is the gold standard for high-recall, low-latency vector search. Understanding how it works is essential for trillion-scale deployments.

**Core Concept**: HNSW builds a multi-layer proximity graph where:

- Upper layers have long-range connections (for fast navigation)
- Lower layers have short-range connections (for high accuracy)
- Search starts at top layer and descends, getting more refined

```python
{{< include /code_examples/ch04_vector_database_fundamentals/hnswdeepdive.py >}}
```

**HNSW at Trillion Scale: Practical Considerations**

**Sharding**: Use horizontal sharding with 100M-1B vectors per shard. Query all shards in parallel, merge top-k. For optimization, use IVF-HNSW hybrid: IVF for coarse partitioning (5-10x speedup), HNSW within partitions.

**Incremental Updates**:

- *Online inserts*: Add to existing graph, O(log N × M × ef_construction), 10-100ms per insert
- *Batch inserts*: Build mini-HNSW, merge with main graph
- *Deletions*: Soft delete (filter at query time) with periodic rebuild
- *Updates*: Delete + re-insert; rebuild when >20% of vectors changed

**Memory Optimization**:

- *Tiered storage*: Layer 0 in RAM, upper layers on SSD, embeddings on slow storage (60-80% reduction, <10ms latency impact)
- *Graph compression*: 30-50% savings with slight decompression overhead
- *32-bit IDs*: 50% savings on graph structure (limits to 4B vectors/shard)
- *Memory-mapping*: Let OS manage hot/cold page paging

```python
def calculate_memory_savings():
    """Memory savings from optimization techniques"""
    vectors = 1_000_000_000  # 1B vectors
    M, dim = 48, 768

    # Baseline: everything in RAM
    baseline_gb = (vectors * dim * 4 + vectors * M * 8) / (1024**3)

    # Optimized: embeddings on SSD, 32-bit IDs, compression
    optimized_gb = (vectors * M * 4 * 0.7) / (1024**3)

    return f"Baseline: {baseline_gb:.0f} GB → Optimized: {optimized_gb:.0f} GB ({(1-optimized_gb/baseline_gb)*100:.0f}% savings)"

# Output: Baseline: 3214 GB → Optimized: 125 GB (96% savings)
```

### Strategy 2: IVF (Inverted File Index) with Product Quantization

While HNSW is excellent for recall and latency, IVF-PQ excels at massive scale with memory constraints.

**Core Concept**: IVF partitions the space into Voronoi cells. Search checks only the cells nearest to query. Product Quantization compresses vectors 20-100x.

```python
{{< include /code_examples/ch04_vector_database_fundamentals/ivfpqstrategy.py >}}
```

**HNSW vs IVF-PQ Trade-offs**

| Dimension | HNSW | IVF-PQ | Winner |
|-----------|------|--------|--------|
| **Memory** | 1.5-2x raw data | 0.02-0.05x (20-50x compression) | IVF-PQ |
| **Recall** | 95-99% | 85-95% | HNSW |
| **Latency (p99)** | 20-100ms | 50-200ms | HNSW |
| **Build Time** | Slower (graph construction) | Faster (k-means) | IVF-PQ |
| **Updates** | Easy incremental | Must reassign centroids | HNSW |
| **Max Scale** | ~100B vectors | Trillions+ | IVF-PQ |

**When to use each:**

- **HNSW**: High recall (>95%), low latency (<100ms p99), frequent updates, sufficient memory
- **IVF-PQ**: Memory constrained, can tolerate 85-90% recall, infrequent updates, trillion+ scale
- **Hybrid IVF-HNSW**: Best of both—IVF for coarse search, HNSW within partitions

```python
def recommend_index_strategy(num_vectors, memory_budget_gb, recall_requirement, latency_p99_ms):
    """Recommend index strategy based on requirements"""
    embedding_dim = 768
    raw_data_gb = (num_vectors * embedding_dim * 4) / (1024**3)
    hnsw_memory_gb = raw_data_gb * 1.7
    ivf_pq_memory_gb = raw_data_gb * 0.03

    if memory_budget_gb >= hnsw_memory_gb and recall_requirement >= 0.95 and latency_p99_ms <= 100:
        return "HNSW"
    if memory_budget_gb < hnsw_memory_gb and recall_requirement < 0.90:
        return "IVF-PQ"
    if recall_requirement >= 0.93:
        return "Hybrid IVF-HNSW"
    return "IVF-PQ with high n_probe"
```

### Strategy 3: Sharding and Distribution Patterns

At trillion scale, no single machine can hold the full index. Sharding is mandatory.

| Pattern | Strategy | Pros | Cons | Use Case |
|---------|----------|------|------|----------|
| **Random** | Hash(vector_id) % num_shards | Even distribution, simple | Must query all shards | Default choice |
| **Learned** | K-means cluster, route by centroid | 5-10x faster (fewer shards) | Uneven load, complex rebalancing | Domain-specific queries |
| **Geographic** | Full copy per region | Low latency, compliance | Higher storage cost | Global applications |
| **Hybrid** | Geo + learned + random tiers | Best of all worlds | Most complex | Large-scale production |

```python
def calculate_query_fanout(total_shards, strategy):
    """Calculate how many shards must be queried"""
    if strategy == 'random':
        return total_shards  # Must query all
    elif strategy == 'learned':
        return min(10, total_shards // 10)  # 10x speedup
    elif strategy == 'geo':
        return total_shards // 3  # One region only

# Example: 1000 total shards
# Random: 1000 shards queried
# Learned: 100 shards queried (10x speedup)
# Geographic: 333 shards queried (in-region only)
```

## Distributed Systems Considerations

Vector databases at trillion-scale are distributed systems, inheriting all the challenges of distributed computing: consistency, availability, partition tolerance, and coordination.

### The CAP Theorem for Vector Databases

Vector databases choose **AP (Availability + Partition Tolerance)** over strong consistency. This is the right tradeoff because embeddings are inherently approximate—if one replica has slightly outdated embeddings, query results are still useful.

**Consistency requirements by operation:**

- **Writes/Inserts**: Eventual consistency. Write to primary, async replicate. New embedding visible within 5 seconds.
- **Updates/Deletions**: Eventual consistency with tombstones. Deleted items filtered at query time.
- **Reads/Queries**: Read-your-writes for same session (via session affinity). May see stale data from other users—acceptable.
- **Metadata filters**: Strong consistency required. Security filters (user access) must be immediate.

**Availability techniques**: 3x replication, read from any replica, automatic failover, circuit breakers. Target: 99.99%.

**Partition tolerance**: Gracefully degrade by serving cached results, partial results from available shards, or falling back to multi-region replicas.

### Replication Strategies

**Primary-Replica (Leader-Follower)**

The default choice for most vector databases. One primary handles all writes; 2+ replicas handle reads with async replication. Write path: client → primary → ACK → async replicate. Read path: query any replica.

*Pros*: Simple, read-scalable, write-consistent. *Cons*: Write bottleneck, 30-60s failover time, replica lag.

**Multi-Primary (Multi-Leader)**

For multi-region deployments with high write throughput. Multiple nodes accept writes with bidirectional replication. Conflicts resolved via last-write-wins (timestamps) or custom logic.

*Pros*: Write-scalable, low latency (write to nearest), no single point of failure. *Cons*: Complex conflict resolution, potential inconsistency.

**Leaderless (Quorum-Based)**

All nodes equal; write to W nodes, read from R nodes. With N=3, W=2, R=2, W+R>N ensures reads see latest writes.

*Pros*: High availability, no leader election delay. *Cons*: Higher latency, complex client logic. Rarely used for vector databases—complexity not worth it.

**Choosing a Strategy:**

- Multi-region + high writes → Multi-primary (leader per region)
- Low writes + high reads → Primary-replica with many replicas
- Default → Primary-replica (simple, reliable)

### Failure Modes and Recovery

:::{.callout-warning}
## Node Failure
**Probability**: High (MTBF ~3-5 years per machine)
**Impact**: Loss of one shard or replica
**Detection**: Heartbeat timeout (10-30 seconds)
**Recovery**: Remove from load balancer → serve from replica → spawn replacement → rebuild index (5-30 minutes)
**Data Loss**: None with proper replication
:::

:::{.callout-warning}
## Disk Failure
**Probability**: Medium (MTBF ~4 years per disk)
**Detection**: I/O errors, SMART metrics
**Recovery**: Switch to replica → replace disk → restore from backup → rebuild index (1-4 hours)
:::

:::{.callout-warning}
## Network Partition
**Probability**: Medium (datacenter network issues)
**Impact**: Subset of nodes unreachable
**Recovery**: Serve from available partition with graceful degradation (partial results), resync after partition resolves
:::

:::{.callout-caution}
## Index Corruption
**Probability**: Low but critical
**Detection**: Checksums, recall monitoring (sudden drop), user reports
**Recovery**: Rollback to previous version or rebuild from raw embeddings (1-8 hours)
:::

:::{.callout-caution}
## Query of Death
**Probability**: Low but high impact (cascading failures)
**Prevention**: Query timeouts, input validation, circuit breakers, load shedding
:::

### Disaster Recovery

For region-level failures, maintain multi-region replication with automated failover:

1. Detect region failure via health checks
2. Update DNS/routing to backup region
3. Promote backup region to primary
4. Scale up if needed
5. Investigate and restore primary region
6. Resync and failback

Target RPO <5 minutes, RTO <15 minutes. Cost: 2x infrastructure for active-active deployment.

### Chaos Engineering

Test failures proactively using tools like Chaos Monkey, Gremlin, or LitmusChaos:

- Terminate random nodes (10% of fleet)
- Inject network latency (100-500ms)
- Simulate datacenter partitions
- Corrupt index files

Run weekly in staging, monthly in production. Success criteria: query success rate >99.9%, latency within SLA, automatic recovery without human intervention.

### Coordination and Consensus

Operations requiring coordination in distributed vector databases:

- **Shard assignment**: Which vectors belong to which shards. Use ZooKeeper/etcd/Consul with strong consistency to avoid double-assignment. Updates are infrequent (only during rebalancing).
- **Leader election**: Which node is primary for each shard. Use Raft/Paxos consensus with strong consistency to avoid split-brain. Updates only on failures.
- **Schema changes**: Embedding dimension changes, index upgrades. Use centralized config service with strong consistency—all nodes must agree.
- **Global counters**: Total vector count, statistics. Use eventual consistency—approximate values are acceptable.

:::{.callout-tip}
## Minimize Coordination
Coordination limits scalability. Prefer deterministic approaches: use `Hash(vector_id) % num_shards` instead of querying a coordinator. Use immutable assignments, eventual consistency for non-critical paths, and CRDTs where possible.
:::

## Performance Benchmarking and SLA Design

Production vector databases require rigorous SLA design and continuous performance monitoring. This section covers benchmarking methodologies and SLA patterns.

### Defining SLA Metrics

Core SLA metrics for vector databases:

| Metric | Typical Target | Business Impact |
|--------|---------------|-----------------|
| **Query Latency** | p50 <20ms, p95 <50ms, p99 <100ms | Every 100ms → 1% conversion loss |
| **Recall@K** | recall@10 >0.95, recall@100 >0.98 | Low recall → users don't find relevant items |
| **Throughput** | 1K-10K QPS/shard, 100K-1M global | Insufficient → requests queued or dropped |
| **Availability** | 99.99% (52 min downtime/year) | Downtime → lost revenue |
| **Index Freshness** | <5 minutes to queryable | Stale data → missing new items |
| **Resource Utilization** | CPU <70%, Memory <85%, Disk I/O <80% | Over-utilization → latency spikes |

**Availability budget by target:**

| Target | Allowed Downtime |
|--------|-----------------|
| 99% | 3.65 days/year |
| 99.9% | 8.76 hours/year |
| 99.99% | 52.6 minutes/year |
| 99.999% | 5.26 minutes/year |

**SLI vs SLO vs SLA:**

- **SLI (Service Level Indicator)**: Quantitative measurement (e.g., "p99 latency: 78ms")
- **SLO (Service Level Objective)**: Internal target (e.g., "p99 < 100ms")
- **SLA (Service Level Agreement)**: Contract with consequences (e.g., "p99 < 100ms or 10% credit")

### Benchmarking Methodology

Key benchmark dimensions for vector databases:

| Category | Metrics | Variables |
|----------|---------|-----------|
| **Index Build** | Build time, throughput (vec/sec), peak memory, CPU | Dataset size, dimensions, index params (M, ef) |
| **Query** | p50/p95/p99 latency, QPS, recall@10/100 | K, ef_search, query distribution, concurrency |
| **Updates** | Insert latency/throughput, recall drift | Insert rate, update fraction |
| **Scalability** | Latency/memory vs size | Test at 1M, 10M, 100M, 1B, 10B vectors |

Standard benchmark datasets include SIFT-1M (1M vectors, 128 dims), Deep1B (1B vectors, 96 dims), and LAION-5B (5B vectors, 768 dims). However, production data provides the most accurate benchmarks since query distributions differ from academic datasets.

```python
import numpy as np
import time

def measure_recall(index, embeddings, k=10, num_queries=100):
    """Measure recall@k by comparing approximate vs exact search"""
    total_recall = 0
    for _ in range(num_queries):
        query_idx = np.random.randint(0, len(embeddings))
        query = embeddings[query_idx]

        # Ground truth: brute force exact search
        distances = np.linalg.norm(embeddings - query, axis=1)
        true_top_k = set(np.argsort(distances)[:k])

        # Approximate search
        approx_top_k = set(index.search(query, k=k))

        recall = len(true_top_k & approx_top_k) / k
        total_recall += recall

    return total_recall / num_queries

def benchmark_latency(index, embedding_dim, num_queries=10000):
    """Measure query latency percentiles"""
    latencies = []
    for _ in range(num_queries):
        query = np.random.randn(embedding_dim).astype(np.float32)
        start = time.time()
        index.search(query, k=10)
        latencies.append((time.time() - start) * 1000)

    latencies = np.array(latencies)
    return {
        'p50_ms': np.percentile(latencies, 50),
        'p95_ms': np.percentile(latencies, 95),
        'p99_ms': np.percentile(latencies, 99)
    }
```

### Load Testing and Capacity Planning

Essential load test scenarios for vector databases:

- **Steady State**: Maintain target QPS (e.g., 100K) for 1 hour. Verify p99 <100ms, no errors, stable resource usage.
- **Ramp Up**: Gradually increase 0→200K QPS over 30 minutes to find breaking point and verify graceful degradation.
- **Spike**: Sudden burst (50K→500K QPS for 5 minutes) to test autoscaling—system should scale within 2 minutes.
- **Sustained Peak**: 150K QPS for 8 hours to detect memory leaks and resource exhaustion.
- **Thundering Herd**: 1M simultaneous requests to test queue depth control and load shedding.
- **Geographic**: Multi-region simultaneous load to verify routing and cross-region failover.

For capacity planning, assume ~10K QPS per shard and maintain 2x headroom for spikes. With 50% YoY growth, plan 3 years ahead: 100K QPS today requires 20 shards with headroom, growing to 68 shards by year 3.

## Data Locality and Global Distribution

For trillion-row systems serving global users, data locality and geographic distribution are critical for latency and compliance.

### Geographic Distribution Patterns

Four primary patterns exist for global vector database deployment:

**Full Replication**: Complete copy of all embeddings in each region. Provides lowest query latency and highest availability, but at 5x storage cost. Best for global consumer applications requiring <100ms latency SLA.

**Regional Sharding**: Partition data by region (US, EU, APAC). Lower storage cost and enables data sovereignty compliance, but cross-region queries are expensive. Best for inherently regional data.

**Tiered Distribution**: Hot data (top 10%) in all regions, cold data (remaining 60%) in primary region only. Balances cost and latency with 60-80% savings vs full replication. Best for Zipfian access patterns.

**Edge Caching**: CDN-style caching at 100+ edge locations for top 1% most-queried embeddings. Achieves <20ms latency globally with 85-95% cache hit rates. Best for product search and recommendations.

### Data Residency Compliance

For GDPR compliance, EU citizen data must stay in EU datacenters with replication only within EU (Paris, Frankfurt, Ireland). Implementation requires tagging embeddings with region constraints, enforcing at ingestion, maintaining audit trails, and encrypting with EU-only keys.

For CCPA, maintain user_id → embedding_ids mappings to support deletion requests within 30 days across all replicas.

For China's Cybersecurity Law, operate a completely separate China region with no cross-border data transfer.

### Latency Optimization

Key strategies for minimizing global latency:

- **Geo DNS**: Route users to nearest datacenter (100-200ms reduction)
- **Anycast**: Single IP routing to nearest PoP via CloudFlare/Fastly
- **Prefetching**: Predict and precompute likely queries (50-100ms reduction)
- **Query result caching**: Redis/Memcached with 5-60 minute TTL (60-80% hit rate)
- **Compression**: gzip/brotli for results (10-50ms reduction)

## Key Takeaways

- **Vector databases are fundamentally different from traditional databases**—optimized for approximate nearest neighbor search in high-dimensional space rather than exact matches, making approximate results and geometric reasoning core architectural principles

- **HNSW is the gold standard for high-recall, low-latency search** at billion to trillion scale, achieving O(log N) query complexity through hierarchical graph navigation, with typical configurations (M=32-64, ef_construction=200-400) delivering 95-99% recall at <100ms p99

- **IVF-PQ provides extreme memory efficiency** with 20-100x compression through coarse quantization and product quantization, making it the best choice for memory-constrained trillion-scale deployments despite slightly lower recall (85-95%)

- **Sharding is mandatory at trillion-scale**—with typical configurations of 100M-1B vectors per shard and 1000-10000 total shards, using random sharding for simplicity or learned sharding for query locality when access patterns allow

- **Vector databases choose AP over C in the CAP theorem**, prioritizing availability and partition tolerance with eventual consistency for embeddings (acceptable due to inherent approximation) while maintaining strong consistency for critical metadata like access controls

- **SLA design requires percentile-based latency targets** (p99 <100ms is typical), recall guarantees (>95% recall@10), and availability targets (99.99%), measured continuously with public dashboards and automated alerting on violations

- **Global distribution requires geographic strategies**—full replication for lowest latency (5x cost), regional sharding for data sovereignty (lower cost), tiered distribution for balanced cost/latency (60-80% savings), or edge caching for popular queries (85-95% hit rates)

## Looking Ahead

Part II begins with Chapter 4, where we explore when and how to build custom embeddings versus fine-tuning pre-trained models—the crucial decision that determines whether you achieve true competitive differentiation or settle for commodity capabilities.

## Further Reading

- Malkov, Y. A., & Yashunin, D. A. (2018). "Efficient and robust approximate nearest neighbor search using Hierarchical Navigable Small World graphs." *IEEE Transactions on Pattern Analysis and Machine Intelligence*
- Jégou, H., Douze, M., & Schmid, C. (2011). "Product Quantization for Nearest Neighbor Search." *IEEE Transactions on Pattern Analysis and Machine Intelligence*
- Johnson, J., Douze, M., & Jégou, H. (2019). "Billion-scale similarity search with GPUs." *IEEE Transactions on Big Data*
- Aumüller, M., Bernhardsson, E., & Faithfull, A. (2020). "ANN-Benchmarks: A Benchmarking Tool for Approximate Nearest Neighbor Algorithms." *Information Systems*
- Brewer, E. A. (2012). "CAP twelve years later: How the 'rules' have changed." *Computer*
- Gormley, C., & Tong, Z. (2015). *Elasticsearch: The Definitive Guide*. O'Reilly Media
- Kleppmann, M. (2017). *Designing Data-Intensive Applications*. O'Reilly Media
- Beyer, B., et al. (2016). *Site Reliability Engineering: How Google Runs Production Systems*. O'Reilly Media
