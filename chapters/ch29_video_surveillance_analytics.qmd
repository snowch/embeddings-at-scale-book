# Video Surveillance and Analytics {#sec-video-surveillance}

:::{.callout-note}
## Chapter Overview
Video surveillance and analytics—from retail loss prevention to smart city safety to industrial compliance monitoring—generates more embedding vectors than almost any other application domain, with a single camera producing 86,400 frame embeddings per day and enterprise deployments spanning thousands of cameras. This chapter applies embeddings to video analytics at scale: real-time video stream processing using efficient frame and clip embeddings that enable sub-second event detection across thousands of concurrent camera feeds, person re-identification tracking individuals across multiple cameras and time periods through appearance embeddings robust to pose, lighting, and occlusion changes, action and behavior recognition detecting activities of interest from temporal embeddings that capture motion patterns and human-object interactions, anomaly detection identifying unusual events without explicit training through deviation from learned normal behavior patterns, forensic video search enabling rapid retrieval of specific events, people, or objects across weeks of archived footage through semantic video embeddings, and privacy-preserving analytics that extract actionable insights while protecting individual privacy through on-device processing, face blurring, and federated learning. These techniques transform video from passive recording to active intelligence across retail (shoplifting detection, customer analytics), smart cities (traffic management, public safety), manufacturing (safety compliance, quality inspection), healthcare (patient monitoring, fall detection), and security (access control, perimeter monitoring)—enabling organizations to derive value from the petabytes of video they capture while respecting privacy and operating within resource constraints.
:::

After exploring defense and intelligence applications (@sec-defense-intelligence), embeddings enable **video surveillance transformation** at unprecedented scale. Traditional video monitoring relies on human operators watching screens—an approach that fails at scale (one operator can effectively monitor 4-8 cameras) and misses critical events during lapses in attention. **Embedding-based video analytics** converts continuous video streams into searchable, analyzable vector representations, enabling automated detection, tracking, and search across camera networks that would be impossible with human review alone—while raising important considerations around privacy, bias, and appropriate use.

## Real-Time Video Stream Processing

Processing live video at scale requires efficient embedding generation that balances accuracy with throughput. **Real-time video processing** extracts embeddings from frames or clips fast enough to enable immediate detection and alerting across thousands of concurrent streams.

### The Real-Time Processing Challenge

Traditional video analytics faces limitations:

- **Throughput**: Processing thousands of concurrent HD/4K streams
- **Latency**: Detection must occur within seconds for actionable alerts
- **Resource constraints**: GPU compute is expensive; efficiency matters
- **Variable content**: Cameras span indoor/outdoor, day/night, crowded/empty scenes
- **24/7 operation**: Systems must run continuously without degradation

**Embedding approach**: Extract lightweight frame embeddings for rapid scene understanding, with deeper clip embeddings for detected events. Hierarchical processing prioritizes compute on interesting regions and time periods.

```python
{{< include /code_examples/ch29_video_surveillance/realtime_processing.py >}}
```

:::{.callout-tip}
## Real-Time Processing Best Practices

**Architecture:**

- **Edge-cloud hybrid**: Initial processing at edge, detailed analysis in cloud
- **Hierarchical models**: Fast detector triggers slower, accurate classifier
- **Batch processing**: Aggregate frames across cameras for GPU efficiency
- **Keyframe extraction**: Process representative frames, not every frame
- **Region of interest**: Focus compute on relevant image areas

**Efficiency:**

- **Model quantization**: INT8 inference for 2-4× speedup with minimal accuracy loss
- **Knowledge distillation**: Train small models to mimic large ones
- **Temporal redundancy**: Skip similar consecutive frames
- **Resolution adaptation**: Process at lower resolution when sufficient
- **Hardware acceleration**: TensorRT, OpenVINO for optimized inference

**Scalability:**

- **Horizontal scaling**: Add processing nodes as camera count grows
- **Load balancing**: Distribute streams across available compute
- **Priority queuing**: Process high-priority cameras first
- **Graceful degradation**: Reduce frame rate under load vs dropping streams
- **Auto-scaling**: Spin up resources during peak activity

**Reliability:**

- **Stream reconnection**: Handle camera disconnects gracefully
- **Failover**: Redundant processing for critical cameras
- **Health monitoring**: Track processing latency and queue depth
- **Alerting**: Notify operators of system issues
- **Graceful shutdown**: Complete in-flight processing before restart
:::

## Person Re-Identification

Person re-identification (Re-ID) tracks individuals across multiple cameras without relying on face recognition. **Embedding-based Re-ID** learns appearance representations that remain consistent across viewpoints, lighting conditions, and time.

### The Re-ID Challenge

Traditional person tracking faces limitations:

- **Camera gaps**: People disappear between camera fields of view
- **Appearance changes**: Lighting, pose, and occlusion vary across cameras
- **Scale**: Large venues may have hundreds of cameras
- **Time gaps**: Need to match across minutes to hours
- **Privacy**: Face recognition raises significant privacy concerns

**Embedding approach**: Learn person embeddings from full-body appearance (clothing, body shape, gait) that generalize across cameras. Similar embeddings indicate the same person; enable tracking without biometric identification.

```python
{{< include /code_examples/ch29_video_surveillance/person_reid.py >}}
```

:::{.callout-tip}
## Person Re-ID Best Practices

**Feature extraction:**

- **Part-based models**: Encode head, torso, legs separately for robustness
- **Attention mechanisms**: Focus on discriminative regions
- **Multi-scale features**: Capture both fine details and global appearance
- **Temporal pooling**: Aggregate features across multiple frames
- **Occlusion handling**: Learn to ignore occluded body parts

**Training:**

- **Triplet loss**: Pull same-person embeddings together, push different apart
- **Hard mining**: Focus on difficult examples (similar different people)
- **Domain adaptation**: Fine-tune on target camera network
- **Data augmentation**: Random erasing, color jitter, pose variation
- **Cross-camera pairs**: Train on same person across different cameras

**Deployment:**

- **Gallery management**: Maintain embeddings for tracked individuals
- **Matching threshold**: Balance precision (false matches) vs recall (missed matches)
- **Temporal constraints**: Weight recent observations higher
- **Spatial constraints**: Use camera topology to prune impossible matches
- **Batch matching**: Efficient similarity search across large galleries

**Evaluation:**

- **Rank-1 accuracy**: Correct match in top result
- **mAP**: Mean average precision across queries
- **Cross-camera**: Separate evaluation per camera pair
- **Time gap**: Performance vs time between observations
- **Occlusion robustness**: Performance on partially visible persons
:::

:::{.callout-warning}
## Re-ID Privacy Considerations

Person re-identification enables tracking without explicit consent:

- **Scope limitation**: Only track within defined areas with notice
- **Retention limits**: Delete tracking data after defined period
- **Purpose restriction**: Use only for stated security purposes
- **Audit trails**: Log all re-identification queries and results
- **Opt-out mechanisms**: Provide ways to request non-tracking where feasible
- **Bias testing**: Evaluate accuracy across demographic groups
- **Human review**: Require human confirmation for consequential actions
:::

## Action and Behavior Recognition

Action recognition detects activities of interest in video—from safety violations to suspicious behavior to customer interactions. **Embedding-based action recognition** learns temporal representations that capture motion patterns and human-object interactions.

### The Action Recognition Challenge

Traditional rule-based detection faces limitations:

- **Complexity**: Human actions are highly variable and context-dependent
- **Subtlety**: Important behaviors may be brief or partially occluded
- **Context**: Same motion means different things in different contexts
- **Scale**: Need to detect across many action categories
- **Novelty**: New behaviors emerge that weren't anticipated

**Embedding approach**: Learn clip embeddings that capture spatiotemporal patterns. Similar actions cluster in embedding space; enable both classification of known actions and detection of anomalous behaviors.

```python
{{< include /code_examples/ch29_video_surveillance/action_recognition.py >}}
```

:::{.callout-tip}
## Action Recognition Best Practices

**Temporal modeling:**

- **3D convolutions**: Capture spatiotemporal patterns directly
- **Two-stream**: Separate RGB (appearance) and optical flow (motion) networks
- **Temporal transformers**: Attention across frames for long-range dependencies
- **Recurrent models**: LSTM/GRU for sequential action modeling
- **Temporal segment networks**: Sample frames across action duration

**Application-specific:**

- **Retail**: Concealment detection, checkout behavior, customer service interactions
- **Safety**: PPE compliance, unsafe actions, fall detection
- **Security**: Loitering, tailgating, perimeter breach
- **Healthcare**: Patient mobility, fall risk behaviors, staff compliance
- **Traffic**: Accidents, wrong-way driving, pedestrian violations

**Training strategies:**

- **Clip sampling**: Random temporal crops during training
- **Multi-scale**: Detect actions at different temporal granularities
- **Weakly supervised**: Learn from video-level labels without frame annotations
- **Self-supervised**: Pre-train on unlabeled video (temporal order, speed prediction)
- **Transfer learning**: Fine-tune from Kinetics, AVA, or similar large datasets

**Deployment:**

- **Sliding window**: Apply classifier across video with overlap
- **Action proposals**: First detect when actions occur, then classify
- **Streaming inference**: Process video as it arrives without buffering
- **Confidence calibration**: Reliable uncertainty for alerting decisions
- **Contextual filtering**: Reduce false positives using scene context
:::

## Anomaly Detection in Video

Anomaly detection identifies unusual events without requiring explicit training examples. **Embedding-based video anomaly detection** learns representations of normal behavior and flags deviations.

### The Anomaly Detection Challenge

Traditional supervised detection faces limitations:

- **Rare events**: Anomalies are by definition uncommon; limited training data
- **Unknown unknowns**: Can't train for events never seen before
- **Context dependence**: Normal varies by time, location, and situation
- **False positives**: Unusual but benign events trigger alerts
- **Concept drift**: Normal behavior evolves over time

**Embedding approach**: Learn compressed representations of normal video; anomalies have high reconstruction error or low likelihood under the learned model. No explicit anomaly labels required.

```python
{{< include /code_examples/ch29_video_surveillance/anomaly_detection.py >}}
```

:::{.callout-tip}
## Video Anomaly Detection Best Practices

**Learning normal:**

- **Autoencoders**: Reconstruct normal video; anomalies have high error
- **Predictive models**: Predict future frames; anomalies are unpredictable
- **Density estimation**: Model distribution of normal embeddings
- **Memory networks**: Store prototypes of normal patterns
- **Contrastive learning**: Learn features that distinguish normal variations

**Anomaly scoring:**

- **Reconstruction error**: Pixel or feature-level reconstruction loss
- **Prediction error**: Difference between predicted and actual future
- **Likelihood**: Probability under learned normal distribution
- **Distance to normal**: Nearest neighbor distance in embedding space
- **Ensemble**: Combine multiple scoring methods for robustness

**Contextual adaptation:**

- **Time-of-day**: Different normal patterns for day vs night
- **Day-of-week**: Weekend vs weekday differences
- **Camera-specific**: Learn separate models per camera
- **Seasonal**: Adapt to weather and seasonal changes
- **Event-aware**: Adjust thresholds during known events

**Operational:**

- **Threshold tuning**: Balance sensitivity vs false positive rate
- **Alert fatigue**: Aggregate and prioritize alerts
- **Human review**: Efficient interfaces for validating anomalies
- **Feedback loops**: Learn from operator accept/reject decisions
- **Continuous learning**: Update models as normal evolves
:::

## Forensic Video Search

Forensic search enables rapid retrieval of specific events, people, or objects across large video archives. **Embedding-based video search** indexes footage for semantic queries across weeks or months of recordings.

### The Forensic Search Challenge

Traditional video review faces limitations:

- **Volume**: Reviewing hours of footage manually is impractical
- **Speed**: Investigations need answers in minutes, not days
- **Precision**: Finding specific moments in vast archives
- **Multi-camera**: Events may span multiple camera views
- **Retention**: Archives may span weeks to years

**Embedding approach**: Index video with frame and clip embeddings; enable semantic search by example (find similar events), by description (natural language queries), or by structured attributes (person wearing red, vehicle type).

```python
{{< include /code_examples/ch29_video_surveillance/forensic_search.py >}}
```

:::{.callout-tip}
## Forensic Search Best Practices

**Indexing:**

- **Keyframe selection**: Index representative frames, not every frame
- **Multi-granularity**: Frame embeddings for appearance, clip embeddings for action
- **Attribute extraction**: Structured metadata (colors, object types, counts)
- **Scene segmentation**: Detect shot boundaries and scene changes
- **Incremental indexing**: Add new footage without full re-index

**Query types:**

- **Query by example**: Find similar to this image/clip
- **Attribute search**: "Person in red shirt", "white sedan"
- **Natural language**: "Person running through parking lot"
- **Composite queries**: Combine multiple constraints
- **Temporal queries**: "What happened before/after this event"

**Search efficiency:**

- **Approximate nearest neighbor**: HNSW, IVF for sub-second search
- **Temporal pruning**: Limit search to relevant time windows
- **Camera filtering**: Search only relevant camera subset
- **Progressive refinement**: Fast initial filter, detailed re-ranking
- **Result clustering**: Group similar results for efficient review

**User interface:**

- **Timeline visualization**: Show result distribution over time
- **Multi-camera view**: Synchronized playback across cameras
- **Result preview**: Quick thumbnails before full video load
- **Relevance feedback**: Refine search based on user selections
- **Export**: Extract clips for evidence or sharing
:::

## Industry Applications

Video surveillance embeddings enable diverse applications across industries, each with specific requirements and use cases.

### Retail Loss Prevention

Retail environments use video analytics for loss prevention, customer experience, and operations optimization.

```python
{{< include /code_examples/ch29_video_surveillance/retail_analytics.py >}}
```

:::{.callout-tip}
## Retail Video Analytics

**Loss prevention:**

- **Concealment detection**: Identify potential shoplifting behavior
- **Checkout exceptions**: Detect scan avoidance, sweethearting
- **Fitting room monitoring**: Track items in vs out (respecting privacy)
- **Exit alerts**: Match items leaving with purchases
- **Evidence retrieval**: Rapid search for incident documentation

**Customer analytics:**

- **Traffic patterns**: Understand store flow and congestion
- **Dwell time**: Measure engagement at displays
- **Queue management**: Monitor wait times, open registers proactively
- **Demographics**: Aggregate (not individual) customer composition
- **Conversion analysis**: Correlate behavior with purchases

**Operations:**

- **Staffing optimization**: Align staff with traffic patterns
- **Planogram compliance**: Verify display setup
- **Cleanliness monitoring**: Detect spills, maintenance needs
- **Delivery verification**: Confirm vendor deliveries
- **Safety compliance**: Employee safety behaviors
:::

### Smart City Public Safety

Smart cities deploy video analytics for traffic management, public safety, and urban planning.

```python
{{< include /code_examples/ch29_video_surveillance/smart_city.py >}}
```

:::{.callout-tip}
## Smart City Video Analytics

**Traffic management:**

- **Vehicle counting**: Traffic volume by time and location
- **Speed estimation**: Detect speeding, traffic flow
- **Incident detection**: Accidents, breakdowns, debris
- **Parking management**: Occupancy, violations, guidance
- **Signal optimization**: Adaptive timing based on real-time flow

**Public safety:**

- **Crowd monitoring**: Density, flow, anomalies
- **Incident detection**: Fights, falls, medical emergencies
- **Abandoned objects**: Unattended bags, packages
- **Perimeter security**: Intrusion detection at restricted areas
- **Emergency response**: Rapid situation assessment

**Urban planning:**

- **Pedestrian patterns**: Sidewalk usage, crossing behavior
- **Public space utilization**: Park, plaza usage patterns
- **Infrastructure monitoring**: Bridge, tunnel conditions
- **Environmental monitoring**: Flooding, smoke detection
- **Accessibility assessment**: Mobility aid usage patterns
:::

### Manufacturing Safety Compliance

Manufacturing facilities use video analytics for safety monitoring, quality control, and process optimization.

```python
{{< include /code_examples/ch29_video_surveillance/manufacturing_safety.py >}}
```

:::{.callout-tip}
## Manufacturing Video Analytics

**Safety compliance:**

- **PPE detection**: Hard hats, safety vests, goggles, gloves
- **Zone monitoring**: Restricted area access, safe distances
- **Unsafe behavior**: Running, improper lifting, horseplay
- **Emergency detection**: Falls, injuries, equipment incidents
- **Compliance reporting**: Automated safety audits

**Quality control:**

- **Defect detection**: Visual inspection of products
- **Assembly verification**: Correct parts, proper installation
- **Process monitoring**: Adherence to standard procedures
- **Measurement**: Dimensional verification via vision
- **Traceability**: Link video to production records

**Operations:**

- **Equipment monitoring**: Abnormal operation detection
- **Workflow analysis**: Cycle time, bottleneck identification
- **Inventory tracking**: Material movement, levels
- **Maintenance**: Predictive maintenance from visual indicators
- **Training**: Capture best practices, identify coaching opportunities
:::

### Healthcare Patient Safety

Healthcare facilities use video analytics for patient safety, operational efficiency, and quality improvement.

:::{.callout-tip}
## Healthcare Video Analytics

**Patient safety:**

- **Fall detection**: Immediate alerts for patient falls
- **Wandering prevention**: Dementia patient monitoring
- **Bed exit detection**: Alert when at-risk patients attempt to leave bed
- **Patient activity**: Mobility tracking for recovery assessment
- **Emergency detection**: Rapid response to medical emergencies

**Infection control:**

- **Hand hygiene**: Monitor compliance with wash requirements
- **PPE compliance**: Mask, gown, glove usage in appropriate areas
- **Contact tracing**: Retrospective tracking for outbreak investigation
- **Isolation compliance**: Monitor isolation room protocols
- **Visitor management**: Enforce visiting policies

**Operations:**

- **Wait time monitoring**: Emergency department, clinic queues
- **Room utilization**: OR, exam room efficiency
- **Staff workflow**: Movement patterns, task analysis
- **Equipment tracking**: Locate mobile equipment
- **Capacity management**: Real-time bed availability
:::

## Privacy-Preserving Video Analytics

Privacy concerns require techniques that extract value from video while protecting individual privacy.

### Privacy Protection Techniques

```python
{{< include /code_examples/ch29_video_surveillance/privacy_preservation.py >}}
```

:::{.callout-tip}
## Privacy-Preserving Techniques

**Data minimization:**

- **Edge processing**: Analyze on-camera, transmit only metadata
- **Face blurring**: Automatic face detection and anonymization
- **Body abstraction**: Replace people with silhouettes or skeletons
- **Selective recording**: Only record when events detected
- **Retention limits**: Automatic deletion after defined period

**Technical measures:**

- **Differential privacy**: Add noise to aggregate statistics
- **Federated learning**: Train models without centralizing video
- **Secure computation**: Encrypted video analysis
- **Access controls**: Role-based access to video and analytics
- **Audit logging**: Track all video access and queries

**Policy measures:**

- **Notice**: Clear signage about video monitoring
- **Purpose limitation**: Define and enforce allowed use cases
- **Data governance**: Policies for access, retention, sharing
- **Impact assessments**: Evaluate privacy implications
- **Regular audits**: Verify compliance with policies

**Bias mitigation:**

- **Demographic testing**: Evaluate accuracy across groups
- **Training data diversity**: Representative training sets
- **Threshold calibration**: Equal error rates across demographics
- **Human review**: Require human confirmation for consequential actions
- **Continuous monitoring**: Track disparate impact in production
:::

## Key Takeaways

:::{.callout-note}
The performance metrics in the takeaways below are illustrative based on published research and industry benchmarks. They represent achievable performance but are not verified results from specific deployments.
:::

- **Real-time video processing at scale requires hierarchical, edge-cloud architectures**: Processing thousands of concurrent streams demands efficient frame embedding extraction (>100 fps per GPU), edge preprocessing to reduce bandwidth, hierarchical detection (fast filter then accurate classifier), and horizontal scaling with load balancing—achieving sub-second detection latency while managing compute costs

- **Person re-identification enables tracking without biometric identification**: Appearance-based embeddings capture clothing, body shape, and gait patterns robust to pose and lighting changes, achieving 80-95% rank-1 accuracy across camera networks while avoiding face recognition privacy concerns—though still requiring careful governance around tracking scope and retention

- **Action recognition detects behaviors through temporal embeddings**: 3D convolutions, two-stream networks, and temporal transformers capture spatiotemporal patterns for detecting activities from shoplifting behaviors to safety violations to customer interactions, with domain-specific fine-tuning achieving 85-95% accuracy on targeted action sets

- **Anomaly detection identifies unusual events without explicit training examples**: Learning normal behavior patterns through autoencoders, prediction models, and density estimation enables detection of arbitrary anomalies—achieving 70-90% detection with <5% false positive rates when properly tuned to specific camera contexts and time patterns

- **Forensic video search transforms archives into queryable databases**: Indexing keyframes and clips with embeddings enables semantic search across weeks of footage in seconds—finding specific people, objects, or events through query-by-example, attribute search, or natural language without manual review of hours of video

- **Industry applications share common technical foundations with domain-specific requirements**: Retail (loss prevention, customer analytics), smart cities (traffic, public safety), manufacturing (safety compliance, quality), and healthcare (patient safety, infection control) all leverage the same core embedding techniques with specialized models, thresholds, and integration requirements

- **Privacy-preserving analytics must be designed in from the start**: Edge processing, face blurring, purpose limitation, retention policies, access controls, and bias testing are not afterthoughts—they determine whether video analytics deployments are legally compliant, ethically acceptable, and trusted by the people being monitored

## Looking Ahead

Part VI (Future-Proofing & Optimization) begins with Chapter 28, which covers performance optimization for embedding systems: query optimization strategies for sub-50ms retrieval at trillion-row scale, index tuning for specific workload patterns, caching strategies for frequently accessed embeddings, compression techniques that reduce storage by 75% while maintaining quality, and network optimization for distributed queries across global data centers.

## Further Reading

### Video Understanding and Recognition
- Carreira, Joao, and Andrew Zisserman (2017). "Quo Vadis, Action Recognition? A New Model and the Kinetics Dataset." CVPR.
- Feichtenhofer, Christoph, et al. (2019). "SlowFast Networks for Video Recognition." ICCV.
- Arnab, Anurag, et al. (2021). "ViViT: A Video Vision Transformer." ICCV.
- Tran, Du, et al. (2015). "Learning Spatiotemporal Features with 3D Convolutional Networks." ICCV.
- Wang, Limin, et al. (2016). "Temporal Segment Networks: Towards Good Practices for Deep Action Recognition." ECCV.

### Person Re-Identification
- Ye, Mang, et al. (2021). "Deep Learning for Person Re-identification: A Survey and Outlook." IEEE TPAMI.
- Luo, Hao, et al. (2019). "Bag of Tricks and a Strong Baseline for Deep Person Re-identification." CVPR Workshops.
- Sun, Yifan, et al. (2018). "Beyond Part Models: Person Retrieval with Refined Part Pooling." ECCV.
- He, Shuting, et al. (2021). "TransReID: Transformer-based Object Re-Identification." ICCV.
- Zheng, Liang, et al. (2015). "Scalable Person Re-identification: A Benchmark." ICCV.

### Video Anomaly Detection
- Liu, Wen, et al. (2018). "Future Frame Prediction for Anomaly Detection – A New Baseline." CVPR.
- Sultani, Waqas, et al. (2018). "Real-World Anomaly Detection in Surveillance Videos." CVPR.
- Park, Hyunjong, et al. (2020). "Learning Memory-guided Normality for Anomaly Detection." CVPR.
- Georgescu, Mariana-Iuliana, et al. (2021). "Anomaly Detection in Video via Self-Supervised and Multi-Task Learning." CVPR.
- Ramachandra, Bharathkumar, and Michael Jones (2020). "Street Scene: A New Dataset and Evaluation Protocol for Video Anomaly Detection." WACV.

### Video Retrieval and Search
- Miech, Antoine, et al. (2019). "HowTo100M: Learning a Text-Video Embedding by Watching Hundred Million Narrated Video Clips." ICCV.
- Bain, Max, et al. (2021). "Frozen in Time: A Joint Video and Image Encoder for End-to-End Retrieval." ICCV.
- Xu, Jun, et al. (2016). "MSR-VTT: A Large Video Description Dataset for Bridging Video and Language." CVPR.
- Lei, Jie, et al. (2021). "Less is More: ClipBERT for Video-and-Language Learning via Sparse Sampling." CVPR.
- Gabeur, Valentin, et al. (2020). "Multi-modal Transformer for Video Retrieval." ECCV.

### Retail and Smart City Analytics
- Hampapur, Arun, et al. (2005). "Smart Video Surveillance: Exploring the Concept of Multiscale Spatiotemporal Tracking." IEEE Signal Processing Magazine.
- Collins, Robert T., et al. (2000). "A System for Video Surveillance and Monitoring." Carnegie Mellon University Technical Report.
- Senior, Andrew, et al. (2006). "Appearance Models for Occlusion Handling." Image and Vision Computing.
- Yilmaz, Alper, et al. (2006). "Object Tracking: A Survey." ACM Computing Surveys.
- Zhang, Shanshan, et al. (2016). "How Far are We from Solving Pedestrian Detection?" CVPR.

### Privacy and Ethics in Video Surveillance
- Cavallaro, Andrea (2007). "Privacy in Video Surveillance." IEEE Signal Processing Magazine.
- Senior, Andrew, et al. (2005). "Enabling Video Privacy through Computer Vision." IEEE Security & Privacy.
- Winkler, Thomas, and Bernhard Rinner (2014). "Security and Privacy Protection in Visual Sensor Networks: A Survey." ACM Computing Surveys.
- Dwork, Cynthia, and Aaron Roth (2014). "The Algorithmic Foundations of Differential Privacy." Foundations and Trends in Theoretical Computer Science.
- Buolamwini, Joy, and Timnit Gebru (2018). "Gender Shades: Intersectional Accuracy Disparities in Commercial Gender Classification." FAT*.
